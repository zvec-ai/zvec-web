{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Python API Reference","text":"<p>This documentation covers the public Python API for Zvec.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install zvec\n</code></pre>"},{"location":"#core-components","title":"Core Components","text":"<p>The Zvec API is built around the following components:</p> <ul> <li>Global Configuration: Configure Zvec's runtime behavior, including logging, threading, memory limits, etc.</li> <li>Types: Enumerations that define supported data types, indexing strategies, and similarity metrics.</li> <li>Collection Schema: Declare the structure of a collection (e.g., field names, data types, etc.).</li> <li>Collection Class: Manage vector data through collections \u2014 the containers for storing, organizing, and querying documents. Collections are analogous to tables in a relational database like MySQL, and are defined by a schema.</li> <li>Doc Class: Represent individual data records. A document is the basic unit of storage in Zvec, analogous to a row in a relational table, and must conform to the schema of its collection.</li> <li>Parameters: Structured configuration objects for collections, indexes, and queries.</li> <li>Extension: Enhance Zvec with additional utilities.</li> </ul>"},{"location":"collection/","title":"Collection Class","text":""},{"location":"collection/#zvec.create_and_open","title":"zvec.create_and_open","text":"<pre><code>create_and_open(\n    path: str, schema: CollectionSchema, option: Optional[CollectionOption] = None\n) -&gt; Collection\n</code></pre> <p>Create a new collection and open it for use.</p> <p>If a collection already exists at the given path, it may raise an error depending on the underlying implementation.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path or name of the collection to create.</p> required <code>CollectionSchema</code> <p>Schema defining the structure of the collection.</p> required <code>CollectionOption</code> <p>Configuration options for opening the collection. Defaults to a default-constructed <code>CollectionOption()</code> if not provided.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Collection</code> <code>Collection</code> <p>An opened collection instance ready for operations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; schema = zvec.CollectionSchema(\n...     name=\"my_collection\",\n...     fields=[zvec.FieldSchema(\"id\", zvec.DataType.INT64, nullable=True)]\n... )\n&gt;&gt;&gt; coll = create_and_open(\"./my_collection\", schema)\n</code></pre>"},{"location":"collection/#zvec.create_and_open(path)","title":"<code>path</code>","text":""},{"location":"collection/#zvec.create_and_open(schema)","title":"<code>schema</code>","text":""},{"location":"collection/#zvec.create_and_open(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.open","title":"zvec.open","text":"<pre><code>open(path: str, option: CollectionOption = CollectionOption()) -&gt; Collection\n</code></pre> <p>Open an existing collection from disk.</p> <p>The collection must have been previously created with <code>create_and_open</code>.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path or name of the existing collection.</p> required <code>CollectionOption</code> <p>Configuration options for opening the collection. Defaults to a default-constructed <code>CollectionOption()</code> if not provided.</p> <code>CollectionOption()</code> <p>Returns:</p> Name Type Description <code>Collection</code> <code>Collection</code> <p>An opened collection instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; coll = zvec.open(\"./my_collection\")\n</code></pre>"},{"location":"collection/#zvec.open(path)","title":"<code>path</code>","text":""},{"location":"collection/#zvec.open(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.model.collection.Collection","title":"zvec.model.collection.Collection","text":"<pre><code>Collection(obj: _Collection)\n</code></pre> <p>Represents an opened collection in Zvec.</p> <p>A <code>Collection</code> provides methods for data definition (DDL), data manipulation (DML), and querying (DQL). It is obtained via <code>create_and_open()</code> or <code>open()</code>.</p> <p>This class is not meant to be instantiated directly; use factory functions instead.</p> <p>Methods:</p> Name Description <code>destroy</code> <p>Permanently delete the collection from disk.</p> <code>flush</code> <p>Force all pending writes to disk.</p> <code>create_index</code> <p>Create an index on a field.</p> <code>drop_index</code> <p>Remove the index from a field.</p> <code>optimize</code> <p>Optimize the collection (e.g., merge segments, rebuild index).</p> <code>add_column</code> <p>Add a new column to the collection.</p> <code>drop_column</code> <p>Remove a column from the collection.</p> <code>alter_column</code> <p>Rename a column, update its schema.</p> <code>insert</code> <p>Insert new documents into the collection.</p> <code>upsert</code> <p>Insert new documents or update existing ones by ID.</p> <code>update</code> <p>Update existing documents by ID.</p> <code>delete</code> <p>Delete documents by ID.</p> <code>delete_by_filter</code> <p>Delete documents matching a filter expression.</p> <code>fetch</code> <p>Retrieve documents by ID.</p> <code>query</code> <p>Perform vector similarity search with optional filtering and re-ranking.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>str: The filesystem path of the collection.</p> <code>option</code> <code>CollectionOption</code> <p>CollectionOption: The options used to open the collection.</p> <code>schema</code> <code>CollectionSchema</code> <p>CollectionSchema: The schema defining the structure of the collection.</p> <code>stats</code> <code>CollectionStats</code> <p>CollectionStats: Runtime statistics about the collection (e.g., doc count, size).</p>"},{"location":"collection/#zvec.model.collection.Collection-attributes","title":"Attributes","text":""},{"location":"collection/#zvec.model.collection.Collection.path","title":"path  <code>property</code>","text":"<pre><code>path: str\n</code></pre> <p>str: The filesystem path of the collection.</p>"},{"location":"collection/#zvec.model.collection.Collection.option","title":"option  <code>property</code>","text":"<pre><code>option: CollectionOption\n</code></pre> <p>CollectionOption: The options used to open the collection.</p>"},{"location":"collection/#zvec.model.collection.Collection.schema","title":"schema  <code>property</code>","text":"<pre><code>schema: CollectionSchema\n</code></pre> <p>CollectionSchema: The schema defining the structure of the collection.</p>"},{"location":"collection/#zvec.model.collection.Collection.stats","title":"stats  <code>property</code>","text":"<pre><code>stats: CollectionStats\n</code></pre> <p>CollectionStats: Runtime statistics about the collection (e.g., doc count, size).</p>"},{"location":"collection/#zvec.model.collection.Collection-functions","title":"Functions","text":""},{"location":"collection/#zvec.model.collection.Collection.destroy","title":"destroy","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Permanently delete the collection from disk.</p> Warning <p>This operation is irreversible. All data will be lost.</p>"},{"location":"collection/#zvec.model.collection.Collection.flush","title":"flush","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Force all pending writes to disk.</p> <p>Ensures durability of recent inserts/updates.</p>"},{"location":"collection/#zvec.model.collection.Collection.create_index","title":"create_index","text":"<pre><code>create_index(\n    field_name: str,\n    index_param: Union[HnswIndexParam, IVFIndexParam, FlatIndexParam, InvertIndexParam],\n    option: IndexOption = IndexOption(),\n) -&gt; None\n</code></pre> <p>Create an index on a field.</p> <p>Vector index types (HNSW, IVF, FLAT) can only be applied to vector fields. Inverted index (<code>InvertIndexParam</code>) is for scalar fields.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the field to index.</p> required <code>Union[HnswIndexParam, IVFIndexParam, FlatIndexParam, InvertIndexParam]</code> <p>Index configuration.</p> required <code>Optional[IndexOption]</code> <p>Index creation options. Defaults to <code>IndexOption()</code>.</p> <code>IndexOption()</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a vector index is applied to a non-vector field.</p>"},{"location":"collection/#zvec.model.collection.Collection.create_index(field_name)","title":"<code>field_name</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.create_index(index_param)","title":"<code>index_param</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.create_index(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.drop_index","title":"drop_index","text":"<pre><code>drop_index(field_name: str) -&gt; None\n</code></pre> <p>Remove the index from a field.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the indexed field.</p> required"},{"location":"collection/#zvec.model.collection.Collection.drop_index(field_name)","title":"<code>field_name</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.optimize","title":"optimize","text":"<pre><code>optimize(option: OptimizeOption = OptimizeOption()) -&gt; None\n</code></pre> <p>Optimize the collection (e.g., merge segments, rebuild index).</p> <p>Parameters:</p> Name Type Description Default <code>Optional[OptimizeOption]</code> <p>Optimization options. Defaults to <code>OptimizeOption()</code>.</p> <code>OptimizeOption()</code>"},{"location":"collection/#zvec.model.collection.Collection.optimize(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.add_column","title":"add_column","text":"<pre><code>add_column(\n    field_schema: FieldSchema, expression: str = \"\", option: AddColumnOption = AddColumnOption()\n) -&gt; None\n</code></pre> <p>Add a new column to the collection.</p> <p>The column is populated using the provided expression (e.g., SQL-like formula).</p> <p>Parameters:</p> Name Type Description Default <code>FieldSchema</code> <p>Schema definition for the new column.</p> required <code>str</code> <p>Expression to compute values for existing documents.</p> <code>''</code> <code>Optional[AddColumnOption]</code> <p>Options for the operation. Defaults to <code>AddColumnOption()</code>.</p> <code>AddColumnOption()</code>"},{"location":"collection/#zvec.model.collection.Collection.add_column(field_schema)","title":"<code>field_schema</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.add_column(expression)","title":"<code>expression</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.add_column(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.drop_column","title":"drop_column","text":"<pre><code>drop_column(field_name: str) -&gt; None\n</code></pre> <p>Remove a column from the collection.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the column to drop.</p> required"},{"location":"collection/#zvec.model.collection.Collection.drop_column(field_name)","title":"<code>field_name</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.alter_column","title":"alter_column","text":"<pre><code>alter_column(\n    old_name: str,\n    new_name: Optional[str] = None,\n    field_schema: Optional[FieldSchema] = None,\n    option: AlterColumnOption = AlterColumnOption(),\n) -&gt; None\n</code></pre> <p>Rename a column, update its schema.</p> This method supports three atomic operations <ol> <li>Rename only (when <code>field_schema</code> is None).</li> <li>Modify schema only (when <code>new_name</code> is None or empty string).</li> </ol> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The current name of the column to be altered.</p> required <code>Optional[str]</code> <p>The new name for the column. - If provided and non-empty, the column will be renamed. - If <code>None</code> or empty string, no rename occurs.</p> <code>None</code> <code>Optional[FieldSchema]</code> <p>The new schema definition. - If provided, the column's type, dimension, or other properties will be updated. - If <code>None</code>, only renaming (if requested) is performed.</p> <code>None</code> <code>AlterColumnOption</code> <p>Options controlling the alteration behavior. Defaults to <code>AlterColumnOption()</code>.</p> <code>AlterColumnOption()</code> <p>Limitation: This operation only supports scalar numeric columns. such as: - <code>DOUBLE</code>, <code>FLOAT</code>, - <code>INT32</code>, <code>INT64</code>, <code>UINT32</code>, <code>UINT64</code></p> Note <ul> <li>Schema modification may trigger data migration or index rebuild.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Rename column only\n&gt;&gt;&gt; results = collection.alter_column(old_name=\"id\", new_name=\"doc_id\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Modify schema only\n&gt;&gt;&gt; new_schema = FieldSchema(name=\"doc_id\", dtype=DataType.INT64)\n&gt;&gt;&gt; collection.alter_column(\"id\", field_schema=new_schema)\n</code></pre>"},{"location":"collection/#zvec.model.collection.Collection.alter_column(old_name)","title":"<code>old_name</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.alter_column(new_name)","title":"<code>new_name</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.alter_column(field_schema)","title":"<code>field_schema</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.alter_column(option)","title":"<code>option</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.insert","title":"insert","text":"<pre><code>insert(docs: Union[Doc, list[Doc]]) -&gt; Union[Status, list[Status]]\n</code></pre> <p>Insert new documents into the collection.</p> <p>Documents must have unique IDs and conform to the schema.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Doc, list[Doc]]</code> <p>One or more documents to insert.</p> required <p>Returns:</p> Type Description <code>Union[Status, list[Status]]</code> <p>Union[Status, list[Status]]: If a single Doc was given, returns its Status;</p> <code>Union[Status, list[Status]]</code> <p>if a list was given, returns a list of Status objects.</p>"},{"location":"collection/#zvec.model.collection.Collection.insert(docs)","title":"<code>docs</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.upsert","title":"upsert","text":"<pre><code>upsert(docs: Union[Doc, list[Doc]]) -&gt; Union[Status, list[Status]]\n</code></pre> <p>Insert new documents or update existing ones by ID.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Doc, list[Doc]]</code> <p>Documents to upsert.</p> required <p>Returns:</p> Type Description <code>Union[Status, list[Status]]</code> <p>Union[Status, list[Status]]: If a single Doc was given, returns its Status;</p> <code>Union[Status, list[Status]]</code> <p>if a list was given, returns a list of Status objects.</p>"},{"location":"collection/#zvec.model.collection.Collection.upsert(docs)","title":"<code>docs</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.update","title":"update","text":"<pre><code>update(docs: Union[Doc, list[Doc]]) -&gt; Union[Status, list[Status]]\n</code></pre> <p>Update existing documents by ID.</p> <p>Only specified fields are updated; others remain unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Doc, list[Doc]]</code> <p>Documents containing updated fields.</p> required <p>Returns:</p> Type Description <code>Union[Status, list[Status]]</code> <p>Union[Status, list[Status]]: If a single Doc was given, returns its Status;</p> <code>Union[Status, list[Status]]</code> <p>if a list was given, returns a list of Status objects.</p>"},{"location":"collection/#zvec.model.collection.Collection.update(docs)","title":"<code>docs</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.delete","title":"delete","text":"<pre><code>delete(ids: Union[str, list[str]]) -&gt; Union[Status, list[Status]]\n</code></pre> <p>Delete documents by ID.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, list[str]]</code> <p>One or more document IDs to delete.</p> required <p>Returns:</p> Type Description <code>Union[Status, list[Status]]</code> <p>Union[Status, list[Status]]: If a single id was given, returns its Status;</p> <code>Union[Status, list[Status]]</code> <p>if a list was given, returns a list of Status objects.</p>"},{"location":"collection/#zvec.model.collection.Collection.delete(ids)","title":"<code>ids</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.delete_by_filter","title":"delete_by_filter","text":"<pre><code>delete_by_filter(filter: str) -&gt; None\n</code></pre> <p>Delete documents matching a filter expression.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Boolean expression (e.g., <code>\"age &gt; 30\"</code>).</p> required"},{"location":"collection/#zvec.model.collection.Collection.delete_by_filter(filter)","title":"<code>filter</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.fetch","title":"fetch","text":"<pre><code>fetch(ids: Union[str, list[str]]) -&gt; dict[str, Doc]\n</code></pre> <p>Retrieve documents by ID.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, list[str]]</code> <p>Document IDs to fetch.</p> required <p>Returns:</p> Type Description <code>dict[str, Doc]</code> <p>dict[str, Doc]: Mapping from ID to document. Missing IDs are omitted.</p>"},{"location":"collection/#zvec.model.collection.Collection.fetch(ids)","title":"<code>ids</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query","title":"query","text":"<pre><code>query(\n    vectors: Optional[Union[VectorQuery, list[VectorQuery]]] = None,\n    *,\n    topk: int = 10,\n    filter: Optional[str] = None,\n    include_vector: bool = False,\n    output_fields: Optional[list[str]] = None,\n    reranker: Optional[ReRanker] = None\n) -&gt; list[Doc]\n</code></pre> <p>Perform vector similarity search with optional filtering and re-ranking.</p> <p>At least one <code>VectorQuery</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[Union[VectorQuery, list[VectorQuery]]]</code> <p>One or more vector queries. Defaults to None.</p> <code>None</code> <code>int</code> <p>Number of nearest neighbors to return. Defaults to 10.</p> <code>10</code> <code>Optional[str]</code> <p>Boolean expression to pre-filter candidates. Defaults to None.</p> <code>None</code> <code>bool</code> <p>Whether to include vector data in results. Defaults to False.</p> <code>False</code> <code>Optional[list[str]]</code> <p>Scalar fields to include. If None, all fields are returned. Defaults to None.</p> <code>None</code> <code>Optional[ReRanker]</code> <p>Re-ranker to refine results. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Top-k matching documents, sorted by relevance score.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec import VectorQuery\n&gt;&gt;&gt; results = collection.query(\n...     vectors=VectorQuery(\"embedding\", vector=[0.1, 0.2]),\n...     topk=5,\n...     filter=\"category == 'tech'\",\n...     output_fields=[\"title\", \"url\"]\n... )\n</code></pre>"},{"location":"collection/#zvec.model.collection.Collection.query(vectors)","title":"<code>vectors</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query(topk)","title":"<code>topk</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query(filter)","title":"<code>filter</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query(include_vector)","title":"<code>include_vector</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query(output_fields)","title":"<code>output_fields</code>","text":""},{"location":"collection/#zvec.model.collection.Collection.query(reranker)","title":"<code>reranker</code>","text":""},{"location":"config/","title":"Global Configuration","text":""},{"location":"config/#zvec.init","title":"zvec.init","text":"<pre><code>init(\n    *,\n    log_type: Optional[LogType] = CONSOLE,\n    log_level: Optional[LogLevel] = WARN,\n    log_dir: Optional[str] = \"./logs\",\n    log_basename: Optional[str] = \"zvec.log\",\n    log_file_size: Optional[int] = 2048,\n    log_overdue_days: Optional[int] = 7,\n    query_threads: Optional[int] = None,\n    optimize_threads: Optional[int] = None,\n    invert_to_forward_scan_ratio: Optional[float] = None,\n    brute_force_by_keys_ratio: Optional[float] = None,\n    memory_limit_mb: Optional[int] = None\n) -&gt; None\n</code></pre> <p>Initialize Zvec with configuration options.</p> <p>This function must be called before any other operation. It can only be called once \u2014 subsequent calls raise a <code>RuntimeError</code>.</p> <p>Parameters set to <code>None</code> are omitted from the configuration and fall back to Zvec's internal defaults, which may be derived from the runtime environment (e.g., cgroup CPU/memory limits). Explicitly provided values always override defaults.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[LogType]</code> <p>Logger destination. - <code>LogType.CONSOLE</code> (default if omitted or set to this) - <code>LogType.FILE</code> - If <code>None</code>, uses internal default (currently <code>CONSOLE</code>).</p> <code>CONSOLE</code> <code>Optional[LogLevel]</code> <p>Minimum log severity. Default: <code>LogLevel.WARN</code>. Accepted values: <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, <code>FATAL</code>. If <code>None</code>, uses internal default (<code>WARN</code>).</p> <code>WARN</code> <code>Optional[str]</code> <p>Directory for log files (only used when <code>log_type=FILE</code>). Parent directories are not created automatically. Default: <code>\"./logs\"</code>. If <code>None</code>, internal default is used.</p> <code>'./logs'</code> <code>Optional[str]</code> <p>Base name for rotated log files (e.g., <code>zvec.log.1</code>, <code>zvec.log.2</code>). Default: <code>\"zvec.log\"</code>.</p> <code>'zvec.log'</code> <code>Optional[int]</code> <p>Max size per log file in MB before rotation. Default: <code>2048</code> MB (2 GB).</p> <code>2048</code> <code>Optional[int]</code> <p>Days to retain rotated log files before deletion. Default: <code>7</code> days.</p> <code>7</code> <code>Optional[int]</code> <p>Number of threads for query execution. If <code>None</code> (default), inferred from available CPU cores (via cgroup). Must be \u2265 1 if provided.</p> <code>None</code> <code>Optional[int]</code> <p>Threads for background tasks (e.g., compaction, indexing). If <code>None</code>, defaults to same as <code>query_threads</code> or CPU count.</p> <code>None</code> <code>Optional[float]</code> <p>Threshold to switch from inverted index to full forward scan. Range: [0.0, 1.0]. Higher \u2192 more aggressive index skipping. Default: <code>0.9</code> (if omitted).</p> <code>None</code> <code>Optional[float]</code> <p>Threshold to use brute-force key lookup over index. Lower \u2192 prefer index; higher \u2192 prefer brute-force. Range: [0.0, 1.0]. Default: <code>0.1</code>.</p> <code>None</code> <code>Optional[int]</code> <p>Soft memory cap in MB. Zvec may throttle or fail operations approaching this limit. If <code>None</code>, inferred from cgroup memory limit * 0.8 (e.g., in Docker). Must be &gt; 0 if provided.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Zvec is already initialized.</p> <code>ValueError</code> <p>On invalid values (e.g., negative thread count, log level out of range).</p> <code>TypeError</code> <p>If a value has incorrect type (e.g., string for <code>query_threads</code>).</p> Note <ul> <li>All <code>None</code> arguments are excluded from the configuration payload,   allowing the core library to apply environment-aware defaults.</li> <li>This design ensures container-friendliness: in Kubernetes/Docker,   omitting <code>memory_limit_mb</code> and thread counts lets Zvec auto-adapt.</li> </ul> <p>Examples:</p> <p>Initialize with defaults (log to console, auto-detect resources):</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; zvec.init()\n</code></pre> <p>Customize logging to file with rotation:</p> <pre><code>&gt;&gt;&gt; zvec.init(\n...     log_type=LogType.FILE,\n...     log_dir=\"/var/log/zvec\",\n...     log_file_size=1024,\n...     log_overdue_days=30\n... )\n</code></pre> <p>Limit resources explicitly:</p> <pre><code>&gt;&gt;&gt; zvec.init(\n...     memory_limit_mb=2048,\n...     query_threads=4,\n...     optimize_threads=2\n... )\n</code></pre> <p>Fine-tune query heuristics:</p> <pre><code>&gt;&gt;&gt; zvec.init(\n...     invert_to_forward_scan_ratio=0.95,\n...     brute_force_by_keys_ratio=0.05\n... )\n</code></pre>"},{"location":"config/#zvec.init(log_type)","title":"<code>log_type</code>","text":""},{"location":"config/#zvec.init(log_level)","title":"<code>log_level</code>","text":""},{"location":"config/#zvec.init(log_dir)","title":"<code>log_dir</code>","text":""},{"location":"config/#zvec.init(log_basename)","title":"<code>log_basename</code>","text":""},{"location":"config/#zvec.init(log_file_size)","title":"<code>log_file_size</code>","text":""},{"location":"config/#zvec.init(log_overdue_days)","title":"<code>log_overdue_days</code>","text":""},{"location":"config/#zvec.init(query_threads)","title":"<code>query_threads</code>","text":""},{"location":"config/#zvec.init(optimize_threads)","title":"<code>optimize_threads</code>","text":""},{"location":"config/#zvec.init(invert_to_forward_scan_ratio)","title":"<code>invert_to_forward_scan_ratio</code>","text":""},{"location":"config/#zvec.init(brute_force_by_keys_ratio)","title":"<code>brute_force_by_keys_ratio</code>","text":""},{"location":"config/#zvec.init(memory_limit_mb)","title":"<code>memory_limit_mb</code>","text":""},{"location":"doc/","title":"Doc Class","text":""},{"location":"doc/#zvec.model.doc.Doc","title":"zvec.model.doc.Doc","text":"<pre><code>Doc(\n    id: str,\n    score: Optional[float] = None,\n    vectors: Optional[dict[str, VectorType]] = None,\n    fields: Optional[dict[str, Any]] = None,\n)\n</code></pre> <p>Represents a retrieved document with optional metadata, fields, and vectors.</p> <p>This immutable data class encapsulates the result of a search or retrieval operation. It includes the document ID, relevance score (if applicable), scalar fields, and vector embeddings.</p> <p>During initialization, any <code>numpy.ndarray</code> in <code>vectors</code> is automatically converted to a plain Python list for JSON serialization and immutability.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier of the document.</p> <code>score</code> <code>Optional[float]</code> <p>Relevance score from search. Defaults to None.</p> <code>vectors</code> <code>Optional[dict[str, VectorType]]</code> <p>Named vector embeddings associated with the document. Values are converted to lists if originally <code>np.ndarray</code>. Defaults to None.</p> <code>fields</code> <code>Optional[dict[str, Any]]</code> <p>Scalar metadata fields (e.g., title, timestamp). Defaults to None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; doc = zvec.Doc(\n...     id=\"doc1\",\n...     score=0.95,\n...     vectors={\"emb\": np.array([0.1, 0.2, 0.3])},\n...     fields={\"title\": \"Hello World\"}\n... )\n&gt;&gt;&gt; print(doc.vector(\"emb\"))\n[0.1, 0.2, 0.3]\n&gt;&gt;&gt; print(doc.has_field(\"title\"))\nTrue\n</code></pre> <p>Methods:</p> Name Description <code>has_field</code> <p>Check if the document contains a scalar field with the given name.</p> <code>has_vector</code> <p>Check if the document contains a vector with the given name.</p> <code>vector</code> <p>Get a vector by name.</p> <code>field</code> <p>Get a scalar field by name.</p> <code>vector_names</code> <p>Get the list of all vector names in this document.</p> <code>field_names</code> <p>Get the list of all scalar field names in this document.</p>"},{"location":"doc/#zvec.model.doc.Doc-functions","title":"Functions","text":""},{"location":"doc/#zvec.model.doc.Doc.has_field","title":"has_field","text":"<pre><code>has_field(name: str) -&gt; bool\n</code></pre> <p>Check if the document contains a scalar field with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the field to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the field exists, False otherwise.</p>"},{"location":"doc/#zvec.model.doc.Doc.has_field(name)","title":"<code>name</code>","text":""},{"location":"doc/#zvec.model.doc.Doc.has_vector","title":"has_vector","text":"<pre><code>has_vector(name: str) -&gt; bool\n</code></pre> <p>Check if the document contains a vector with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the vector to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the vector exists, False otherwise.</p>"},{"location":"doc/#zvec.model.doc.Doc.has_vector(name)","title":"<code>name</code>","text":""},{"location":"doc/#zvec.model.doc.Doc.vector","title":"vector","text":"<pre><code>vector(name: str)\n</code></pre> <p>Get a vector by name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the vector.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>The vector (as a list) if it exists, otherwise None.</p>"},{"location":"doc/#zvec.model.doc.Doc.vector(name)","title":"<code>name</code>","text":""},{"location":"doc/#zvec.model.doc.Doc.field","title":"field","text":"<pre><code>field(name: str)\n</code></pre> <p>Get a scalar field by name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the field.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>The field value if it exists, otherwise None.</p>"},{"location":"doc/#zvec.model.doc.Doc.field(name)","title":"<code>name</code>","text":""},{"location":"doc/#zvec.model.doc.Doc.vector_names","title":"vector_names","text":"<pre><code>vector_names() -&gt; list[str]\n</code></pre> <p>Get the list of all vector names in this document.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of vector field names. Empty if no vectors.</p>"},{"location":"doc/#zvec.model.doc.Doc.field_names","title":"field_names","text":"<pre><code>field_names() -&gt; list[str]\n</code></pre> <p>Get the list of all scalar field names in this document.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of field names. Empty if no fields.</p>"},{"location":"extension/","title":"Extension","text":""},{"location":"extension/#zvec.extension","title":"zvec.extension","text":"<p>Modules:</p> Name Description <code>bm25_embedding_function</code> <code>embedding_function</code> <code>multi_vector_reranker</code> <code>openai_embedding_function</code> <code>openai_function</code> <code>qwen_embedding_function</code> <code>qwen_function</code> <code>qwen_rerank_function</code> <code>rerank_function</code> <code>sentence_transformer_embedding_function</code> <code>sentence_transformer_function</code> <code>sentence_transformer_rerank_function</code> <p>Classes:</p> Name Description <code>BM25EmbeddingFunction</code> <p>BM25-based sparse embedding function using DashText SDK.</p> <code>DenseEmbeddingFunction</code> <p>Protocol for dense vector embedding functions.</p> <code>SparseEmbeddingFunction</code> <p>Abstract base class for sparse vector embedding functions.</p> <code>RrfReRanker</code> <p>Re-ranker using Reciprocal Rank Fusion (RRF) for multi-vector search.</p> <code>WeightedReRanker</code> <p>Re-ranker that combines scores from multiple vector fields using weights.</p> <code>OpenAIDenseEmbedding</code> <p>Dense text embedding function using OpenAI API.</p> <code>OpenAIFunctionBase</code> <p>Base class for OpenAI functions.</p> <code>QwenDenseEmbedding</code> <p>Dense text embedding function using Qwen (DashScope) API.</p> <code>QwenSparseEmbedding</code> <p>Sparse text embedding function using Qwen (DashScope) API.</p> <code>QwenFunctionBase</code> <p>Base class for Qwen (DashScope) functions.</p> <code>QwenReRanker</code> <p>Re-ranker using Qwen (DashScope) cross-encoder API for semantic re-ranking.</p> <code>ReRanker</code> <p>Abstract base class for re-ranking search results.</p> <code>DefaultLocalDenseEmbedding</code> <p>Default local dense embedding using all-MiniLM-L6-v2 model.</p> <code>DefaultLocalSparseEmbedding</code> <p>Default local sparse embedding using SPLADE model.</p> <code>SentenceTransformerFunctionBase</code> <p>Base class for Sentence Transformer functions (both dense and sparse).</p> <code>DefaultLocalReRanker</code> <p>Re-ranker using Sentence Transformer cross-encoder models for semantic re-ranking.</p>"},{"location":"extension/#zvec.extension-classes","title":"Classes","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction","title":"BM25EmbeddingFunction","text":"<pre><code>BM25EmbeddingFunction(\n    corpus: Optional[list[str]] = None,\n    encoding_type: Literal[\"query\", \"document\"] = \"query\",\n    language: Literal[\"zh\", \"en\"] = \"zh\",\n    b: float = 0.75,\n    k1: float = 1.2,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SparseEmbeddingFunction[TEXT]</code></p> <p>BM25-based sparse embedding function using DashText SDK.</p> <p>This class provides text-to-sparse-vector embedding capabilities using the DashText library with BM25 algorithm. BM25 (Best Matching 25) is a probabilistic retrieval function used for lexical search and document ranking based on term frequency and inverse document frequency.</p> <p>BM25 generates sparse vectors where each dimension corresponds to a term in the vocabulary, and the value represents the BM25 score for that term. It's particularly effective for:</p> <ul> <li>Lexical search and keyword matching</li> <li>Document ranking and information retrieval</li> <li>Combining with dense embeddings for hybrid search</li> <li>Traditional IR tasks where exact term matching is important</li> </ul> <p>This implementation uses DashText's SparseVectorEncoder, which provides efficient BM25 computation for Chinese and English text using either a built-in encoder or custom corpus training.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[list[str]]</code> <p>List of documents to train the BM25 encoder. If provided, creates a custom encoder trained on this corpus for better domain-specific accuracy. If <code>None</code>, uses the built-in encoder. Defaults to <code>None</code>.</p> <code>None</code> <code>Literal['query', 'document']</code> <p>Encoding mode for text processing. Use <code>\"query\"</code> for search queries (default) and <code>\"document\"</code> for document indexing. This distinction optimizes the BM25 scoring for asymmetric retrieval tasks. Defaults to <code>\"query\"</code>.</p> <code>'query'</code> <code>Literal['zh', 'en']</code> <p>Language for built-in encoder. Only used when corpus is None. <code>\"zh\"</code> for Chinese (trained on Chinese Wikipedia), <code>\"en\"</code> for English. Defaults to <code>\"zh\"</code>.</p> <code>'zh'</code> <code>float</code> <p>Document length normalization parameter for BM25. Range [0, 1]. 0 means no normalization, 1 means full normalization. Only used with custom corpus. Defaults to <code>0.75</code>.</p> <code>0.75</code> <code>float</code> <p>Term frequency saturation parameter for BM25. Higher values give more weight to term frequency. Only used with custom corpus. Defaults to <code>1.2</code>.</p> <code>1.2</code> <p>Additional parameters for DashText encoder customization.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>corpus_size</code> <code>int</code> <p>Number of documents in the training corpus (0 if using built-in encoder).</p> <code>encoding_type</code> <code>str</code> <p>The encoding type being used (\"query\" or \"document\").</p> <code>language</code> <code>str</code> <p>The language of the built-in encoder (\"zh\" or \"en\").</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If corpus is provided but empty or contains non-string elements.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If DashText encoder initialization or training fails.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>dashtext</code> package: <code>pip install dashtext</code></li> <li> <p>Two encoder options available:</p> </li> <li> <p>Built-in encoder (no corpus needed): Pre-trained models for      Chinese (zh) and English (en), good generalization, works out-of-the-box</p> </li> <li> <p>Custom encoder (corpus required): Better accuracy for domain-specific      terminology, requires training on your full corpus with BM25 parameters</p> </li> <li> <p>Encoding types:</p> </li> <li> <p><code>encoding_type=\"query\"</code>: Optimized for search queries (shorter text)</p> </li> <li> <p><code>encoding_type=\"document\"</code>: Optimized for document indexing (longer text)</p> </li> <li> <p>BM25 parameters (b, k1) only apply to custom encoder training</p> </li> <li>Output is sorted by indices (vocabulary term IDs) for consistency</li> <li>Results are cached (LRU cache, maxsize=10) to reduce computation</li> <li>No API key or network connectivity required (local computation)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Option 1: Using built-in encoder for Chinese (no corpus needed)\n&gt;&gt;&gt; from zvec.extension import BM25EmbeddingFunction\n&gt;&gt;&gt;\n&gt;&gt;&gt; # For query encoding (Chinese)\n&gt;&gt;&gt; bm25_query_zh = BM25EmbeddingFunction(language=\"zh\", encoding_type=\"query\")\n&gt;&gt;&gt; query_vec = bm25_query_zh.embed(\"\u4ec0\u4e48\u662f\u673a\u5668\u5b66\u4e60\")\n&gt;&gt;&gt; isinstance(query_vec, dict)\nTrue\n&gt;&gt;&gt; # query_vec: {1169440797: 0.29, 2045788977: 0.70, ...}\n</code></pre> <pre><code>&gt;&gt;&gt; # For document encoding (Chinese)\n&gt;&gt;&gt; bm25_doc_zh = BM25EmbeddingFunction(language=\"zh\", encoding_type=\"document\")\n&gt;&gt;&gt; doc_vec = bm25_doc_zh.embed(\"\u673a\u5668\u5b66\u4e60\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u91cd\u8981\u5206\u652f...\")\n&gt;&gt;&gt; isinstance(doc_vec, dict)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Using built-in encoder for English\n&gt;&gt;&gt; bm25_query_en = BM25EmbeddingFunction(language=\"en\", encoding_type=\"query\")\n&gt;&gt;&gt; query_vec_en = bm25_query_en.embed(\"what is vector search service\")\n&gt;&gt;&gt; isinstance(query_vec_en, dict)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Option 2: Using custom corpus for domain-specific accuracy\n&gt;&gt;&gt; corpus = [\n...     \"\u673a\u5668\u5b66\u4e60\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u91cd\u8981\u5206\u652f\",\n...     \"\u6df1\u5ea6\u5b66\u4e60\u4f7f\u7528\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\",\n...     \"\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7528\u4e8e\u7406\u89e3\u548c\u751f\u6210\u4eba\u7c7b\u8bed\u8a00\"\n... ]\n&gt;&gt;&gt; bm25_custom = BM25EmbeddingFunction(\n...     corpus=corpus,\n...     encoding_type=\"query\",\n...     b=0.75,\n...     k1=1.2\n... )\n&gt;&gt;&gt; custom_vec = bm25_custom.embed(\"\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\")\n&gt;&gt;&gt; isinstance(custom_vec, dict)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Hybrid search: combining with dense embeddings\n&gt;&gt;&gt; from zvec.extension import DefaultLocalDenseEmbedding\n&gt;&gt;&gt; dense_emb = DefaultLocalDenseEmbedding()\n&gt;&gt;&gt; bm25_emb = BM25EmbeddingFunction(language=\"zh\", encoding_type=\"query\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; query = \"machine learning algorithms\"\n&gt;&gt;&gt; dense_vec = dense_emb.embed(query)  # Semantic similarity\n&gt;&gt;&gt; sparse_vec = bm25_emb.embed(query)  # Lexical matching\n&gt;&gt;&gt; # Combine scores for hybrid retrieval\n</code></pre> <pre><code>&gt;&gt;&gt; # Callable interface\n&gt;&gt;&gt; sparse_vec = bm25_query_zh(\"information retrieval\")\n&gt;&gt;&gt; isinstance(sparse_vec, dict)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     bm25_query_zh.embed(\"\")  # Empty query\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> See Also <ul> <li><code>SparseEmbeddingFunction</code>: Base class for sparse embeddings</li> <li><code>DefaultLocalSparseEmbedding</code>: SPLADE-based sparse embedding</li> <li><code>QwenSparseEmbedding</code>: API-based sparse embedding using Qwen</li> <li><code>DefaultLocalDenseEmbedding</code>: Dense embedding for semantic search</li> </ul> References <ul> <li>DashText Documentation: https://help.aliyun.com/zh/document_detail/2546039.html</li> <li>DashText PyPI: https://pypi.org/project/dashtext/</li> <li>BM25 Algorithm: Robertson &amp; Zaragoza (2009)</li> </ul> <p>Initialize the BM25 embedding function.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[list[str]]</code> <p>Optional corpus for training custom encoder. If None, uses built-in encoder. Defaults to None.</p> <code>None</code> <code>Literal['query', 'document']</code> <p>Text encoding mode. Use \"query\" for search queries, \"document\" for indexing. Defaults to \"query\".</p> <code>'query'</code> <code>Literal['zh', 'en']</code> <p>Language for built-in encoder. \"zh\" for Chinese, \"en\" for English. Defaults to \"zh\".</p> <code>'zh'</code> <code>float</code> <p>Document length normalization for BM25 [0, 1]. Only used with custom corpus. Defaults to 0.75.</p> <code>0.75</code> <code>float</code> <p>Term frequency saturation for BM25. Only used with custom corpus. Defaults to 1.2.</p> <code>1.2</code> <p>Additional DashText encoder parameters.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If corpus is provided but empty or invalid.</p> <code>ImportError</code> <p>If dashtext package is not installed.</p> <code>RuntimeError</code> <p>If encoder initialization or training fails.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate BM25 sparse embedding for the input text.</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(corpus)","title":"<code>corpus</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(encoding_type)","title":"<code>encoding_type</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(language)","title":"<code>language</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(b)","title":"<code>b</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(k1)","title":"<code>k1</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(corpus)","title":"<code>corpus</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(encoding_type)","title":"<code>encoding_type</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(language)","title":"<code>language</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(b)","title":"<code>b</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(k1)","title":"<code>k1</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.corpus_size","title":"corpus_size  <code>property</code>","text":"<pre><code>corpus_size: int\n</code></pre> <p>int: Number of documents in the training corpus (0 if using built-in encoder).</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.encoding_type","title":"encoding_type  <code>property</code>","text":"<pre><code>encoding_type: str\n</code></pre> <p>str: The encoding type being used (\"query\" or \"document\").</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.language","title":"language  <code>property</code>","text":"<pre><code>language: str\n</code></pre> <p>str: The language of the built-in encoder (\"zh\" or \"en\").</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for DashText encoder customization.</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.__call__","title":"__call__","text":"<pre><code>__call__(input: TEXT) -&gt; SparseVectorType\n</code></pre> <p>Make the embedding function callable.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>TEXT</code> <p>Input text to embed.</p> required <p>Returns:</p> Name Type Description <code>SparseVectorType</code> <code>SparseVectorType</code> <p>Sparse vector as dictionary.</p>"},{"location":"extension/#zvec.extension.BM25EmbeddingFunction.embed","title":"embed  <code>cached</code>","text":"<pre><code>embed(input: TEXT) -&gt; SparseVectorType\n</code></pre> <p>Generate BM25 sparse embedding for the input text.</p> <p>This method computes BM25 scores for the input text using DashText's SparseVectorEncoder. The encoding behavior depends on the encoding_type:</p> <ul> <li><code>encoding_type=\"query\"</code>: Uses <code>encode_queries()</code> for search queries</li> <li><code>encoding_type=\"document\"</code>: Uses <code>encode_documents()</code> for documents</li> </ul> <p>The result is a sparse vector where keys are term indices in the vocabulary and values are BM25 scores.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>TEXT</code> <p>Input text string to embed. Must be non-empty after stripping whitespace.</p> required <p>Returns:</p> Name Type Description <code>SparseVectorType</code> <code>SparseVectorType</code> <p>A dictionary mapping vocabulary term index to BM25 score. Only non-zero scores are included. The dictionary is sorted by indices (keys) in ascending order for consistent output. Example: <code>{1169440797: 0.29, 2045788977: 0.70, ...}</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty or whitespace-only.</p> <code>RuntimeError</code> <p>If BM25 encoding fails.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bm25 = BM25EmbeddingFunction(language=\"zh\", encoding_type=\"query\")\n&gt;&gt;&gt; sparse_vec = bm25.embed(\"query text\")\n&gt;&gt;&gt; isinstance(sparse_vec, dict)\nTrue\n&gt;&gt;&gt; all(isinstance(k, int) and isinstance(v, float) for k, v in sparse_vec.items())\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Verify sorted output\n&gt;&gt;&gt; keys = list(sparse_vec.keys())\n&gt;&gt;&gt; keys == sorted(keys)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: empty input\n&gt;&gt;&gt; bm25.embed(\"   \")\nValueError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: non-string input\n&gt;&gt;&gt; bm25.embed(123)\nTypeError: Expected 'input' to be str, got int\n</code></pre> Note <ul> <li>BM25 scores are relative to the vocabulary statistics</li> <li>Output dictionary is always sorted by indices for consistency</li> <li>Terms not in the vocabulary will have zero scores (not included)</li> <li>This method is cached (maxsize=10) for performance</li> <li>DashText automatically handles Chinese/English text segmentation</li> </ul>"},{"location":"extension/#zvec.extension.DenseEmbeddingFunction","title":"DenseEmbeddingFunction","text":"<p>               Bases: <code>Protocol[MD]</code></p> <p>Protocol for dense vector embedding functions.</p> <p>Dense embedding functions map multimodal input (text, image, or audio) to fixed-length real-valued vectors. This is a Protocol class that defines the interface - implementations should provide their own initialization and properties.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <p>The type of input data (bound to Embeddable: TEXT, IMAGE, or AUDIO).</p> required Note <ul> <li>This is a Protocol class - it only defines the <code>embed()</code> interface.</li> <li>Implementations are free to define their own <code>__init__</code>, properties,   and additional methods as needed.</li> <li>The <code>embed()</code> method is the only required interface.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Custom text embedding implementation\n&gt;&gt;&gt; class MyTextEmbedding:\n...     def __init__(self, dimension: int, model_name: str):\n...         self.dimension = dimension\n...         self.model = load_model(model_name)\n...\n...     def embed(self, input: str) -&gt; list[float]:\n...         return self.model.encode(input).tolist()\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom image embedding implementation\n&gt;&gt;&gt; class MyImageEmbedding:\n...     def __init__(self, dimension: int = 512):\n...         self.dimension = dimension\n...         self.model = load_image_model()\n...\n...     def embed(self, input: Union[str, bytes, np.ndarray]) -&gt; list[float]:\n...         if isinstance(input, str):\n...             image = load_image_from_path(input)\n...         else:\n...             image = input\n...         return self.model.extract_features(image).tolist()\n</code></pre> <pre><code>&gt;&gt;&gt; # Using built-in implementations\n&gt;&gt;&gt; from zvec.extension import QwenDenseEmbedding\n&gt;&gt;&gt; text_emb = QwenDenseEmbedding(dimension=768, api_key=\"sk-xxx\")\n&gt;&gt;&gt; vector = text_emb.embed(\"Hello world\")\n</code></pre> <p>Methods:</p> Name Description <code>embed</code> <p>Generate a dense embedding vector for the input data.</p>"},{"location":"extension/#zvec.extension.DenseEmbeddingFunction[MD]","title":"<code>MD</code>","text":""},{"location":"extension/#zvec.extension.DenseEmbeddingFunction-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.DenseEmbeddingFunction.embed","title":"embed  <code>abstractmethod</code>","text":"<pre><code>embed(input: MD) -&gt; DenseVectorType\n</code></pre> <p>Generate a dense embedding vector for the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>MD</code> <p>Multimodal input data to embed. Can be: - TEXT (str): Text string - IMAGE (str | bytes | np.ndarray): Image file path, raw bytes, or array - AUDIO (str | bytes | np.ndarray): Audio file path, raw bytes, or array</p> required <p>Returns:</p> Name Type Description <code>DenseVectorType</code> <code>DenseVectorType</code> <p>A dense vector representing the embedding. Can be list[float], list[int], or np.ndarray. Length should match the implementation's dimension.</p>"},{"location":"extension/#zvec.extension.SparseEmbeddingFunction","title":"SparseEmbeddingFunction","text":"<p>               Bases: <code>Protocol[MD]</code></p> <p>Abstract base class for sparse vector embedding functions.</p> <p>Sparse embedding functions map multimodal input (text, image, or audio) to a dictionary of {index: weight}, where only non-zero dimensions are stored. You can inherit this class to create custom sparse embedding functions.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <p>The type of input data (bound to Embeddable: TEXT, IMAGE, or AUDIO).</p> required Note <p>Subclasses must implement the <code>embed()</code> method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Using built-in text sparse embedding (e.g., BM25, TF-IDF)\n&gt;&gt;&gt; sparse_emb = SomeSparseEmbedding()\n&gt;&gt;&gt; vector = sparse_emb.embed(\"Hello world\")\n&gt;&gt;&gt; # Returns: {0: 0.5, 42: 1.2, 100: 0.8}\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom BM25 sparse embedding function\n&gt;&gt;&gt; class MyBM25Embedding(SparseEmbeddingFunction):\n...     def __init__(self, vocab_size: int = 10000):\n...         self.vocab_size = vocab_size\n...         self.tokenizer = MyTokenizer()\n...\n...     def embed(self, input: str) -&gt; dict[int, float]:\n...         tokens = self.tokenizer.tokenize(input)\n...         sparse_vector = {}\n...         for token_id, weight in self._calculate_bm25(tokens):\n...             if weight &gt; 0:\n...                 sparse_vector[token_id] = weight\n...         return sparse_vector\n...\n...     def _calculate_bm25(self, tokens):\n...         # BM25 calculation logic\n...         pass\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom sparse image feature extractor\n&gt;&gt;&gt; class MySparseImageEmbedding(SparseEmbeddingFunction):\n...     def embed(self, input: Union[str, bytes, np.ndarray]) -&gt; dict[int, float]:\n...         image = self._load_image(input)\n...         features = self._extract_sparse_features(image)\n...         return {idx: val for idx, val in enumerate(features) if val != 0}\n</code></pre> <p>Methods:</p> Name Description <code>embed</code> <p>Generate a sparse embedding for the input data.</p>"},{"location":"extension/#zvec.extension.SparseEmbeddingFunction[MD]","title":"<code>MD</code>","text":""},{"location":"extension/#zvec.extension.SparseEmbeddingFunction-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.SparseEmbeddingFunction.embed","title":"embed  <code>abstractmethod</code>","text":"<pre><code>embed(input: MD) -&gt; SparseVectorType\n</code></pre> <p>Generate a sparse embedding for the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>MD</code> <p>Multimodal input data to embed. Can be: - TEXT (str): Text string - IMAGE (str | bytes | np.ndarray): Image file path, raw bytes, or array - AUDIO (str | bytes | np.ndarray): Audio file path, raw bytes, or array</p> required <p>Returns:</p> Name Type Description <code>SparseVectorType</code> <code>SparseVectorType</code> <p>Mapping from dimension index to non-zero weight. Only dimensions with non-zero values are included.</p>"},{"location":"extension/#zvec.extension.RrfReRanker","title":"RrfReRanker","text":"<pre><code>RrfReRanker(topn: int = 10, rerank_field: Optional[str] = None, rank_constant: int = 60)\n</code></pre> <p>               Bases: <code>RerankFunction</code></p> <p>Re-ranker using Reciprocal Rank Fusion (RRF) for multi-vector search.</p> <p>RRF combines results from multiple vector queries without requiring relevance scores. It assigns higher weight to documents that appear early in multiple result lists.</p> <p>The RRF score for a document at rank <code>r</code> is: <code>1 / (k + r + 1)</code>, where <code>k</code> is the rank constant.</p> Note <p>This re-ranker is specifically designed for multi-vector scenarios where query results from multiple vector fields need to be combined.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of top documents to return. Defaults to 10.</p> <code>10</code> <code>Optional[str]</code> <p>Ignored by RRF. Defaults to None.</p> <code>None</code> <code>int</code> <p>Smoothing constant <code>k</code> in RRF formula. Larger values reduce the impact of early ranks. Defaults to 60.</p> <code>60</code> <p>Methods:</p> Name Description <code>rerank</code> <p>Apply Reciprocal Rank Fusion to combine multiple query results.</p> <p>Attributes:</p> Name Type Description <code>topn</code> <code>int</code> <p>int: Number of top documents to return after re-ranking.</p> <code>rerank_field</code> <code>Optional[str]</code> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.RrfReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.RrfReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.RrfReRanker(rank_constant)","title":"<code>rank_constant</code>","text":""},{"location":"extension/#zvec.extension.RrfReRanker-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.RrfReRanker.topn","title":"topn  <code>property</code>","text":"<pre><code>topn: int\n</code></pre> <p>int: Number of top documents to return after re-ranking.</p>"},{"location":"extension/#zvec.extension.RrfReRanker.rerank_field","title":"rerank_field  <code>property</code>","text":"<pre><code>rerank_field: Optional[str]\n</code></pre> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.RrfReRanker-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.RrfReRanker.rerank","title":"rerank","text":"<pre><code>rerank(query_results: dict[str, list[Doc]]) -&gt; list[Doc]\n</code></pre> <p>Apply Reciprocal Rank Fusion to combine multiple query results.</p> <p>Parameters:</p> Name Type Description Default <code>query_results</code> <code>dict[str, list[Doc]]</code> <p>Results from one or more vector queries.</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Re-ranked documents with RRF scores in the <code>score</code> field.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker","title":"WeightedReRanker","text":"<pre><code>WeightedReRanker(\n    topn: int = 10,\n    rerank_field: Optional[str] = None,\n    metric: MetricType = L2,\n    weights: Optional[dict[str, float]] = None,\n)\n</code></pre> <p>               Bases: <code>RerankFunction</code></p> <p>Re-ranker that combines scores from multiple vector fields using weights.</p> <p>Each vector field's relevance score is normalized based on its metric type, then scaled by a user-provided weight. Final scores are summed across fields.</p> Note <p>This re-ranker is specifically designed for multi-vector scenarios where query results from multiple vector fields need to be combined with configurable weights.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of top documents to return. Defaults to 10.</p> <code>10</code> <code>Optional[str]</code> <p>Ignored. Defaults to None.</p> <code>None</code> <code>MetricType</code> <p>Distance metric used for score normalization. Defaults to <code>MetricType.L2</code>.</p> <code>L2</code> <code>Optional[dict[str, float]]</code> <p>Weight per vector field. Fields not listed use weight 1.0. Defaults to None.</p> <code>None</code> Note <p>Supported metrics: L2, IP, COSINE. Scores are normalized to [0, 1].</p> <p>Methods:</p> Name Description <code>rerank</code> <p>Combine scores from multiple vector fields using weighted sum.</p> <p>Attributes:</p> Name Type Description <code>topn</code> <code>int</code> <p>int: Number of top documents to return after re-ranking.</p> <code>rerank_field</code> <code>Optional[str]</code> <p>Optional[str]: Field name used as re-ranking input.</p> <code>weights</code> <code>dict[str, float]</code> <p>dict[str, float]: Weight mapping for vector fields.</p> <code>metric</code> <code>MetricType</code> <p>MetricType: Distance metric used for score normalization.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.WeightedReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.WeightedReRanker(metric)","title":"<code>metric</code>","text":""},{"location":"extension/#zvec.extension.WeightedReRanker(weights)","title":"<code>weights</code>","text":""},{"location":"extension/#zvec.extension.WeightedReRanker-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.WeightedReRanker.topn","title":"topn  <code>property</code>","text":"<pre><code>topn: int\n</code></pre> <p>int: Number of top documents to return after re-ranking.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker.rerank_field","title":"rerank_field  <code>property</code>","text":"<pre><code>rerank_field: Optional[str]\n</code></pre> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker.weights","title":"weights  <code>property</code>","text":"<pre><code>weights: dict[str, float]\n</code></pre> <p>dict[str, float]: Weight mapping for vector fields.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker.metric","title":"metric  <code>property</code>","text":"<pre><code>metric: MetricType\n</code></pre> <p>MetricType: Distance metric used for score normalization.</p>"},{"location":"extension/#zvec.extension.WeightedReRanker-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.WeightedReRanker.rerank","title":"rerank","text":"<pre><code>rerank(query_results: dict[str, list[Doc]]) -&gt; list[Doc]\n</code></pre> <p>Combine scores from multiple vector fields using weighted sum.</p> <p>Parameters:</p> Name Type Description Default <code>query_results</code> <code>dict[str, list[Doc]]</code> <p>Results per vector field.</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Re-ranked documents with combined scores in <code>score</code> field.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding","title":"OpenAIDenseEmbedding","text":"<pre><code>OpenAIDenseEmbedding(\n    model: str = \"text-embedding-3-small\",\n    dimension: Optional[int] = None,\n    api_key: Optional[str] = None,\n    base_url: Optional[str] = None,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>OpenAIFunctionBase</code>, <code>DenseEmbeddingFunction[TEXT]</code></p> <p>Dense text embedding function using OpenAI API.</p> <p>This class provides text-to-vector embedding capabilities using OpenAI's embedding models. It inherits from <code>DenseEmbeddingFunction</code> and implements dense text embedding via the OpenAI API.</p> <p>The implementation supports various OpenAI embedding models with different dimensions and includes automatic result caching for improved performance.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>OpenAI embedding model identifier. Defaults to <code>\"text-embedding-3-small\"</code>. Common options: - <code>\"text-embedding-3-small\"</code>: 1536 dims, cost-efficient, good performance - <code>\"text-embedding-3-large\"</code>: 3072 dims, highest quality - <code>\"text-embedding-ada-002\"</code>: 1536 dims, legacy model</p> <code>'text-embedding-3-small'</code> <code>Optional[int]</code> <p>Desired output embedding dimension. If <code>None</code>, uses model's default dimension. For text-embedding-3 models, you can specify custom dimensions (e.g., 256, 512, 1024, 1536). Defaults to <code>None</code>.</p> <code>None</code> <code>Optional[str]</code> <p>OpenAI API authentication key. If <code>None</code>, reads from <code>OPENAI_API_KEY</code> environment variable. Obtain your key from: https://platform.openai.com/api-keys</p> <code>None</code> <code>Optional[str]</code> <p>Custom API base URL for OpenAI-compatible services. Defaults to <code>None</code> (uses official OpenAI endpoint).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>dimension</code> <code>int</code> <p>The embedding vector dimension.</p> <code>data_type</code> <code>DataType</code> <p>Always <code>DataType.VECTOR_FP32</code> for this implementation.</p> <code>model</code> <code>str</code> <p>The OpenAI model name being used.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not found in environment, or if API returns an error response.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If network error or OpenAI service error occurs.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>openai</code> package: <code>pip install openai</code></li> <li>Embedding results are cached (LRU cache, maxsize=10) to reduce API calls</li> <li>Network connectivity to OpenAI API endpoints is required</li> <li>API usage incurs costs based on your OpenAI subscription plan</li> <li>Rate limits apply based on your OpenAI account tier</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with default model\n&gt;&gt;&gt; from zvec.extension import OpenAIDenseEmbedding\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n&gt;&gt;&gt;\n&gt;&gt;&gt; emb_func = OpenAIDenseEmbedding()\n&gt;&gt;&gt; vector = emb_func.embed(\"Hello, world!\")\n&gt;&gt;&gt; len(vector)\n1536\n</code></pre> <pre><code>&gt;&gt;&gt; # Using specific model with custom dimension\n&gt;&gt;&gt; emb_func = OpenAIDenseEmbedding(\n...     model=\"text-embedding-3-large\",\n...     dimension=1024,\n...     api_key=\"sk-...\"\n... )\n&gt;&gt;&gt; vector = emb_func.embed(\"Machine learning is fascinating\")\n&gt;&gt;&gt; len(vector)\n1024\n</code></pre> <pre><code>&gt;&gt;&gt; # Using with custom base URL (e.g., Azure OpenAI)\n&gt;&gt;&gt; emb_func = OpenAIDenseEmbedding(\n...     model=\"text-embedding-ada-002\",\n...     api_key=\"your-azure-key\",\n...     base_url=\"https://your-resource.openai.azure.com/\"\n... )\n&gt;&gt;&gt; vector = emb_func(\"Natural language processing\")\n&gt;&gt;&gt; isinstance(vector, list)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Batch processing with caching benefit\n&gt;&gt;&gt; texts = [\"First text\", \"Second text\", \"First text\"]\n&gt;&gt;&gt; vectors = [emb_func.embed(text) for text in texts]\n&gt;&gt;&gt; # Third call uses cached result for \"First text\"\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     emb_func.embed(\"\")  # Empty string\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> See Also <ul> <li><code>DenseEmbeddingFunction</code>: Base class for dense embeddings</li> <li><code>QwenDenseEmbedding</code>: Alternative using Qwen/DashScope API</li> <li><code>DefaultDenseEmbedding</code>: Local model without API calls</li> <li><code>SparseEmbeddingFunction</code>: Base class for sparse embeddings</li> </ul> <p>Initialize the OpenAI dense embedding function.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>OpenAI model name. Defaults to \"text-embedding-3-small\".</p> <code>'text-embedding-3-small'</code> <code>Optional[int]</code> <p>Target embedding dimension or None for default.</p> <code>None</code> <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <code>Optional[str]</code> <p>Custom API base URL or None for default.</p> <code>None</code> <p>Additional parameters for API calls. Examples: - <code>encoding_format</code> (str): Format of embeddings, \"float\" or \"base64\". - <code>user</code> (str): User identifier for tracking.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not in environment.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate dense embedding vector for the input text.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(base_url)","title":"<code>base_url</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(base_url)","title":"<code>base_url</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The OpenAI model name currently in use.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding.dimension","title":"dimension  <code>property</code>","text":"<pre><code>dimension: int\n</code></pre> <p>int: The expected dimensionality of the embedding vector.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for model-specific customization.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding.__call__","title":"__call__","text":"<pre><code>__call__(input: TEXT) -&gt; DenseVectorType\n</code></pre> <p>Make the embedding function callable.</p>"},{"location":"extension/#zvec.extension.OpenAIDenseEmbedding.embed","title":"embed  <code>cached</code>","text":"<pre><code>embed(input: TEXT) -&gt; DenseVectorType\n</code></pre> <p>Generate dense embedding vector for the input text.</p> <p>This method calls the OpenAI Embeddings API to convert input text into a dense vector representation. Results are cached to improve performance for repeated inputs.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>TEXT</code> <p>Input text string to embed. Must be non-empty after stripping whitespace. Maximum length is 8191 tokens for most models.</p> required <p>Returns:</p> Name Type Description <code>DenseVectorType</code> <code>DenseVectorType</code> <p>A list of floats representing the embedding vector. Length equals <code>self.dimension</code>. Example: <code>[0.123, -0.456, 0.789, ...]</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty/whitespace-only, or if the API returns an error or malformed response.</p> <code>RuntimeError</code> <p>If network connectivity issues or OpenAI service errors occur.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; emb = OpenAIDenseEmbedding()\n&gt;&gt;&gt; vector = emb.embed(\"Natural language processing\")\n&gt;&gt;&gt; len(vector)\n1536\n&gt;&gt;&gt; isinstance(vector[0], float)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: empty input\n&gt;&gt;&gt; emb.embed(\"   \")\nValueError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: non-string input\n&gt;&gt;&gt; emb.embed(123)\nTypeError: Expected 'input' to be str, got int\n</code></pre> Note <ul> <li>This method is cached (maxsize=10). Identical inputs return cached results.</li> <li>The cache is based on exact string match (case-sensitive).</li> <li>Consider pre-processing text (lowercasing, normalization) for better caching.</li> </ul>"},{"location":"extension/#zvec.extension.OpenAIFunctionBase","title":"OpenAIFunctionBase","text":"<pre><code>OpenAIFunctionBase(model: str, api_key: Optional[str] = None, base_url: Optional[str] = None)\n</code></pre> <p>Base class for OpenAI functions.</p> <p>This base class provides common functionality for calling OpenAI APIs and handling responses. It supports embeddings (dense) operations.</p> <p>This class is not meant to be used directly. Use concrete implementations: - <code>OpenAIDenseEmbedding</code> for dense embeddings</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>OpenAI model identifier.</p> required <code>Optional[str]</code> <p>OpenAI API authentication key.</p> <code>None</code> <code>Optional[str]</code> <p>Custom API base URL.</p> <code>None</code> Note <ul> <li>This is an internal base class for code reuse across OpenAI features</li> <li>Subclasses should inherit from appropriate Protocol</li> <li>Provides unified API connection and response handling</li> </ul> <p>Initialize the base OpenAI functionality.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>OpenAI model name.</p> required <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <code>Optional[str]</code> <p>Custom API base URL or None for default.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not in environment.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>str: The OpenAI model name currently in use.</p>"},{"location":"extension/#zvec.extension.OpenAIFunctionBase(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase(base_url)","title":"<code>base_url</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase(base_url)","title":"<code>base_url</code>","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.OpenAIFunctionBase.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The OpenAI model name currently in use.</p>"},{"location":"extension/#zvec.extension.OpenAIFunctionBase-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding","title":"QwenDenseEmbedding","text":"<pre><code>QwenDenseEmbedding(\n    dimension: int, model: str = \"text-embedding-v4\", api_key: Optional[str] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>QwenFunctionBase</code>, <code>DenseEmbeddingFunction[TEXT]</code></p> <p>Dense text embedding function using Qwen (DashScope) API.</p> <p>This class provides text-to-vector embedding capabilities using Alibaba Cloud's DashScope service and Qwen embedding models. It inherits from <code>DenseEmbeddingFunction</code> and implements dense text embedding.</p> <p>The implementation supports various Qwen embedding models with configurable dimensions and includes automatic result caching for improved performance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Desired output embedding dimension. Common values: - 512: Balanced performance and accuracy - 1024: Higher accuracy, larger storage - 1536: Maximum accuracy for supported models</p> required <code>str</code> <p>DashScope embedding model identifier. Defaults to <code>\"text-embedding-v4\"</code>. Other options include: - <code>\"text-embedding-v3\"</code> - <code>\"text-embedding-v2\"</code> - <code>\"text-embedding-v1\"</code></p> <code>'text-embedding-v4'</code> <code>Optional[str]</code> <p>DashScope API authentication key. If <code>None</code>, reads from <code>DASHSCOPE_API_KEY</code> environment variable. Obtain your key from: https://dashscope.console.aliyun.com/</p> <code>None</code> <p>Additional DashScope API parameters. Supported options: - <code>text_type</code> (str): Specifies the text role in retrieval tasks.   Options: <code>\"query\"</code> (search query) or <code>\"document\"</code> (indexed content).   This parameter optimizes embeddings for asymmetric search scenarios.</p> <p>Reference: https://help.aliyun.com/zh/model-studio/text-embedding-synchronous-api</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>dimension</code> <code>int</code> <p>The embedding vector dimension.</p> <code>data_type</code> <code>DataType</code> <p>Always <code>DataType.VECTOR_FP32</code> for this implementation.</p> <code>model</code> <code>str</code> <p>The DashScope model name being used.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not found in environment, or if API returns an error response.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If network error or DashScope service error occurs.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>dashscope</code> package: <code>pip install dashscope</code></li> <li>Embedding results are cached (LRU cache, maxsize=10) to reduce API calls</li> <li>Network connectivity to DashScope API endpoints is required</li> <li>API usage may incur costs based on your DashScope subscription plan</li> </ul> <p>Parameter Guidelines:</p> <ul> <li>Use <code>text_type=\"query\"</code> for search queries and <code>text_type=\"document\"</code>   for indexed content to optimize asymmetric retrieval tasks.</li> <li>For detailed API specifications and parameter usage, refer to:   https://help.aliyun.com/zh/model-studio/text-embedding-synchronous-api</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with default model\n&gt;&gt;&gt; from zvec.extension import QwenDenseEmbedding\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.environ[\"DASHSCOPE_API_KEY\"] = \"your-api-key\"\n&gt;&gt;&gt;\n&gt;&gt;&gt; emb_func = QwenDenseEmbedding(dimension=1024)\n&gt;&gt;&gt; vector = emb_func.embed(\"Hello, world!\")\n&gt;&gt;&gt; len(vector)\n1024\n</code></pre> <pre><code>&gt;&gt;&gt; # Using specific model with explicit API key\n&gt;&gt;&gt; emb_func = QwenDenseEmbedding(\n...     dimension=512,\n...     model=\"text-embedding-v3\",\n...     api_key=\"sk-xxxxx\"\n... )\n&gt;&gt;&gt; vector = emb_func(\"Machine learning is fascinating\")\n&gt;&gt;&gt; isinstance(vector, list)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Using with custom parameters (text_type)\n&gt;&gt;&gt; # For search queries - optimize for query-document matching\n&gt;&gt;&gt; emb_func = QwenDenseEmbedding(\n...     dimension=1024,\n...     text_type=\"query\"\n... )\n&gt;&gt;&gt; query_vector = emb_func.embed(\"What is machine learning?\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # For document embeddings - optimize for being matched by queries\n&gt;&gt;&gt; doc_emb_func = QwenDenseEmbedding(\n...     dimension=1024,\n...     text_type=\"document\"\n... )\n&gt;&gt;&gt; doc_vector = doc_emb_func.embed(\n...     \"Machine learning is a subset of artificial intelligence...\"\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Batch processing with caching benefit\n&gt;&gt;&gt; texts = [\"First text\", \"Second text\", \"First text\"]\n&gt;&gt;&gt; vectors = [emb_func.embed(text) for text in texts]\n&gt;&gt;&gt; # Third call uses cached result for \"First text\"\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     emb_func.embed(\"\")  # Empty string\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> See Also <ul> <li><code>DenseEmbeddingFunction</code>: Base class for dense embeddings</li> <li><code>SparseEmbeddingFunction</code>: Base class for sparse embeddings</li> </ul> <p>Initialize the Qwen dense embedding function.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Target embedding dimension.</p> required <code>str</code> <p>DashScope model name. Defaults to \"text-embedding-v4\".</p> <code>'text-embedding-v4'</code> <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <p>Additional DashScope API parameters. Supported options: - <code>text_type</code> (str): Text role in asymmetric retrieval.   * <code>\"query\"</code>: Optimize for search queries (short, question-like).   * <code>\"document\"</code>: Optimize for indexed documents (longer content).   Using appropriate text_type improves retrieval accuracy by   optimizing the embedding space for query-document matching.</p> <p>For detailed API documentation, see: https://help.aliyun.com/zh/model-studio/text-embedding-synchronous-api</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not in environment.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate dense embedding vector for the input text.</p>"},{"location":"extension/#zvec.extension.QwenDenseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The DashScope embedding model name currently in use.</p>"},{"location":"extension/#zvec.extension.QwenDenseEmbedding.dimension","title":"dimension  <code>property</code>","text":"<pre><code>dimension: int\n</code></pre> <p>int: The expected dimensionality of the embedding vector.</p>"},{"location":"extension/#zvec.extension.QwenDenseEmbedding.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for model-specific customization.</p>"},{"location":"extension/#zvec.extension.QwenDenseEmbedding-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.QwenDenseEmbedding.__call__","title":"__call__","text":"<pre><code>__call__(input: TEXT) -&gt; DenseVectorType\n</code></pre> <p>Make the embedding function callable.</p>"},{"location":"extension/#zvec.extension.QwenDenseEmbedding.embed","title":"embed  <code>cached</code>","text":"<pre><code>embed(input: TEXT) -&gt; DenseVectorType\n</code></pre> <p>Generate dense embedding vector for the input text.</p> <p>This method calls the DashScope TextEmbedding API to convert input text into a dense vector representation. Results are cached to improve performance for repeated inputs.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>TEXT</code> <p>Input text string to embed. Must be non-empty after stripping whitespace. Maximum length depends on the model used (typically 2048-8192 tokens).</p> required <p>Returns:</p> Name Type Description <code>DenseVectorType</code> <code>DenseVectorType</code> <p>A list of floats representing the embedding vector. Length equals <code>self.dimension</code>. Example: <code>[0.123, -0.456, 0.789, ...]</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty/whitespace-only, or if the API returns an error or malformed response.</p> <code>RuntimeError</code> <p>If network connectivity issues or DashScope service errors occur.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; emb = QwenDenseEmbedding(dimension=1024)\n&gt;&gt;&gt; vector = emb.embed(\"Natural language processing\")\n&gt;&gt;&gt; len(vector)\n1024\n&gt;&gt;&gt; isinstance(vector[0], float)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: empty input\n&gt;&gt;&gt; emb.embed(\"   \")\nValueError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: non-string input\n&gt;&gt;&gt; emb.embed(123)\nTypeError: Expected 'input' to be str, got int\n</code></pre> Note <ul> <li>This method is cached (maxsize=10). Identical inputs return cached results.</li> <li>The cache is based on exact string match (case-sensitive).</li> <li>Consider pre-processing text (lowercasing, normalization) for better caching.</li> </ul>"},{"location":"extension/#zvec.extension.QwenSparseEmbedding","title":"QwenSparseEmbedding","text":"<pre><code>QwenSparseEmbedding(\n    dimension: int, model: str = \"text-embedding-v4\", api_key: Optional[str] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>QwenFunctionBase</code>, <code>SparseEmbeddingFunction[TEXT]</code></p> <p>Sparse text embedding function using Qwen (DashScope) API.</p> <p>This class provides text-to-sparse-vector embedding capabilities using Alibaba Cloud's DashScope service and Qwen embedding models. It generates sparse keyword-weighted vectors suitable for lexical matching and BM25-style retrieval scenarios.</p> <p>Sparse embeddings are particularly useful for: - Keyword-based search and exact matching - Hybrid retrieval (combining with dense embeddings) - Interpretable search results (weights show term importance)</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Desired output embedding dimension. Common values: - 512: Balanced performance and accuracy - 1024: Higher accuracy, larger storage - 1536: Maximum accuracy for supported models</p> required <code>str</code> <p>DashScope embedding model identifier. Defaults to <code>\"text-embedding-v4\"</code>. Other options include: - <code>\"text-embedding-v3\"</code> - <code>\"text-embedding-v2\"</code></p> <code>'text-embedding-v4'</code> <code>Optional[str]</code> <p>DashScope API authentication key. If <code>None</code>, reads from <code>DASHSCOPE_API_KEY</code> environment variable. Obtain your key from: https://dashscope.console.aliyun.com/</p> <code>None</code> <p>Additional DashScope API parameters. Supported options: - <code>encoding_type</code> (Literal[\"query\", \"document\"]): Encoding type.   * <code>\"query\"</code>: Optimize for search queries (default).   * <code>\"document\"</code>: Optimize for indexed documents.   This distinction is important for asymmetric retrieval tasks.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>The DashScope model name being used.</p> <code>encoding_type</code> <code>str</code> <p>The encoding type (\"query\" or \"document\").</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not found in environment, or if API returns an error response.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If network error or DashScope service error occurs.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>dashscope</code> package: <code>pip install dashscope</code></li> <li>Embedding results are cached (LRU cache, maxsize=10) to reduce API calls</li> <li>Network connectivity to DashScope API endpoints is required</li> <li>API usage may incur costs based on your DashScope subscription plan</li> <li>Sparse vectors have only non-zero dimensions stored as dict</li> <li>Output is sorted by indices (keys) in ascending order</li> </ul> <p>Parameter Guidelines:</p> <ul> <li>Use <code>encoding_type=\"query\"</code> for search queries and   <code>encoding_type=\"document\"</code> for indexed content to optimize   asymmetric retrieval tasks.</li> <li>For detailed API specifications, refer to:   https://help.aliyun.com/zh/model-studio/text-embedding-synchronous-api</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage for query embedding\n&gt;&gt;&gt; from zvec.extension import QwenSparseEmbedding\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.environ[\"DASHSCOPE_API_KEY\"] = \"your-api-key\"\n&gt;&gt;&gt;\n&gt;&gt;&gt; query_emb = QwenSparseEmbedding(dimension=1024, encoding_type=\"query\")\n&gt;&gt;&gt; query_vec = query_emb.embed(\"machine learning\")\n&gt;&gt;&gt; type(query_vec)\n&lt;class 'dict'&gt;\n&gt;&gt;&gt; len(query_vec)  # Only non-zero dimensions\n156\n</code></pre> <pre><code>&gt;&gt;&gt; # Document embedding\n&gt;&gt;&gt; doc_emb = QwenSparseEmbedding(dimension=1024, encoding_type=\"document\")\n&gt;&gt;&gt; doc_vec = doc_emb.embed(\"Machine learning is a subset of AI\")\n&gt;&gt;&gt; isinstance(doc_vec, dict)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Asymmetric retrieval example\n&gt;&gt;&gt; query_vec = query_emb.embed(\"what causes aging fast\")\n&gt;&gt;&gt; doc_vec = doc_emb.embed(\n...     \"UV-A light causes tanning, skin aging, and cataracts...\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Calculate similarity (dot product for sparse vectors)\n&gt;&gt;&gt; similarity = sum(\n...     query_vec.get(k, 0) * doc_vec.get(k, 0)\n...     for k in set(query_vec) | set(doc_vec)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Output is sorted by indices\n&gt;&gt;&gt; list(query_vec.items())[:5]  # First 5 dimensions (by index)\n[(10, 0.45), (23, 0.87), (56, 0.32), (89, 1.12), (120, 0.65)]\n</code></pre> <pre><code>&gt;&gt;&gt; # Hybrid retrieval (combining dense + sparse)\n&gt;&gt;&gt; from zvec.extension import QwenDenseEmbedding\n&gt;&gt;&gt; dense_emb = QwenDenseEmbedding(dimension=1024)\n&gt;&gt;&gt; sparse_emb = QwenSparseEmbedding(dimension=1024)\n&gt;&gt;&gt;\n&gt;&gt;&gt; query = \"deep learning neural networks\"\n&gt;&gt;&gt; dense_vec = dense_emb.embed(query)   # [0.1, -0.3, 0.5, ...]\n&gt;&gt;&gt; sparse_vec = sparse_emb.embed(query)  # {12: 0.8, 45: 1.2, ...}\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     sparse_emb.embed(\"\")  # Empty string\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> See Also <ul> <li><code>SparseEmbeddingFunction</code>: Base class for sparse embeddings</li> <li><code>QwenDenseEmbedding</code>: Dense embedding using Qwen API</li> <li><code>DefaultSparseEmbedding</code>: Sparse embedding with SPLADE model</li> </ul> <p>Initialize the Qwen sparse embedding function.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Target embedding dimension.</p> required <code>str</code> <p>DashScope model name. Defaults to \"text-embedding-v4\".</p> <code>'text-embedding-v4'</code> <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <p>Additional DashScope API parameters. Supported options: - <code>encoding_type</code> (Literal[\"query\", \"document\"]): Encoding type.   * <code>\"query\"</code>: Optimize for search queries (default).   * <code>\"document\"</code>: Optimize for indexed documents.   This distinction is important for asymmetric retrieval tasks.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not in environment.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate sparse embedding vector for the input text.</p>"},{"location":"extension/#zvec.extension.QwenSparseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(dimension)","title":"<code>dimension</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The DashScope embedding model name currently in use.</p>"},{"location":"extension/#zvec.extension.QwenSparseEmbedding.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for model-specific customization.</p>"},{"location":"extension/#zvec.extension.QwenSparseEmbedding-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.QwenSparseEmbedding.__call__","title":"__call__","text":"<pre><code>__call__(input: TEXT) -&gt; SparseVectorType\n</code></pre> <p>Make the embedding function callable.</p>"},{"location":"extension/#zvec.extension.QwenSparseEmbedding.embed","title":"embed  <code>cached</code>","text":"<pre><code>embed(input: TEXT) -&gt; SparseVectorType\n</code></pre> <p>Generate sparse embedding vector for the input text.</p> <p>This method calls the DashScope TextEmbedding API with sparse output type to convert input text into a sparse vector representation. The result is a dictionary where keys are dimension indices and values are importance weights (only non-zero values included).</p> <p>The embedding is optimized based on the <code>encoding_type</code> specified during initialization: \"query\" for search queries or \"document\" for indexed content.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>TEXT</code> <p>Input text string to embed. Must be non-empty after stripping whitespace. Maximum length depends on the model used (typically 2048-8192 tokens).</p> required <p>Returns:</p> Name Type Description <code>SparseVectorType</code> <code>SparseVectorType</code> <p>A dictionary mapping dimension index to weight. Only non-zero dimensions are included. The dictionary is sorted by indices (keys) in ascending order for consistent output. Example: <code>{10: 0.5, 245: 0.8, 1023: 1.2, 5678: 0.5}</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty/whitespace-only, or if the API returns an error or malformed response.</p> <code>RuntimeError</code> <p>If network connectivity issues or DashScope service errors occur.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; emb = QwenSparseEmbedding(dimension=1024, encoding_type=\"query\")\n&gt;&gt;&gt; sparse_vec = emb.embed(\"machine learning\")\n&gt;&gt;&gt; isinstance(sparse_vec, dict)\nTrue\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Verify sorted output\n&gt;&gt;&gt; keys = list(sparse_vec.keys())\n&gt;&gt;&gt; keys == sorted(keys)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: empty input\n&gt;&gt;&gt; emb.embed(\"   \")\nValueError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: non-string input\n&gt;&gt;&gt; emb.embed(123)\nTypeError: Expected 'input' to be str, got int\n</code></pre> Note <ul> <li>This method is cached (maxsize=10). Identical inputs return cached results.</li> <li>The cache is based on exact string match (case-sensitive).</li> <li>Output dictionary is always sorted by indices for consistency.</li> </ul>"},{"location":"extension/#zvec.extension.QwenFunctionBase","title":"QwenFunctionBase","text":"<pre><code>QwenFunctionBase(model: str, api_key: Optional[str] = None)\n</code></pre> <p>Base class for Qwen (DashScope) functions.</p> <p>This base class provides common functionality for calling DashScope APIs and handling responses. It supports embeddings (dense and sparse) and re-ranking operations.</p> <p>This class is not meant to be used directly. Use concrete implementations: - <code>QwenDenseEmbedding</code> for dense embeddings - <code>QwenSparseEmbedding</code> for sparse embeddings - <code>QwenReRanker</code> for semantic re-ranking</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>DashScope model identifier.</p> required <code>Optional[str]</code> <p>DashScope API authentication key.</p> <code>None</code> Note <ul> <li>This is an internal base class for code reuse across Qwen features</li> <li>Subclasses should inherit from appropriate Protocol/ABC</li> <li>Provides unified API connection and response handling</li> </ul> <p>Initialize the base Qwen embedding functionality.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>DashScope model name.</p> required <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If API key is not provided and not in environment.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>str: The DashScope embedding model name currently in use.</p>"},{"location":"extension/#zvec.extension.QwenFunctionBase(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenFunctionBase(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenFunctionBase(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenFunctionBase(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenFunctionBase-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.QwenFunctionBase.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The DashScope embedding model name currently in use.</p>"},{"location":"extension/#zvec.extension.QwenFunctionBase-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.QwenReRanker","title":"QwenReRanker","text":"<pre><code>QwenReRanker(\n    query: Optional[str] = None,\n    topn: int = 10,\n    rerank_field: Optional[str] = None,\n    model: str = \"gte-rerank-v2\",\n    api_key: Optional[str] = None,\n)\n</code></pre> <p>               Bases: <code>QwenFunctionBase</code>, <code>RerankFunction</code></p> <p>Re-ranker using Qwen (DashScope) cross-encoder API for semantic re-ranking.</p> <p>This re-ranker leverages DashScope's TextReRank service to perform cross-encoder style re-ranking. It sends query and document pairs to the API and receives relevance scores based on deep semantic understanding.</p> <p>The re-ranker is suitable for single-vector or multi-vector search scenarios where semantic relevance to a specific query is required.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Query text for semantic re-ranking. Required.</p> <code>None</code> <code>int</code> <p>Maximum number of documents to return after re-ranking. Defaults to 10.</p> <code>10</code> <code>str</code> <p>Document field name to use as re-ranking input text. Required (e.g., \"content\", \"title\", \"body\").</p> <code>None</code> <code>str</code> <p>DashScope re-ranking model identifier. Defaults to <code>\"gte-rerank-v2\"</code>.</p> <code>'gte-rerank-v2'</code> <code>Optional[str]</code> <p>DashScope API authentication key. If not provided, reads from <code>DASHSCOPE_API_KEY</code> environment variable.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>query</code> is empty/None, <code>rerank_field</code> is None, or API key is not available.</p> Note <ul> <li>Requires <code>dashscope</code> Python package installed</li> <li>Documents without valid content in <code>rerank_field</code> are skipped</li> <li>API rate limits and quotas apply per DashScope subscription</li> </ul> Example <p>reranker = QwenReRanker( ...     query=\"machine learning algorithms\", ...     topn=5, ...     rerank_field=\"content\", ...     model=\"gte-rerank-v2\", ...     api_key=\"your-api-key\" ... )</p> <p>Initialize QwenReRanker with query and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[str]</code> <p>Query text for semantic matching. Required.</p> <code>None</code> <code>int</code> <p>Number of top results to return.</p> <code>10</code> <code>Optional[str]</code> <p>Document field for re-ranking input.</p> <code>None</code> <code>str</code> <p>DashScope model name.</p> <code>'gte-rerank-v2'</code> <code>Optional[str]</code> <p>API key or None to use environment variable.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty or API key is unavailable.</p> <p>Methods:</p> Name Description <code>rerank</code> <p>Re-rank documents using Qwen's TextReRank API.</p> <p>Attributes:</p> Name Type Description <code>topn</code> <code>int</code> <p>int: Number of top documents to return after re-ranking.</p> <code>rerank_field</code> <code>Optional[str]</code> <p>Optional[str]: Field name used as re-ranking input.</p> <code>model</code> <code>str</code> <p>str: The DashScope embedding model name currently in use.</p> <code>query</code> <code>str</code> <p>str: Query text used for semantic re-ranking.</p>"},{"location":"extension/#zvec.extension.QwenReRanker(query)","title":"<code>query</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker--use-in-collectionqueryrerankerreranker","title":"Use in collection.query(reranker=reranker)","text":""},{"location":"extension/#zvec.extension.QwenReRanker(query)","title":"<code>query</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(model)","title":"<code>model</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker(api_key)","title":"<code>api_key</code>","text":""},{"location":"extension/#zvec.extension.QwenReRanker-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.QwenReRanker.topn","title":"topn  <code>property</code>","text":"<pre><code>topn: int\n</code></pre> <p>int: Number of top documents to return after re-ranking.</p>"},{"location":"extension/#zvec.extension.QwenReRanker.rerank_field","title":"rerank_field  <code>property</code>","text":"<pre><code>rerank_field: Optional[str]\n</code></pre> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.QwenReRanker.model","title":"model  <code>property</code>","text":"<pre><code>model: str\n</code></pre> <p>str: The DashScope embedding model name currently in use.</p>"},{"location":"extension/#zvec.extension.QwenReRanker.query","title":"query  <code>property</code>","text":"<pre><code>query: str\n</code></pre> <p>str: Query text used for semantic re-ranking.</p>"},{"location":"extension/#zvec.extension.QwenReRanker-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.QwenReRanker.rerank","title":"rerank","text":"<pre><code>rerank(query_results: dict[str, list[Doc]]) -&gt; list[Doc]\n</code></pre> <p>Re-rank documents using Qwen's TextReRank API.</p> <p>Sends document texts to DashScope TextReRank service along with the query. Returns documents sorted by relevance scores from the cross-encoder model.</p> <p>Parameters:</p> Name Type Description Default <code>query_results</code> <code>dict[str, list[Doc]]</code> <p>Mapping from vector field names to lists of retrieved documents. Documents from all fields are deduplicated and re-ranked together.</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Re-ranked documents (up to <code>topn</code>) with updated <code>score</code> fields containing relevance scores from the API.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no valid documents are found or API call fails.</p> Note <ul> <li>Duplicate documents (same ID) across fields are processed once</li> <li>Documents with empty/missing <code>rerank_field</code> content are skipped</li> <li>Returned scores are relevance scores from the cross-encoder model</li> </ul>"},{"location":"extension/#zvec.extension.ReRanker","title":"ReRanker","text":"<pre><code>ReRanker(topn: int = 10, rerank_field: Optional[str] = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for re-ranking search results.</p> <p>Re-rankers refine the output of one or more vector queries by applying a secondary scoring strategy. They are used in the <code>query()</code> method of <code>Collection</code> via the <code>reranker</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of top documents to return after re-ranking. Defaults to 10.</p> <code>10</code> <code>Optional[str]</code> <p>Field name used as input for re-ranking (e.g., document title or body). Defaults to None.</p> <code>None</code> Note <p>Subclasses must implement the <code>rerank()</code> method.</p> <p>Methods:</p> Name Description <code>rerank</code> <p>Re-rank documents from one or more vector queries.</p> <p>Attributes:</p> Name Type Description <code>topn</code> <code>int</code> <p>int: Number of top documents to return after re-ranking.</p> <code>rerank_field</code> <code>Optional[str]</code> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.ReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.ReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.ReRanker-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.ReRanker.topn","title":"topn  <code>property</code>","text":"<pre><code>topn: int\n</code></pre> <p>int: Number of top documents to return after re-ranking.</p>"},{"location":"extension/#zvec.extension.ReRanker.rerank_field","title":"rerank_field  <code>property</code>","text":"<pre><code>rerank_field: Optional[str]\n</code></pre> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.ReRanker-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.ReRanker.rerank","title":"rerank  <code>abstractmethod</code>","text":"<pre><code>rerank(query_results: dict[str, list[Doc]]) -&gt; list[Doc]\n</code></pre> <p>Re-rank documents from one or more vector queries.</p> <p>Parameters:</p> Name Type Description Default <code>query_results</code> <code>dict[str, list[Doc]]</code> <p>Mapping from vector field name to list of retrieved documents (sorted by relevance).</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Re-ranked list of documents (length \u2264 <code>topn</code>), with updated <code>score</code> fields.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding","title":"DefaultLocalDenseEmbedding","text":"<pre><code>DefaultLocalDenseEmbedding(\n    model_source: Literal[\"huggingface\", \"modelscope\"] = \"huggingface\",\n    device: Optional[str] = None,\n    normalize_embeddings: bool = True,\n    batch_size: int = 32,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SentenceTransformerFunctionBase</code>, <code>DenseEmbeddingFunction[TEXT]</code></p> <p>Default local dense embedding using all-MiniLM-L6-v2 model.</p> <p>This is the default implementation for dense text embedding that uses the <code>all-MiniLM-L6-v2</code> model from Hugging Face by default. This model provides a good balance between speed and quality for general-purpose text embedding.</p> <p>The class provides text-to-vector dense embedding capabilities using the sentence-transformers library. It supports models from Hugging Face Hub and ModelScope, runs locally without API calls, and supports CPU/GPU acceleration.</p> <p>The model produces 384-dimensional embeddings and is optimized for semantic similarity tasks. It runs locally without requiring API keys.</p> <p>Parameters:</p> Name Type Description Default <code>Literal['huggingface', 'modelscope']</code> <p>Model source. - <code>\"huggingface\"</code>: Use Hugging Face Hub (default, for international users) - <code>\"modelscope\"</code>: Use ModelScope (recommended for users in China) Defaults to <code>\"huggingface\"</code>.</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Device to run the model on. Options: <code>\"cpu\"</code>, <code>\"cuda\"</code>, <code>\"mps\"</code> (for Apple Silicon), or <code>None</code> for automatic detection. Defaults to <code>None</code>.</p> <code>None</code> <code>bool</code> <p>Whether to normalize embeddings to unit length (L2 normalization). Useful for cosine similarity. Defaults to <code>True</code>.</p> <code>True</code> <code>int</code> <p>Batch size for encoding. Defaults to <code>32</code>.</p> <code>32</code> <p>Additional parameters for future extension.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>dimension</code> <code>int</code> <p>Always 384 for both models.</p> <code>model_name</code> <code>str</code> <p>\"all-MiniLM-L6-v2\" (HF) or \"iic/nlp_gte_sentence-embedding_chinese-small\" (MS).</p> <code>model_source</code> <code>str</code> <p>The model source being used.</p> <code>device</code> <code>str</code> <p>The device the model is running on.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model cannot be loaded or input is invalid.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If model inference fails.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>sentence-transformers</code> package:   <code>pip install sentence-transformers</code></li> <li>For ModelScope, also requires: <code>pip install modelscope</code></li> <li>First run downloads the model (~50-80MB) from chosen source</li> <li>Hugging Face cache: <code>~/.cache/torch/sentence_transformers/</code></li> <li>ModelScope cache: <code>~/.cache/modelscope/hub/</code></li> <li>No API keys or network required after initial download</li> <li>Inference speed: ~1000 sentences/sec on CPU, ~10000 on GPU</li> </ul> <p>For users in China:</p> <p>If you encounter Hugging Face access issues, use ModelScope instead:</p> <p>.. code-block:: python</p> <pre><code># Recommended for users in China\nemb = DefaultLocalDenseEmbedding(model_source=\"modelscope\")\n</code></pre> <p>Alternatively, use Hugging Face mirror:</p> <p>.. code-block:: bash</p> <pre><code>export HF_ENDPOINT=https://hf-mirror.com\n# Then use default Hugging Face mode\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with Hugging Face (default)\n&gt;&gt;&gt; from zvec.extension import DefaultLocalDenseEmbedding\n&gt;&gt;&gt;\n&gt;&gt;&gt; emb_func = DefaultLocalDenseEmbedding()\n&gt;&gt;&gt; vector = emb_func.embed(\"Hello, world!\")\n&gt;&gt;&gt; len(vector)\n384\n&gt;&gt;&gt; isinstance(vector, list)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Recommended for users in China (uses ModelScope)\n&gt;&gt;&gt; emb_func = DefaultLocalDenseEmbedding(model_source=\"modelscope\")\n&gt;&gt;&gt; vector = emb_func.embed(\"\u4f60\u597d\uff0c\u4e16\u754c\uff01\")  # Works well with Chinese text\n&gt;&gt;&gt; len(vector)\n384\n</code></pre> <pre><code>&gt;&gt;&gt; # Alternative for China users: Use Hugging Face mirror\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n&gt;&gt;&gt; emb_func = DefaultLocalDenseEmbedding()  # Uses HF mirror\n&gt;&gt;&gt; vector = emb_func.embed(\"Hello, world!\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Using GPU for faster inference\n&gt;&gt;&gt; emb_func = DefaultLocalDenseEmbedding(device=\"cuda\")\n&gt;&gt;&gt; vector = emb_func(\"Machine learning is fascinating\")\n&gt;&gt;&gt; # Normalized vector has unit length\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.linalg.norm(vector)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; # Batch processing\n&gt;&gt;&gt; texts = [\"First text\", \"Second text\", \"Third text\"]\n&gt;&gt;&gt; vectors = [emb_func.embed(text) for text in texts]\n&gt;&gt;&gt; len(vectors)\n3\n&gt;&gt;&gt; all(len(v) == 384 for v in vectors)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Semantic similarity\n&gt;&gt;&gt; v1 = emb_func.embed(\"The cat sits on the mat\")\n&gt;&gt;&gt; v2 = emb_func.embed(\"A feline rests on a rug\")\n&gt;&gt;&gt; v3 = emb_func.embed(\"Python programming\")\n&gt;&gt;&gt; similarity_high = np.dot(v1, v2)  # Similar sentences\n&gt;&gt;&gt; similarity_low = np.dot(v1, v3)   # Different topics\n&gt;&gt;&gt; similarity_high &gt; similarity_low\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     emb_func.embed(\"\")  # Empty string\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> See Also <ul> <li><code>DenseEmbeddingFunction</code>: Base class for dense embeddings</li> <li><code>DefaultLocalSparseEmbedding</code>: Sparse embedding with SPLADE</li> <li><code>QwenDenseEmbedding</code>: Alternative using Qwen API</li> </ul> <p>Initialize with all-MiniLM-L6-v2 model.</p> <p>Parameters:</p> Name Type Description Default <code>Literal['huggingface', 'modelscope']</code> <p>Model source. Defaults to \"huggingface\".</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Target device (\"cpu\", \"cuda\", \"mps\", or None). Defaults to None (automatic detection).</p> <code>None</code> <code>bool</code> <p>Whether to L2-normalize output vectors. Defaults to True.</p> <code>True</code> <code>int</code> <p>Batch size for encoding. Defaults to 32.</p> <code>32</code> <p>Additional parameters for future extension.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If sentence-transformers or modelscope is not installed.</p> <code>ValueError</code> <p>If model cannot be loaded.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate dense embedding vector for the input text.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(normalize_embeddings)","title":"<code>normalize_embeddings</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(batch_size)","title":"<code>batch_size</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(normalize_embeddings)","title":"<code>normalize_embeddings</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(batch_size)","title":"<code>batch_size</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.model_name","title":"model_name  <code>property</code>","text":"<pre><code>model_name: str\n</code></pre> <p>str: The Sentence Transformer model name currently in use.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.model_source","title":"model_source  <code>property</code>","text":"<pre><code>model_source: str\n</code></pre> <p>str: The model source being used (\"huggingface\" or \"modelscope\").</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.device","title":"device  <code>property</code>","text":"<pre><code>device: str\n</code></pre> <p>str: The device the model is running on.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.dimension","title":"dimension  <code>property</code>","text":"<pre><code>dimension: int\n</code></pre> <p>int: The expected dimensionality of the embedding vector.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for model-specific customization.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.__call__","title":"__call__","text":"<pre><code>__call__(input: str) -&gt; DenseVectorType\n</code></pre> <p>Make the embedding function callable.</p>"},{"location":"extension/#zvec.extension.DefaultLocalDenseEmbedding.embed","title":"embed","text":"<pre><code>embed(input: str) -&gt; DenseVectorType\n</code></pre> <p>Generate dense embedding vector for the input text.</p> <p>This method uses the Sentence Transformer model to convert input text into a dense vector representation. The model runs locally without requiring API calls.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>Input text string to embed. Must be non-empty after stripping whitespace. Maximum length depends on the model used (typically 128-512 tokens for most models).</p> required <p>Returns:</p> Name Type Description <code>DenseVectorType</code> <code>DenseVectorType</code> <p>A list of floats representing the embedding vector. Length equals <code>self.dimension</code>. If <code>normalize_embeddings=True</code>, the vector has unit length. Example: <code>[0.123, -0.456, 0.789, ...]</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty or whitespace-only.</p> <code>RuntimeError</code> <p>If model inference fails.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; emb = DefaultLocalDenseEmbedding()\n&gt;&gt;&gt; vector = emb.embed(\"Natural language processing\")\n&gt;&gt;&gt; len(vector)\n384\n&gt;&gt;&gt; isinstance(vector[0], float)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Normalized vectors have unit length\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; emb = DefaultLocalDenseEmbedding(normalize_embeddings=True)\n&gt;&gt;&gt; vector = emb.embed(\"Test sentence\")\n&gt;&gt;&gt; np.linalg.norm(vector)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: empty input\n&gt;&gt;&gt; emb.embed(\"   \")\nValueError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Error: non-string input\n&gt;&gt;&gt; emb.embed(123)\nTypeError: Expected 'input' to be str, got int\n</code></pre> <pre><code>&gt;&gt;&gt; # Semantic similarity example\n&gt;&gt;&gt; v1 = emb.embed(\"The cat sits on the mat\")\n&gt;&gt;&gt; v2 = emb.embed(\"A feline rests on a rug\")\n&gt;&gt;&gt; similarity = np.dot(v1, v2)  # High similarity due to semantic meaning\n&gt;&gt;&gt; similarity &gt; 0.7\nTrue\n</code></pre> Note <ul> <li>First call may be slower due to model loading</li> <li>Subsequent calls are much faster as the model stays in memory</li> <li>For batch processing, consider encoding multiple texts together   (though this method handles single texts only)</li> <li>GPU acceleration provides 5-10x speedup over CPU</li> </ul>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding","title":"DefaultLocalSparseEmbedding","text":"<pre><code>DefaultLocalSparseEmbedding(\n    model_source: Literal[\"huggingface\", \"modelscope\"] = \"huggingface\",\n    device: Optional[str] = None,\n    encoding_type: Literal[\"query\", \"document\"] = \"query\",\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SentenceTransformerFunctionBase</code>, <code>SparseEmbeddingFunction[TEXT]</code></p> <p>Default local sparse embedding using SPLADE model.</p> <p>This class provides sparse vector embedding using the SPLADE (SParse Lexical AnD Expansion) model. SPLADE generates sparse, interpretable representations where each dimension corresponds to a vocabulary term with learned importance weights. It's ideal for lexical matching, BM25-style retrieval, and hybrid search scenarios.</p> <p>The default model is <code>naver/splade-cocondenser-ensembledistil</code>, which is publicly available without authentication. It produces sparse vectors with thousands of dimensions but only hundreds of non-zero values, making them efficient for storage and retrieval while maintaining strong lexical matching.</p> <p>Model Caching:</p> <p>This class uses class-level caching to share the SPLADE model across all instances with the same configuration (model_source, device). This significantly reduces memory usage when creating multiple instances for different encoding types (query vs document).</p> <p>Cache Management:</p> <p>The class provides methods to manage the model cache:</p> <ul> <li><code>clear_cache()</code>: Clear all cached models to free memory</li> <li><code>get_cache_info()</code>: Get information about cached models</li> <li><code>remove_from_cache(model_source, device)</code>: Remove a specific model from cache</li> </ul> <p>.. note::     Why not use splade-v3?</p> <pre><code>The newer ``naver/splade-v3`` model is gated (requires access approval).\nWe use ``naver/splade-cocondenser-ensembledistil`` instead.\n\n**To use splade-v3 (if you have access):**\n\n1. Request access at https://huggingface.co/naver/splade-v3\n2. Get your Hugging Face token from https://huggingface.co/settings/tokens\n3. Set environment variable:\n\n   .. code-block:: bash\n\n       export HF_TOKEN=\"your_huggingface_token\"\n\n4. Or login programmatically:\n\n   .. code-block:: python\n\n       from huggingface_hub import login\n       login(token=\"your_huggingface_token\")\n\n5. To use a custom SPLADE model, you can subclass this class and override\n   the model_name in ``__init__``, or create your own implementation\n   inheriting from ``SentenceTransformerFunctionBase`` and\n   ``SparseEmbeddingFunction``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>Literal['huggingface', 'modelscope']</code> <p>Model source. Defaults to <code>\"huggingface\"</code>. ModelScope support may vary for SPLADE models.</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Device to run the model on. Options: <code>\"cpu\"</code>, <code>\"cuda\"</code>, <code>\"mps\"</code> (for Apple Silicon), or <code>None</code> for automatic detection. Defaults to <code>None</code>.</p> <code>None</code> <code>Literal['query', 'document']</code> <p>Encoding type. - <code>\"query\"</code>: Optimize for search queries (default) - <code>\"document\"</code>: Optimize for indexed documents</p> <code>'query'</code> <p>Additional parameters (currently unused, for future extension).</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Model identifier.</p> <code>model_source</code> <code>str</code> <p>The model source being used.</p> <code>device</code> <code>str</code> <p>The device the model is running on.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model cannot be loaded or input is invalid.</p> <code>TypeError</code> <p>If input to <code>embed()</code> is not a string.</p> <code>RuntimeError</code> <p>If model inference fails.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires the <code>sentence-transformers</code> package:   <code>pip install sentence-transformers</code></li> <li>First run downloads the model (~100MB) from Hugging Face</li> <li>Cache location: <code>~/.cache/torch/sentence_transformers/</code></li> <li>No API keys or authentication required</li> <li>Sparse vectors have ~30k dimensions but only ~100-200 non-zero values</li> <li>Best combined with dense embeddings for hybrid retrieval</li> </ul> <p>SPLADE vs Dense Embeddings:</p> <ul> <li>Dense: Continuous semantic vectors, good for semantic similarity</li> <li>Sparse: Lexical keyword-based, interpretable, good for exact matching</li> <li>Hybrid: Combine both for best retrieval performance</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Memory-efficient: both instances share the same model (~200MB)\n&gt;&gt;&gt; from zvec.extension import DefaultLocalSparseEmbedding\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Query embedding\n&gt;&gt;&gt; query_emb = DefaultLocalSparseEmbedding(encoding_type=\"query\")\n&gt;&gt;&gt; query_vec = query_emb.embed(\"machine learning algorithms\")\n&gt;&gt;&gt; type(query_vec)\n&lt;class 'dict'&gt;\n&gt;&gt;&gt; len(query_vec)  # Only non-zero dimensions\n156\n</code></pre> <pre><code>&gt;&gt;&gt; # Document embedding (shares model with query_emb)\n&gt;&gt;&gt; doc_emb = DefaultLocalSparseEmbedding(encoding_type=\"document\")\n&gt;&gt;&gt; doc_vec = doc_emb.embed(\"Machine learning is a subset of AI\")\n&gt;&gt;&gt; # Total memory: ~200MB (not 400MB) thanks to model caching\n</code></pre> <pre><code>&gt;&gt;&gt; # Asymmetric retrieval example\n&gt;&gt;&gt; query_vec = query_emb.embed(\"what causes aging fast\")\n&gt;&gt;&gt; doc_vec = doc_emb.embed(\n...     \"UV-A light causes tanning, skin aging, and cataracts...\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Calculate similarity (dot product for sparse vectors)\n&gt;&gt;&gt; similarity = sum(\n...     query_vec.get(k, 0) * doc_vec.get(k, 0)\n...     for k in set(query_vec) | set(doc_vec)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Batch processing\n&gt;&gt;&gt; queries = [\"query 1\", \"query 2\", \"query 3\"]\n&gt;&gt;&gt; query_vecs = [query_emb.embed(q) for q in queries]\n&gt;&gt;&gt;\n&gt;&gt;&gt; documents = [\"doc 1\", \"doc 2\", \"doc 3\"]\n&gt;&gt;&gt; doc_vecs = [doc_emb.embed(d) for d in documents]\n</code></pre> <pre><code>&gt;&gt;&gt; # Inspecting sparse dimensions (output is sorted by indices)\n&gt;&gt;&gt; query_vec = query_emb.embed(\"machine learning\")\n&gt;&gt;&gt; list(query_vec.items())[:5]  # First 5 dimensions (by index)\n[(10, 0.45), (23, 0.87), (56, 0.32), (89, 1.12), (120, 0.65)]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Sort by weight to find most important terms\n&gt;&gt;&gt; sorted_by_weight = sorted(query_vec.items(), key=lambda x: x[1], reverse=True)\n&gt;&gt;&gt; top_5 = sorted_by_weight[:5]  # Top 5 most important terms\n&gt;&gt;&gt; top_5\n[(1023, 1.45), (245, 1.23), (8901, 0.98), (5678, 0.87), (12034, 0.76)]\n</code></pre> <pre><code>&gt;&gt;&gt; # Using GPU for faster inference\n&gt;&gt;&gt; sparse_emb = DefaultLocalSparseEmbedding(device=\"cuda\")\n&gt;&gt;&gt; vector = sparse_emb.embed(\"natural language processing\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Hybrid retrieval example (combining dense + sparse)\n&gt;&gt;&gt; from zvec.extension import DefaultDenseEmbedding\n&gt;&gt;&gt; dense_emb = DefaultDenseEmbedding()\n&gt;&gt;&gt; sparse_emb = DefaultLocalSparseEmbedding()\n&gt;&gt;&gt;\n&gt;&gt;&gt; query = \"deep learning neural networks\"\n&gt;&gt;&gt; dense_vec = dense_emb.embed(query)   # [0.1, -0.3, 0.5, ...]\n&gt;&gt;&gt; sparse_vec = sparse_emb.embed(query)  # {12: 0.8, 45: 1.2, ...}\n</code></pre> <pre><code>&gt;&gt;&gt; # Error handling\n&gt;&gt;&gt; try:\n...     sparse_emb.embed(\"\")  # Empty string\n... except ValueError as e:\n...     print(f\"Error: {e}\")\nError: Input text cannot be empty or whitespace only\n</code></pre> <pre><code>&gt;&gt;&gt; # Cache management\n&gt;&gt;&gt; # Check cache status\n&gt;&gt;&gt; info = DefaultLocalSparseEmbedding.get_cache_info()\n&gt;&gt;&gt; print(f\"Cached models: {info['cached_models']}\")\nCached models: 1\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Clear cache to free memory\n&gt;&gt;&gt; DefaultLocalSparseEmbedding.clear_cache()\n&gt;&gt;&gt; info = DefaultLocalSparseEmbedding.get_cache_info()\n&gt;&gt;&gt; print(f\"Cached models: {info['cached_models']}\")\nCached models: 0\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Remove specific model from cache\n&gt;&gt;&gt; query_emb = DefaultLocalSparseEmbedding()  # Creates CPU model\n&gt;&gt;&gt; cuda_emb = DefaultLocalSparseEmbedding(device=\"cuda\")  # Creates CUDA model\n&gt;&gt;&gt; info = DefaultLocalSparseEmbedding.get_cache_info()\n&gt;&gt;&gt; print(f\"Cached models: {info['cached_models']}\")\nCached models: 2\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Remove only CPU model\n&gt;&gt;&gt; removed = DefaultLocalSparseEmbedding.remove_from_cache(device=None)\n&gt;&gt;&gt; print(f\"Removed: {removed}\")\nTrue\n&gt;&gt;&gt; info = DefaultLocalSparseEmbedding.get_cache_info()\n&gt;&gt;&gt; print(f\"Cached models: {info['cached_models']}\")\nCached models: 1\n</code></pre> See Also <ul> <li><code>SparseEmbeddingFunction</code>: Base class for sparse embeddings</li> <li><code>DefaultDenseEmbedding</code>: Dense embedding with all-MiniLM-L6-v2</li> <li><code>QwenDenseEmbedding</code>: Alternative using Qwen API</li> </ul> References <ul> <li>SPLADE Paper: https://arxiv.org/abs/2109.10086</li> <li>Model: https://huggingface.co/naver/splade-cocondenser-ensembledistil</li> </ul> <p>Initialize with SPLADE model.</p> <p>Parameters:</p> Name Type Description Default <code>Literal['huggingface', 'modelscope']</code> <p>Model source. Defaults to \"huggingface\".</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Target device (\"cpu\", \"cuda\", \"mps\", or None). Defaults to None (automatic detection).</p> <code>None</code> <code>Literal['query', 'document']</code> <p>Encoding type for embeddings. - \"query\": Optimize for search queries (default) - \"document\": Optimize for indexed documents This distinction is important for asymmetric retrieval tasks.</p> <code>'query'</code> <p>Additional parameters (reserved for future use).</p> <code>{}</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If sentence-transformers is not installed.</p> <code>ValueError</code> <p>If model cannot be loaded.</p> Note <p>Multiple instances with the same (model_source, device) configuration will share the same underlying model to save memory. Different instances can use different encoding_type settings while sharing the model.</p> <p>Model Selection:</p> <p>Uses <code>naver/splade-cocondenser-ensembledistil</code> instead of the newer <code>naver/splade-v3</code> because splade-v3 is a gated model requiring Hugging Face authentication. The cocondenser-ensembledistil variant:</p> <ul> <li>Does not require authentication or API tokens</li> <li>Is immediately available for all users</li> <li>Provides comparable retrieval performance (~2% difference)</li> <li>Avoids \"Access to model is restricted\" errors</li> </ul> <p>If you need splade-v3 and have obtained access, you can subclass this class and override the model_name parameter.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Both instances share the same model (saves memory)\n&gt;&gt;&gt; query_emb = DefaultLocalSparseEmbedding(encoding_type=\"query\")\n&gt;&gt;&gt; doc_emb = DefaultLocalSparseEmbedding(encoding_type=\"document\")\n&gt;&gt;&gt; # Only one model is loaded in memory\n</code></pre> <p>Methods:</p> Name Description <code>clear_cache</code> <p>Clear all cached SPLADE models from memory.</p> <code>get_cache_info</code> <p>Get information about currently cached models.</p> <code>remove_from_cache</code> <p>Remove a specific model from cache.</p> <code>__call__</code> <p>Make the embedding function callable.</p> <code>embed</code> <p>Generate sparse embedding vector for the input text.</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(encoding_type)","title":"<code>encoding_type</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(encoding_type)","title":"<code>encoding_type</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.model_name","title":"model_name  <code>property</code>","text":"<pre><code>model_name: str\n</code></pre> <p>str: The Sentence Transformer model name currently in use.</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.model_source","title":"model_source  <code>property</code>","text":"<pre><code>model_source: str\n</code></pre> <p>str: The model source being used (\"huggingface\" or \"modelscope\").</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.device","title":"device  <code>property</code>","text":"<pre><code>device: str\n</code></pre> <p>str: The device the model is running on.</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.extra_params","title":"extra_params  <code>property</code>","text":"<pre><code>extra_params: dict\n</code></pre> <p>dict: Extra parameters for model-specific customization.</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.clear_cache","title":"clear_cache  <code>classmethod</code>","text":"<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear all cached SPLADE models from memory.</p> <p>This is useful for: - Freeing memory when models are no longer needed - Forcing a fresh model reload - Testing and debugging         Examples:     &gt;&gt;&gt; # Clear cache to free memory     &gt;&gt;&gt; DefaultLocalSparseEmbedding.clear_cache()</p> <pre><code>&gt;&gt;&gt; # Or in tests to ensure fresh model loading\n&gt;&gt;&gt; def test_something():\n...     DefaultLocalSparseEmbedding.clear_cache()\n...     emb = DefaultLocalSparseEmbedding()\n...     # Test with fresh model\n</code></pre>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.get_cache_info","title":"get_cache_info  <code>classmethod</code>","text":"<pre><code>get_cache_info() -&gt; dict\n</code></pre> <p>Get information about currently cached models.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary with cache statistics: - cached_models (int): Number of cached model instances - cache_keys (list): List of cache keys (model_name, model_source, device)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; info = DefaultLocalSparseEmbedding.get_cache_info()\n&gt;&gt;&gt; print(f\"Cached models: {info['cached_models']}\")\nCached models: 2\n&gt;&gt;&gt; print(f\"Cache keys: {info['cache_keys']}\")\nCache keys: [('naver/splade-cocondenser-ensembledistil', 'huggingface', None),\n            ('naver/splade-cocondenser-ensembledistil', 'huggingface', 'cuda')]\n</code></pre>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.remove_from_cache","title":"remove_from_cache  <code>classmethod</code>","text":"<pre><code>remove_from_cache(model_source: str = 'huggingface', device: Optional[str] = None) -&gt; bool\n</code></pre> <p>Remove a specific model from cache.</p> <p>Parameters:</p> Name Type Description Default <code>model_source</code> <code>str</code> <p>Model source (\"huggingface\" or \"modelscope\"). Defaults to \"huggingface\".</p> <code>'huggingface'</code> <code>device</code> <code>Optional[str]</code> <p>Device identifier. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if model was found and removed, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Remove CPU model from cache\n&gt;&gt;&gt; removed = DefaultLocalSparseEmbedding.remove_from_cache()\n&gt;&gt;&gt; print(f\"Removed: {removed}\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; # Remove CUDA model from cache\n&gt;&gt;&gt; removed = DefaultLocalSparseEmbedding.remove_from_cache(device=\"cuda\")\n&gt;&gt;&gt; print(f\"Removed: {removed}\")\nTrue\n</code></pre>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.__call__","title":"__call__","text":"<pre><code>__call__(input: str) -&gt; SparseVectorType\n</code></pre> <p>Make the embedding function callable.</p>"},{"location":"extension/#zvec.extension.DefaultLocalSparseEmbedding.embed","title":"embed","text":"<pre><code>embed(input: str) -&gt; SparseVectorType\n</code></pre> <p>Generate sparse embedding vector for the input text.</p> <p>This method uses the SPLADE model to convert input text into a sparse vector representation. The result is a dictionary where keys are dimension indices and values are importance weights (only non-zero values included).</p> <p>The embedding is optimized based on the <code>encoding_type</code> specified during initialization: \"query\" for search queries or \"document\" for indexed content.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>Input text string to embed. Must be non-empty after stripping whitespace.</p> required <p>Returns:</p> Name Type Description <code>SparseVectorType</code> <code>SparseVectorType</code> <p>A dictionary mapping dimension index to weight. Only non-zero dimensions are included. The dictionary is sorted by indices (keys) in ascending order for consistent output. Example: <code>{10: 0.5, 245: 0.8, 1023: 1.2, 5678: 0.5}</code></p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>input</code> is not a string.</p> <code>ValueError</code> <p>If input is empty or whitespace-only.</p> <code>RuntimeError</code> <p>If model inference fails.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Query embedding\n&gt;&gt;&gt; query_emb = DefaultLocalSparseEmbedding(encoding_type=\"query\")\n&gt;&gt;&gt; query_vec = query_emb.embed(\"machine learning\")\n&gt;&gt;&gt; isinstance(query_vec, dict)\nTrue\n</code></pre> Note <ul> <li>First call may be slower due to model loading</li> <li>Subsequent calls are much faster as the model stays in memory</li> <li>GPU acceleration provides significant speedup</li> <li>Sparse vectors are memory-efficient (only store non-zero values)</li> </ul>"},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase","title":"SentenceTransformerFunctionBase","text":"<pre><code>SentenceTransformerFunctionBase(\n    model_name: str,\n    model_source: Literal[\"huggingface\", \"modelscope\"] = \"huggingface\",\n    device: Optional[str] = None,\n)\n</code></pre> <p>Base class for Sentence Transformer functions (both dense and sparse).</p> <p>This base class provides common functionality for loading and managing sentence-transformers models from Hugging Face or ModelScope. It supports both dense models (e.g., all-MiniLM-L6-v2) and sparse models (e.g., SPLADE).</p> <p>This class is not meant to be used directly. Use concrete implementations: - <code>SentenceTransformerEmbeddingFunction</code> for dense embeddings - <code>SentenceTransformerSparseEmbeddingFunction</code> for sparse embeddings - <code>DefaultDenseEmbedding</code> for default dense embeddings - <code>DefaultSparseEmbedding</code> for default sparse embeddings</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Model identifier or local path.</p> required <code>Literal['huggingface', 'modelscope']</code> <p>Model source.</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Device to run the model on.</p> <code>None</code> Note <ul> <li>This is an internal base class for code reuse</li> <li>Subclasses should inherit from appropriate Protocol (Dense/Sparse)</li> <li>Provides model loading and management functionality</li> </ul> <p>Initialize the base Sentence Transformer functionality.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Model identifier or local path.</p> required <code>Literal['huggingface', 'modelscope']</code> <p>Model source.</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Device to run the model on.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If model_source is invalid.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>str: The Sentence Transformer model name currently in use.</p> <code>model_source</code> <code>str</code> <p>str: The model source being used (\"huggingface\" or \"modelscope\").</p> <code>device</code> <code>str</code> <p>str: The device the model is running on.</p>"},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(model_name)","title":"<code>model_name</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(model_name)","title":"<code>model_name</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase.model_name","title":"model_name  <code>property</code>","text":"<pre><code>model_name: str\n</code></pre> <p>str: The Sentence Transformer model name currently in use.</p>"},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase.model_source","title":"model_source  <code>property</code>","text":"<pre><code>model_source: str\n</code></pre> <p>str: The model source being used (\"huggingface\" or \"modelscope\").</p>"},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase.device","title":"device  <code>property</code>","text":"<pre><code>device: str\n</code></pre> <p>str: The device the model is running on.</p>"},{"location":"extension/#zvec.extension.SentenceTransformerFunctionBase-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker","title":"DefaultLocalReRanker","text":"<pre><code>DefaultLocalReRanker(\n    query: Optional[str] = None,\n    topn: int = 10,\n    rerank_field: Optional[str] = None,\n    model_name: str = \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n    model_source: Literal[\"huggingface\", \"modelscope\"] = \"huggingface\",\n    device: Optional[str] = None,\n    batch_size: int = 32,\n)\n</code></pre> <p>               Bases: <code>SentenceTransformerFunctionBase</code>, <code>RerankFunction</code></p> <p>Re-ranker using Sentence Transformer cross-encoder models for semantic re-ranking.</p> <p>This re-ranker leverages pre-trained cross-encoder models to perform deep semantic re-ranking of search results. It runs locally without API calls, supports GPU acceleration, and works with models from Hugging Face or ModelScope.</p> <p>Cross-encoder models evaluate query-document pairs jointly, providing more accurate relevance scores than bi-encoder (embedding-based) similarity.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Query text for semantic re-ranking. Required.</p> <code>None</code> <code>int</code> <p>Maximum number of documents to return after re-ranking. Defaults to 10.</p> <code>10</code> <code>Optional[str]</code> <p>Document field name to use as re-ranking input text. Required (e.g., \"content\", \"title\", \"body\").</p> <code>None</code> <code>str</code> <p>Cross-encoder model identifier or local path. Defaults to <code>\"cross-encoder/ms-marco-MiniLM-L6-v2\"</code> (MS MARCO MiniLM). Common options: - <code>\"cross-encoder/ms-marco-MiniLM-L6-v2\"</code>: Lightweight, fast (~80MB, recommended) - <code>\"cross-encoder/ms-marco-MiniLM-L12-v2\"</code>: Better accuracy (~120MB) - <code>\"BAAI/bge-reranker-base\"</code>: BGE Reranker Base (~280MB) - <code>\"BAAI/bge-reranker-large\"</code>: BGE Reranker Large (highest quality, ~560MB)</p> <code>'cross-encoder/ms-marco-MiniLM-L6-v2'</code> <code>Literal['huggingface', 'modelscope']</code> <p>Model source. Defaults to <code>\"huggingface\"</code>. - <code>\"huggingface\"</code>: Load from Hugging Face Hub - <code>\"modelscope\"</code>: Load from ModelScope (recommended for users in China)</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Device to run the model on. Options: <code>\"cpu\"</code>, <code>\"cuda\"</code>, <code>\"mps\"</code> (for Apple Silicon), or <code>None</code> for automatic detection. Defaults to <code>None</code>.</p> <code>None</code> <code>int</code> <p>Batch size for processing query-document pairs. Larger values speed up processing but use more memory. Defaults to <code>32</code>.</p> <code>32</code> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>The query text used for re-ranking.</p> <code>topn</code> <code>int</code> <p>Maximum number of documents to return.</p> <code>rerank_field</code> <code>Optional[str]</code> <p>Field name used for re-ranking input.</p> <code>model_name</code> <code>str</code> <p>The cross-encoder model being used.</p> <code>model_source</code> <code>str</code> <p>The model source (\"huggingface\" or \"modelscope\").</p> <code>device</code> <code>str</code> <p>The device the model is running on.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>query</code> is empty/None, <code>rerank_field</code> is None, or model cannot be loaded.</p> <code>TypeError</code> <p>If input types are invalid.</p> <code>RuntimeError</code> <p>If model inference fails.</p> Note <ul> <li>Requires Python 3.10, 3.11, or 3.12</li> <li>Requires <code>sentence-transformers</code> package: <code>pip install sentence-transformers</code></li> <li>For ModelScope support, also requires: <code>pip install modelscope</code></li> <li>First run downloads the model (~80-560MB depending on model) from chosen source</li> <li>No API keys or network required after initial download</li> <li>Cross-encoders are slower than bi-encoders but more accurate</li> <li>GPU acceleration provides significant speedup (5-10x)</li> </ul> <p>MS MARCO MiniLM-L6-v2 Model (Default):</p> <p>The default model <code>cross-encoder/ms-marco-MiniLM-L6-v2</code> is a lightweight and efficient cross-encoder trained on MS MARCO dataset. It provides:</p> <ul> <li>Fast inference speed (suitable for real-time applications)</li> <li>Small model size (~80MB, quick to download)</li> <li>Good balance between speed and accuracy</li> <li>Trained on 500K+ query-document pairs</li> <li>Public availability without authentication</li> </ul> <p>For users in China:</p> <p>If you encounter Hugging Face access issues, use ModelScope instead:</p> <p>.. code-block:: python</p> <pre><code># Recommended for users in China\nreranker = SentenceTransformerReRanker(\n    query=\"\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\",\n    rerank_field=\"content\",\n    model_source=\"modelscope\"\n)\n</code></pre> <p>Alternatively, use Hugging Face mirror:</p> <p>.. code-block:: bash</p> <pre><code>export HF_ENDPOINT=https://hf-mirror.com\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with default MS MARCO MiniLM model\n&gt;&gt;&gt; from zvec.extension import SentenceTransformerReRanker\n&gt;&gt;&gt;\n&gt;&gt;&gt; reranker = SentenceTransformerReRanker(\n...     query=\"machine learning algorithms\",\n...     topn=5,\n...     rerank_field=\"content\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use in collection.query()\n&gt;&gt;&gt; results = collection.query(\n...     data={\"vector_field\": query_vector},\n...     reranker=reranker,\n...     topk=20\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Using ModelScope for users in China\n&gt;&gt;&gt; reranker = SentenceTransformerReRanker(\n...     query=\"\u6df1\u5ea6\u5b66\u4e60\",\n...     topn=10,\n...     rerank_field=\"content\",\n...     model_source=\"modelscope\"\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Using larger model for better quality\n&gt;&gt;&gt; reranker = SentenceTransformerReRanker(\n...     query=\"neural networks\",\n...     topn=5,\n...     rerank_field=\"content\",\n...     model_name=\"BAAI/bge-reranker-large\",\n...     device=\"cuda\",\n...     batch_size=64\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Direct rerank call (for testing)\n&gt;&gt;&gt; query_results = {\n...     \"vector1\": [\n...         Doc(id=\"1\", score=0.9, fields={\"content\": \"Machine learning is...\"}),\n...         Doc(id=\"2\", score=0.8, fields={\"content\": \"Deep learning is...\"}),\n...     ]\n... }\n&gt;&gt;&gt; reranked = reranker.rerank(query_results)\n&gt;&gt;&gt; for doc in reranked:\n...     print(f\"ID: {doc.id}, Score: {doc.score:.4f}\")\nID: 2, Score: 0.9234\nID: 1, Score: 0.8567\n</code></pre> See Also <ul> <li><code>RerankFunction</code>: Abstract base class for re-rankers</li> <li><code>QwenReRanker</code>: Re-ranker using Qwen API</li> <li><code>RrfReRanker</code>: Multi-vector re-ranker using RRF</li> <li><code>WeightedReRanker</code>: Multi-vector re-ranker using weighted scores</li> </ul> References <ul> <li>MS MARCO Cross-Encoder: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2</li> <li>BGE Reranker: https://huggingface.co/BAAI/bge-reranker-base</li> <li>Cross-Encoder vs Bi-Encoder: https://www.sbert.net/examples/applications/cross-encoder/README.html</li> </ul> <p>Initialize SentenceTransformerReRanker with query and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[str]</code> <p>Query text for semantic matching. Required.</p> <code>None</code> <code>int</code> <p>Number of top results to return.</p> <code>10</code> <code>Optional[str]</code> <p>Document field for re-ranking input.</p> <code>None</code> <code>str</code> <p>Cross-encoder model identifier.</p> <code>'cross-encoder/ms-marco-MiniLM-L6-v2'</code> <code>Literal['huggingface', 'modelscope']</code> <p>Model source.</p> <code>'huggingface'</code> <code>Optional[str]</code> <p>Target device (\"cpu\", \"cuda\", \"mps\", or None).</p> <code>None</code> <code>int</code> <p>Batch size for processing query-document pairs.</p> <code>32</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty or model cannot be loaded.</p> <p>Methods:</p> Name Description <code>rerank</code> <p>Re-rank documents using Sentence Transformer cross-encoder model.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker(query)","title":"<code>query</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(model_name)","title":"<code>model_name</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(batch_size)","title":"<code>batch_size</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(query)","title":"<code>query</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(topn)","title":"<code>topn</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(rerank_field)","title":"<code>rerank_field</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(model_name)","title":"<code>model_name</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(model_source)","title":"<code>model_source</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(device)","title":"<code>device</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker(batch_size)","title":"<code>batch_size</code>","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker-attributes","title":"Attributes","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker.topn","title":"topn  <code>property</code>","text":"<pre><code>topn: int\n</code></pre> <p>int: Number of top documents to return after re-ranking.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.rerank_field","title":"rerank_field  <code>property</code>","text":"<pre><code>rerank_field: Optional[str]\n</code></pre> <p>Optional[str]: Field name used as re-ranking input.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.model_name","title":"model_name  <code>property</code>","text":"<pre><code>model_name: str\n</code></pre> <p>str: The Sentence Transformer model name currently in use.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.model_source","title":"model_source  <code>property</code>","text":"<pre><code>model_source: str\n</code></pre> <p>str: The model source being used (\"huggingface\" or \"modelscope\").</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.device","title":"device  <code>property</code>","text":"<pre><code>device: str\n</code></pre> <p>str: The device the model is running on.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.query","title":"query  <code>property</code>","text":"<pre><code>query: str\n</code></pre> <p>str: Query text used for semantic re-ranking.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker.batch_size","title":"batch_size  <code>property</code>","text":"<pre><code>batch_size: int\n</code></pre> <p>int: Batch size for processing query-document pairs.</p>"},{"location":"extension/#zvec.extension.DefaultLocalReRanker-functions","title":"Functions","text":""},{"location":"extension/#zvec.extension.DefaultLocalReRanker.rerank","title":"rerank","text":"<pre><code>rerank(query_results: dict[str, list[Doc]]) -&gt; list[Doc]\n</code></pre> <p>Re-rank documents using Sentence Transformer cross-encoder model.</p> <p>Evaluates each query-document pair using the cross-encoder model to compute relevance scores. Documents are then sorted by these scores and the top-k results are returned.</p> <p>Parameters:</p> Name Type Description Default <code>query_results</code> <code>dict[str, list[Doc]]</code> <p>Mapping from vector field names to lists of retrieved documents. Documents from all fields are deduplicated and re-ranked together.</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>list[Doc]: Re-ranked documents (up to <code>topn</code>) with updated <code>score</code> fields containing relevance scores from the cross-encoder model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no valid documents are found or model inference fails.</p> Note <ul> <li>Duplicate documents (same ID) across fields are processed once</li> <li>Documents with empty/missing <code>rerank_field</code> content are skipped</li> <li>Returned scores are logits from the cross-encoder model</li> <li>Higher scores indicate higher relevance</li> <li>Processing time is O(n) where n is the number of documents</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; reranker = SentenceTransformerReRanker(\n...     query=\"machine learning\",\n...     topn=3,\n...     rerank_field=\"content\"\n... )\n&gt;&gt;&gt; query_results = {\n...     \"vector1\": [\n...         Doc(id=\"1\", score=0.9, fields={\"content\": \"ML basics\"}),\n...         Doc(id=\"2\", score=0.8, fields={\"content\": \"DL tutorial\"}),\n...     ]\n... }\n&gt;&gt;&gt; reranked = reranker.rerank(query_results)\n&gt;&gt;&gt; len(reranked) &lt;= 3\nTrue\n</code></pre>"},{"location":"params/","title":"Parameters","text":""},{"location":"params/#zvec.model.param","title":"zvec.model.param","text":"<p>This module contains the params of Zvec</p> <p>Modules:</p> Name Description <code>vector_query</code> <p>Classes:</p> Name Description <code>AddColumnOption</code> <p>Options for adding a new column to a collection.</p> <code>AlterColumnOption</code> <p>Options for altering an existing column (e.g., changing index settings).</p> <code>CollectionOption</code> <p>Options for opening or creating a collection.</p> <code>FlatIndexParam</code> <p>Parameters for configuring a flat (brute-force) index.</p> <code>HnswIndexParam</code> <p>Parameters for configuring an HNSW (Hierarchical Navigable Small World) index.</p> <code>HnswQueryParam</code> <p>Query parameters for HNSW (Hierarchical Navigable Small World) index.</p> <code>IVFIndexParam</code> <p>Parameters for configuring an IVF (Inverted File Index) index.</p> <code>IVFQueryParam</code> <p>Query parameters for IVF (Inverted File Index) index.</p> <code>IndexOption</code> <p>Options for creating an index.</p> <code>IndexParam</code> <p>Base class for all index parameter configurations.</p> <code>InvertIndexParam</code> <p>Parameters for configuring an invert index.</p> <code>OptimizeOption</code> <p>Options for optimizing a collection (e.g., merging segments).</p> <code>QueryParam</code> <p>Base class for all query parameter configurations.</p> <code>SegmentOption</code> <p>Options for segment-level operations.</p> <code>VectorIndexParam</code> <p>Base class for vector index parameter configurations.</p>"},{"location":"params/#zvec.model.param-classes","title":"Classes","text":""},{"location":"params/#zvec.model.param.AddColumnOption","title":"AddColumnOption","text":"<pre><code>AddColumnOption(concurrency: SupportsInt = 0)\n</code></pre> <p>Options for adding a new column to a collection.</p> <p>Attributes:</p> Name Type Description <code>concurrency</code> <code>int</code> <p>Number of threads to use when backfilling data for the new column. If 0, auto-detect is used. Default is 0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = AddColumnOption(concurrency=1)\n&gt;&gt;&gt; print(opt.concurrency)\n1\n</code></pre> <p>Constructs an AddColumnOption instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of threads for data backfill. 0 means auto-detect. Defaults to 0.</p> <code>0</code>"},{"location":"params/#zvec.model.param.AddColumnOption(concurrency)","title":"<code>concurrency</code>","text":""},{"location":"params/#zvec.model.param.AddColumnOption-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.AddColumnOption.concurrency","title":"concurrency  <code>property</code>","text":"<pre><code>concurrency: int\n</code></pre> <p>int: Number of threads used when adding a column (0 = auto).</p>"},{"location":"params/#zvec.model.param.AddColumnOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.AlterColumnOption","title":"AlterColumnOption","text":"<pre><code>AlterColumnOption(concurrency: SupportsInt = 0)\n</code></pre> <p>Options for altering an existing column (e.g., changing index settings).</p> <p>Attributes:</p> Name Type Description <code>concurrency</code> <code>int</code> <p>Number of threads to use during the alteration process. If 0, the system will choose an optimal value automatically. Default is 0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = AlterColumnOption(concurrency=1)\n&gt;&gt;&gt; print(opt.concurrency)\n1\n</code></pre> <p>Constructs an AlterColumnOption instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of threads for column alteration. 0 means auto-detect. Defaults to 0.</p> <code>0</code>"},{"location":"params/#zvec.model.param.AlterColumnOption(concurrency)","title":"<code>concurrency</code>","text":""},{"location":"params/#zvec.model.param.AlterColumnOption-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.AlterColumnOption.concurrency","title":"concurrency  <code>property</code>","text":"<pre><code>concurrency: int\n</code></pre> <p>int: Number of threads used when altering a column (0 = auto).</p>"},{"location":"params/#zvec.model.param.AlterColumnOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.CollectionOption","title":"CollectionOption","text":"<pre><code>CollectionOption(read_only: bool = False, enable_mmap: bool = True)\n</code></pre> <p>Options for opening or creating a collection.</p> <p>Attributes:</p> Name Type Description <code>read_only</code> <code>bool</code> <p>Whether the collection is opened in read-only mode. Default is False.</p> <code>enable_mmap</code> <code>bool</code> <p>Whether to use memory-mapped I/O for data files. Default is True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = CollectionOption(read_only=True, enable_mmap=False)\n&gt;&gt;&gt; print(opt.read_only)\nTrue\n</code></pre> <p>Constructs a CollectionOption instance.</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>Open collection in read-only mode. Defaults to False.</p> <code>False</code> <code>bool</code> <p>Enable memory-mapped I/O. Defaults to True.</p> <code>True</code>"},{"location":"params/#zvec.model.param.CollectionOption(read_only)","title":"<code>read_only</code>","text":""},{"location":"params/#zvec.model.param.CollectionOption(enable_mmap)","title":"<code>enable_mmap</code>","text":""},{"location":"params/#zvec.model.param.CollectionOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.FlatIndexParam","title":"FlatIndexParam","text":"<pre><code>FlatIndexParam(metric_type: MetricType = ..., quantize_type: QuantizeType = ...)\n</code></pre> <p>               Bases: <code>VectorIndexParam</code></p> <p>Parameters for configuring a flat (brute-force) index.</p> <p>A flat index performs exact nearest neighbor search by comparing the query vector against all vectors in the collection. It is simple, accurate, and suitable for small to medium datasets or as a baseline.</p> <p>Attributes:</p> Name Type Description <code>metric_type</code> <code>MetricType</code> <p>Distance metric used for similarity computation. Default is <code>MetricType.IP</code> (inner product).</p> <code>quantize_type</code> <code>QuantizeType</code> <p>Optional quantization type for vector compression (e.g., FP16, INT8). Use <code>QuantizeType.UNDEFINED</code> to disable quantization. Default is <code>QuantizeType.UNDEFINED</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import MetricType, QuantizeType\n&gt;&gt;&gt; params = FlatIndexParam(\n...     metric_type=MetricType.L2,\n...     quantize_type=QuantizeType.FP16\n... )\n&gt;&gt;&gt; print(params)\n{'metric_type': 'L2', 'quantize_type': 'FP16'}\n</code></pre> <p>Constructs a FlatIndexParam instance.</p> <p>Parameters:</p> Name Type Description Default <code>MetricType</code> <p>Distance metric. Defaults to MetricType.IP.</p> <code>...</code> <code>QuantizeType</code> <p>Vector quantization type. Defaults to QuantizeType.UNDEFINED (no quantization).</p> <code>...</code> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.FlatIndexParam(metric_type)","title":"<code>metric_type</code>","text":""},{"location":"params/#zvec.model.param.FlatIndexParam(quantize_type)","title":"<code>quantize_type</code>","text":""},{"location":"params/#zvec.model.param.FlatIndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.FlatIndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.FlatIndexParam.metric_type","title":"metric_type  <code>property</code>","text":"<pre><code>metric_type: MetricType\n</code></pre> <p>MetricType: Distance metric (e.g., IP, COSINE, L2).</p>"},{"location":"params/#zvec.model.param.FlatIndexParam.quantize_type","title":"quantize_type  <code>property</code>","text":"<pre><code>quantize_type: QuantizeType\n</code></pre> <p>QuantizeType: Vector quantization type (e.g., FP16, INT8).</p>"},{"location":"params/#zvec.model.param.FlatIndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.FlatIndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.HnswIndexParam","title":"HnswIndexParam","text":"<pre><code>HnswIndexParam(\n    metric_type: MetricType = ...,\n    m: SupportsInt = 50,\n    ef_construction: SupportsInt = 500,\n    quantize_type: QuantizeType = ...,\n)\n</code></pre> <p>               Bases: <code>VectorIndexParam</code></p> <p>Parameters for configuring an HNSW (Hierarchical Navigable Small World) index.</p> <p>HNSW is a graph-based approximate nearest neighbor search index. This class encapsulates its construction hyperparameters.</p> <p>Attributes:</p> Name Type Description <code>metric_type</code> <code>MetricType</code> <p>Distance metric used for similarity computation. Default is <code>MetricType.IP</code> (inner product).</p> <code>m</code> <code>int</code> <p>Number of bi-directional links created for every new element during construction. Higher values improve accuracy but increase memory usage and construction time. Default is 50.</p> <code>ef_construction</code> <code>int</code> <p>Size of the dynamic candidate list for nearest neighbors during index construction. Larger values yield better graph quality at the cost of slower build time. Default is 500.</p> <code>quantize_type</code> <code>QuantizeType</code> <p>Optional quantization type for vector compression (e.g., FP16, INT8). Default is <code>QuantizeType.UNDEFINED</code> to disable quantization.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import MetricType, QuantizeType\n&gt;&gt;&gt; params = HnswIndexParam(\n...     metric_type=MetricType.COSINE,\n...     m=16,\n...     ef_construction=200,\n...     quantize_type=QuantizeType.INT8\n... )\n&gt;&gt;&gt; print(params)\n{'metric_type': 'IP', 'm': 16, 'ef_construction': 200, 'quantize_type': 'INT8'}\n</code></pre> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.HnswIndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.HnswIndexParam.ef_construction","title":"ef_construction  <code>property</code>","text":"<pre><code>ef_construction: int\n</code></pre> <p>int: Candidate list size during index construction.</p>"},{"location":"params/#zvec.model.param.HnswIndexParam.m","title":"m  <code>property</code>","text":"<pre><code>m: int\n</code></pre> <p>int: Maximum number of neighbors per node in upper layers.</p>"},{"location":"params/#zvec.model.param.HnswIndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.HnswIndexParam.metric_type","title":"metric_type  <code>property</code>","text":"<pre><code>metric_type: MetricType\n</code></pre> <p>MetricType: Distance metric (e.g., IP, COSINE, L2).</p>"},{"location":"params/#zvec.model.param.HnswIndexParam.quantize_type","title":"quantize_type  <code>property</code>","text":"<pre><code>quantize_type: QuantizeType\n</code></pre> <p>QuantizeType: Vector quantization type (e.g., FP16, INT8).</p>"},{"location":"params/#zvec.model.param.HnswIndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.HnswIndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.HnswQueryParam","title":"HnswQueryParam","text":"<pre><code>HnswQueryParam(\n    ef: SupportsInt = 300,\n    radius: SupportsFloat = 0.0,\n    is_linear: bool = False,\n    is_using_refiner: bool = False,\n)\n</code></pre> <p>               Bases: <code>QueryParam</code></p> <p>Query parameters for HNSW (Hierarchical Navigable Small World) index.</p> <p>Controls the trade-off between search speed and accuracy via the <code>ef</code> parameter.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>Always <code>IndexType.HNSW</code>.</p> <code>ef</code> <code>int</code> <p>Size of the dynamic candidate list during search. Larger values improve recall but slow down search. Default is 300.</p> <code>radius</code> <code>float</code> <p>Search radius for range queries. Default is 0.0.</p> <code>is_linear</code> <code>bool</code> <p>Force linear search. Default is False.</p> <code>is_using_refiner</code> <code>bool</code> <p>Whether to use refiner for the query. Default is False.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; params = HnswQueryParam(ef=300)\n&gt;&gt;&gt; print(params.ef)\n300\n&gt;&gt;&gt; print(params.to_dict() if hasattr(params, 'to_dict') else params)\n{\"type\":\"HNSW\", \"ef\":300}\n</code></pre> <p>Constructs an HnswQueryParam instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Search-time candidate list size. Higher values improve accuracy. Defaults to 300.</p> <code>300</code> <code>float</code> <p>Search radius for range queries. Default is 0.0.</p> <code>0.0</code> <code>bool</code> <p>Force linear search. Default is False.</p> <code>False</code> <code>bool</code> <p>Whether to use refiner for the query. Default is False.</p> <code>False</code>"},{"location":"params/#zvec.model.param.HnswQueryParam(ef)","title":"<code>ef</code>","text":""},{"location":"params/#zvec.model.param.HnswQueryParam(radius)","title":"<code>radius</code>","text":""},{"location":"params/#zvec.model.param.HnswQueryParam(is_linear)","title":"<code>is_linear</code>","text":""},{"location":"params/#zvec.model.param.HnswQueryParam(is_using_refiner)","title":"<code>is_using_refiner</code>","text":""},{"location":"params/#zvec.model.param.HnswQueryParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.HnswQueryParam.ef","title":"ef  <code>property</code>","text":"<pre><code>ef: int\n</code></pre> <p>int: Size of the dynamic candidate list during HNSW search.</p>"},{"location":"params/#zvec.model.param.HnswQueryParam.is_linear","title":"is_linear  <code>property</code>","text":"<pre><code>is_linear: bool\n</code></pre> <p>bool: Whether to bypass the index and use brute-force linear search.</p>"},{"location":"params/#zvec.model.param.HnswQueryParam.is_using_refiner","title":"is_using_refiner  <code>property</code>","text":"<pre><code>is_using_refiner: bool\n</code></pre> <p>bool: Whether to use refiner for the query.</p>"},{"location":"params/#zvec.model.param.HnswQueryParam.radius","title":"radius  <code>property</code>","text":"<pre><code>radius: float\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.HnswQueryParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.HnswQueryParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.IVFIndexParam","title":"IVFIndexParam","text":"<pre><code>IVFIndexParam(\n    metric_type: MetricType = ...,\n    n_list: SupportsInt = 0,\n    n_iters: SupportsInt = 10,\n    use_soar: bool = False,\n    quantize_type: QuantizeType = ...,\n)\n</code></pre> <p>               Bases: <code>VectorIndexParam</code></p> <p>Parameters for configuring an IVF (Inverted File Index) index.</p> <p>IVF partitions the vector space into clusters (inverted lists). At query time, only a subset of clusters is searched, providing a trade-off between speed and accuracy.</p> <p>Attributes:</p> Name Type Description <code>metric_type</code> <code>MetricType</code> <p>Distance metric used for similarity computation. Default is <code>MetricType.IP</code> (inner product).</p> <code>n_list</code> <code>int</code> <p>Number of clusters (inverted lists) to partition the dataset into. If set to 0, the system will auto-select a reasonable value based on data size. Default is 0 (auto).</p> <code>n_iters</code> <code>int</code> <p>Number of iterations for k-means clustering during index training. Higher values yield more stable centroids. Default is 10.</p> <code>use_soar</code> <code>bool</code> <p>Whether to enable SOAR (Scalable Optimized Adaptive Routing) for improved IVF search performance. Default is False.</p> <code>quantize_type</code> <code>QuantizeType</code> <p>Optional quantization type for vector compression (e.g., FP16, INT8). Default is <code>QuantizeType.UNDEFINED</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import MetricType, QuantizeType\n&gt;&gt;&gt; params = IVFIndexParam(\n...     metric_type=MetricType.COSINE,\n...     n_list=100,\n...     n_iters=15,\n...     use_soar=True,\n...     quantize_type=QuantizeType.INT8\n... )\n&gt;&gt;&gt; print(params.n_list)\n100\n</code></pre> <p>Constructs an IVFIndexParam instance.</p> <p>Parameters:</p> Name Type Description Default <code>MetricType</code> <p>Distance metric. Defaults to MetricType.IP.</p> <code>...</code> <code>int</code> <p>Number of inverted lists (clusters). Set to 0 for auto. Defaults to 0.</p> <code>0</code> <code>int</code> <p>Number of k-means iterations during training. Defaults to 10.</p> <code>10</code> <code>bool</code> <p>Enable SOAR optimization. Defaults to False.</p> <code>False</code> <code>QuantizeType</code> <p>Vector quantization type. Defaults to QuantizeType.UNDEFINED.</p> <code>...</code> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.IVFIndexParam(metric_type)","title":"<code>metric_type</code>","text":""},{"location":"params/#zvec.model.param.IVFIndexParam(n_list)","title":"<code>n_list</code>","text":""},{"location":"params/#zvec.model.param.IVFIndexParam(n_iters)","title":"<code>n_iters</code>","text":""},{"location":"params/#zvec.model.param.IVFIndexParam(use_soar)","title":"<code>use_soar</code>","text":""},{"location":"params/#zvec.model.param.IVFIndexParam(quantize_type)","title":"<code>quantize_type</code>","text":""},{"location":"params/#zvec.model.param.IVFIndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.IVFIndexParam.n_iters","title":"n_iters  <code>property</code>","text":"<pre><code>n_iters: int\n</code></pre> <p>int: Number of k-means iterations during training.</p>"},{"location":"params/#zvec.model.param.IVFIndexParam.n_list","title":"n_list  <code>property</code>","text":"<pre><code>n_list: int\n</code></pre> <p>int: Number of inverted lists (0 = auto).</p>"},{"location":"params/#zvec.model.param.IVFIndexParam.use_soar","title":"use_soar  <code>property</code>","text":"<pre><code>use_soar: bool\n</code></pre> <p>bool: Whether SOAR optimization is enabled.</p>"},{"location":"params/#zvec.model.param.IVFIndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.IVFIndexParam.metric_type","title":"metric_type  <code>property</code>","text":"<pre><code>metric_type: MetricType\n</code></pre> <p>MetricType: Distance metric (e.g., IP, COSINE, L2).</p>"},{"location":"params/#zvec.model.param.IVFIndexParam.quantize_type","title":"quantize_type  <code>property</code>","text":"<pre><code>quantize_type: QuantizeType\n</code></pre> <p>QuantizeType: Vector quantization type (e.g., FP16, INT8).</p>"},{"location":"params/#zvec.model.param.IVFIndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.IVFIndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.IVFQueryParam","title":"IVFQueryParam","text":"<pre><code>IVFQueryParam(nprobe: SupportsInt = 10)\n</code></pre> <p>               Bases: <code>QueryParam</code></p> <p>Query parameters for IVF (Inverted File Index) index.</p> <p>Controls how many inverted lists (<code>nprobe</code>) to visit during search.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>Always <code>IndexType.IVF</code>.</p> <code>nprobe</code> <code>int</code> <p>Number of closest clusters (inverted lists) to search. Higher values improve recall but increase latency. Default is 10.</p> <code>radius</code> <code>float</code> <p>Search radius for range queries. Default is 0.0.</p> <code>is_linear</code> <code>bool</code> <p>Force linear search. Default is False.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; params = IVFQueryParam(nprobe=20)\n&gt;&gt;&gt; print(params.nprobe)\n20\n</code></pre> <p>Constructs an IVFQueryParam instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of inverted lists to probe during search. Higher values improve accuracy. Defaults to 10.</p> <code>10</code>"},{"location":"params/#zvec.model.param.IVFQueryParam(nprobe)","title":"<code>nprobe</code>","text":""},{"location":"params/#zvec.model.param.IVFQueryParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.IVFQueryParam.nprobe","title":"nprobe  <code>property</code>","text":"<pre><code>nprobe: int\n</code></pre> <p>int: Number of inverted lists to search during IVF query.</p>"},{"location":"params/#zvec.model.param.IVFQueryParam.is_linear","title":"is_linear  <code>property</code>","text":"<pre><code>is_linear: bool\n</code></pre> <p>bool: Whether to bypass the index and use brute-force linear search.</p>"},{"location":"params/#zvec.model.param.IVFQueryParam.is_using_refiner","title":"is_using_refiner  <code>property</code>","text":"<pre><code>is_using_refiner: bool\n</code></pre> <p>bool: Whether to use refiner for the query.</p>"},{"location":"params/#zvec.model.param.IVFQueryParam.radius","title":"radius  <code>property</code>","text":"<pre><code>radius: float\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.IVFQueryParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.IVFQueryParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.IndexOption","title":"IndexOption","text":"<pre><code>IndexOption(concurrency: SupportsInt = 0)\n</code></pre> <p>Options for creating an index.</p> <p>Attributes:</p> Name Type Description <code>concurrency</code> <code>int</code> <p>Number of threads to use during index creation. If 0, the system will choose an optimal value automatically. Default is 0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = IndexOption(concurrency=4)\n&gt;&gt;&gt; print(opt.concurrency)\n4\n</code></pre> <p>Constructs an IndexOption instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of concurrent threads. 0 means auto-detect. Defaults to 0.</p> <code>0</code>"},{"location":"params/#zvec.model.param.IndexOption(concurrency)","title":"<code>concurrency</code>","text":""},{"location":"params/#zvec.model.param.IndexOption-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.IndexOption.concurrency","title":"concurrency  <code>property</code>","text":"<pre><code>concurrency: int\n</code></pre> <p>int: Number of threads used for index creation (0 = auto).</p>"},{"location":"params/#zvec.model.param.IndexOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.IndexParam","title":"IndexParam","text":"<p>Base class for all index parameter configurations.</p> <p>This abstract base class defines the common interface for index types. It should not be instantiated directly; use derived classes instead.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>The type of the index (e.g., HNSW, FLAT, INVERT).</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.IndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.IndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.IndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.IndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.InvertIndexParam","title":"InvertIndexParam","text":"<pre><code>InvertIndexParam(enable_range_optimization: bool = False, enable_extended_wildcard: bool = False)\n</code></pre> <p>               Bases: <code>IndexParam</code></p> <p>Parameters for configuring an invert index.</p> <p>This class controls whether range query optimization is enabled for invert index structures.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>Always <code>IndexType.INVERTED</code>.</p> <code>enable_range_optimization</code> <code>bool</code> <p>Whether range optimization is enabled.</p> <code>enable_extended_wildcard</code> <code>bool</code> <p>Whether extended wildcard (suffix and infix) search is enabled.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; params = InvertIndexParam(enable_range_optimization=True, enable_extended_wildcard=False)\n&gt;&gt;&gt; print(params.enable_range_optimization)\nTrue\n&gt;&gt;&gt; print(params.enable_extended_wildcard)\nFalse\n&gt;&gt;&gt; config = params.to_dict()\n&gt;&gt;&gt; print(config)\n{'enable_range_optimization': True, 'enable_extended_wildcard': False}\n</code></pre> <p>Constructs an InvertIndexParam instance.</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>If True, enables range query optimization for the invert index. Defaults to False.</p> <code>False</code> <code>bool</code> <p>If True, enables extended wildcard search including suffix and infix patterns. Defaults to False.</p> <code>False</code> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.InvertIndexParam(enable_range_optimization)","title":"<code>enable_range_optimization</code>","text":""},{"location":"params/#zvec.model.param.InvertIndexParam(enable_extended_wildcard)","title":"<code>enable_extended_wildcard</code>","text":""},{"location":"params/#zvec.model.param.InvertIndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.InvertIndexParam.enable_extended_wildcard","title":"enable_extended_wildcard  <code>property</code>","text":"<pre><code>enable_extended_wildcard: bool\n</code></pre> <p>bool: Whether extended wildcard (suffix and infix) search is enabled. Note: Prefix search is always enabled regardless of this setting.</p>"},{"location":"params/#zvec.model.param.InvertIndexParam.enable_range_optimization","title":"enable_range_optimization  <code>property</code>","text":"<pre><code>enable_range_optimization: bool\n</code></pre> <p>bool: Whether range optimization is enabled for this inverted index.</p>"},{"location":"params/#zvec.model.param.InvertIndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.InvertIndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.InvertIndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.OptimizeOption","title":"OptimizeOption","text":"<pre><code>OptimizeOption(concurrency: SupportsInt = 0)\n</code></pre> <p>Options for optimizing a collection (e.g., merging segments).</p> <p>Attributes:</p> Name Type Description <code>concurrency</code> <code>int</code> <p>Number of threads to use during optimization. If 0, the system will choose an optimal value automatically. Default is 0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = OptimizeOption(concurrency=2)\n&gt;&gt;&gt; print(opt.concurrency)\n2\n</code></pre> <p>Constructs an OptimizeOption instance.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of concurrent threads. 0 means auto-detect. Defaults to 0.</p> <code>0</code>"},{"location":"params/#zvec.model.param.OptimizeOption(concurrency)","title":"<code>concurrency</code>","text":""},{"location":"params/#zvec.model.param.OptimizeOption-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.OptimizeOption.concurrency","title":"concurrency  <code>property</code>","text":"<pre><code>concurrency: int\n</code></pre> <p>int: Number of threads used for optimization (0 = auto).</p>"},{"location":"params/#zvec.model.param.OptimizeOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.QueryParam","title":"QueryParam","text":"<p>Base class for all query parameter configurations.</p> <p>This abstract base class defines common query settings such as search radius and whether to force linear (brute-force) search. It should not be instantiated directly; use derived classes like <code>HnswQueryParam</code> or <code>IVFQueryParam</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>The index type this query is configured for.</p> <code>radius</code> <code>float</code> <p>Search radius for range queries. Used in combination with top-k to filter results. Default is 0.0 (disabled).</p> <code>is_linear</code> <code>bool</code> <p>If True, forces brute-force linear search instead of using the index. Useful for debugging or small datasets. Default is False.</p> <code>is_using_refiner</code> <code>bool</code> <p>Whether to use refiner for the query. Default is False.</p>"},{"location":"params/#zvec.model.param.QueryParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.QueryParam.is_linear","title":"is_linear  <code>property</code>","text":"<pre><code>is_linear: bool\n</code></pre> <p>bool: Whether to bypass the index and use brute-force linear search.</p>"},{"location":"params/#zvec.model.param.QueryParam.is_using_refiner","title":"is_using_refiner  <code>property</code>","text":"<pre><code>is_using_refiner: bool\n</code></pre> <p>bool: Whether to use refiner for the query.</p>"},{"location":"params/#zvec.model.param.QueryParam.radius","title":"radius  <code>property</code>","text":"<pre><code>radius: float\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.QueryParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of index this query targets.</p>"},{"location":"params/#zvec.model.param.SegmentOption","title":"SegmentOption","text":"<pre><code>SegmentOption()\n</code></pre> <p>Options for segment-level operations.</p> <p>Currently, this class mirrors CollectionOption and is used internally. It supports read-only mode, memory mapping, and buffer configuration.</p> Note <p>This class is primarily for internal use. Most users should use CollectionOption instead.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opt = SegmentOption()\n&gt;&gt;&gt; print(opt.enable_mmap)\nTrue\n</code></pre> <p>Constructs a SegmentOption with default settings.</p> <p>Attributes:</p> Name Type Description <code>enable_mmap</code> <code>bool</code> <p>bool: Whether memory-mapped I/O is enabled.</p> <code>max_buffer_size</code> <code>int</code> <p>int: Maximum buffer size in bytes (internal use).</p> <code>read_only</code> <code>bool</code> <p>bool: Whether the segment is read-only.</p>"},{"location":"params/#zvec.model.param.SegmentOption-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.SegmentOption.enable_mmap","title":"enable_mmap  <code>property</code>","text":"<pre><code>enable_mmap: bool\n</code></pre> <p>bool: Whether memory-mapped I/O is enabled.</p>"},{"location":"params/#zvec.model.param.SegmentOption.max_buffer_size","title":"max_buffer_size  <code>property</code>","text":"<pre><code>max_buffer_size: int\n</code></pre> <p>int: Maximum buffer size in bytes (internal use).</p>"},{"location":"params/#zvec.model.param.SegmentOption.read_only","title":"read_only  <code>property</code>","text":"<pre><code>read_only: bool\n</code></pre> <p>bool: Whether the segment is read-only.</p>"},{"location":"params/#zvec.model.param.SegmentOption-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.VectorIndexParam","title":"VectorIndexParam","text":"<p>               Bases: <code>IndexParam</code></p> <p>Base class for vector index parameter configurations.</p> <p>Encapsulates common settings for all vector index types.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>IndexType</code> <p>The specific vector index type (e.g., HNSW, FLAT).</p> <code>metric_type</code> <code>MetricType</code> <p>Distance metric used for similarity search.</p> <code>quantize_type</code> <code>QuantizeType</code> <p>Optional vector quantization type.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert to dictionary with all fields</p>"},{"location":"params/#zvec.model.param.VectorIndexParam-attributes","title":"Attributes","text":""},{"location":"params/#zvec.model.param.VectorIndexParam.metric_type","title":"metric_type  <code>property</code>","text":"<pre><code>metric_type: MetricType\n</code></pre> <p>MetricType: Distance metric (e.g., IP, COSINE, L2).</p>"},{"location":"params/#zvec.model.param.VectorIndexParam.quantize_type","title":"quantize_type  <code>property</code>","text":"<pre><code>quantize_type: QuantizeType\n</code></pre> <p>QuantizeType: Vector quantization type (e.g., FP16, INT8).</p>"},{"location":"params/#zvec.model.param.VectorIndexParam.type","title":"type  <code>property</code>","text":"<pre><code>type: IndexType\n</code></pre> <p>IndexType: The type of the index.</p>"},{"location":"params/#zvec.model.param.VectorIndexParam-functions","title":"Functions","text":""},{"location":"params/#zvec.model.param.VectorIndexParam.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary with all fields</p>"},{"location":"schema/","title":"Collection Schema","text":""},{"location":"schema/#zvec.model.schema","title":"zvec.model.schema","text":"<p>This module contains the schema of Zvec</p> <p>Modules:</p> Name Description <code>collection_schema</code> <code>field_schema</code> <p>Classes:</p> Name Description <code>CollectionSchema</code> <p>Defines the structure of a collection in Zvec.</p> <code>FieldSchema</code> <p>Represents a scalar (non-vector) field in a collection schema.</p> <code>VectorSchema</code> <p>Represents a vector field in a collection schema.</p>"},{"location":"schema/#zvec.model.schema-classes","title":"Classes","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema","title":"CollectionSchema","text":"<pre><code>CollectionSchema(\n    name: str,\n    fields: Optional[Union[FieldSchema, list[FieldSchema]]] = None,\n    vectors: Optional[Union[VectorSchema, list[VectorSchema]]] = None,\n)\n</code></pre> <p>Defines the structure of a collection in Zvec.</p> <p>A collection schema specifies the name of the collection and its fields, including both scalar fields (e.g., int, string) and vector fields. Field names must be unique across both scalar and vector fields.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the collection.</p> required <code>Optional[Union[FieldSchema, list[FieldSchema]]]</code> <p>One or more scalar field definitions. Defaults to None.</p> <code>None</code> <code>Optional[Union[VectorSchema, list[VectorSchema]]]</code> <p>One or more vector field definitions. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>fields</code> or <code>vectors</code> are of unsupported types.</p> <code>ValueError</code> <p>If any field or vector name is duplicated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec import FieldSchema, VectorSchema, DataType, IndexType\n&gt;&gt;&gt; id_field = FieldSchema(\"id\", DataType.INT64, is_primary=True)\n&gt;&gt;&gt; emb_field = VectorSchema(\"embedding\", dim=128, data_type=DataType.VECTOR_FP32)\n&gt;&gt;&gt; schema = CollectionSchema(\n...     name=\"my_collection\",\n...     fields=id_field,\n...     vectors=emb_field\n... )\n&gt;&gt;&gt; print(schema.name)\nmy_collection\n</code></pre> <p>Methods:</p> Name Description <code>field</code> <p>Retrieve a scalar field by name.</p> <code>vector</code> <p>Retrieve a vector field by name.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>str: The name of the collection.</p> <code>fields</code> <code>list[FieldSchema]</code> <p>list[FieldSchema]: All scalar (non-vector) fields in the schema.</p> <code>vectors</code> <code>list[VectorSchema]</code> <p>list[VectorSchema]: All vector fields in the schema.</p>"},{"location":"schema/#zvec.model.schema.CollectionSchema(name)","title":"<code>name</code>","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema(fields)","title":"<code>fields</code>","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema(vectors)","title":"<code>vectors</code>","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema-attributes","title":"Attributes","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>str: The name of the collection.</p>"},{"location":"schema/#zvec.model.schema.CollectionSchema.fields","title":"fields  <code>property</code>","text":"<pre><code>fields: list[FieldSchema]\n</code></pre> <p>list[FieldSchema]: All scalar (non-vector) fields in the schema.</p>"},{"location":"schema/#zvec.model.schema.CollectionSchema.vectors","title":"vectors  <code>property</code>","text":"<pre><code>vectors: list[VectorSchema]\n</code></pre> <p>list[VectorSchema]: All vector fields in the schema.</p>"},{"location":"schema/#zvec.model.schema.CollectionSchema-functions","title":"Functions","text":""},{"location":"schema/#zvec.model.schema.CollectionSchema.field","title":"field","text":"<pre><code>field(name: str) -&gt; Optional[FieldSchema]\n</code></pre> <p>Retrieve a scalar field by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the field.</p> required <p>Returns:</p> Type Description <code>Optional[FieldSchema]</code> <p>Optional[FieldSchema]: The field if found, otherwise None.</p>"},{"location":"schema/#zvec.model.schema.CollectionSchema.vector","title":"vector","text":"<pre><code>vector(name: str) -&gt; Optional[VectorSchema]\n</code></pre> <p>Retrieve a vector field by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the vector field.</p> required <p>Returns:</p> Type Description <code>Optional[VectorSchema]</code> <p>Optional[VectorSchema]: The vector field if found, otherwise None.</p>"},{"location":"schema/#zvec.model.schema.FieldSchema","title":"FieldSchema","text":"<pre><code>FieldSchema(\n    name: str,\n    data_type: DataType,\n    nullable: bool = False,\n    index_param: Optional[InvertIndexParam] = None,\n)\n</code></pre> <p>Represents a scalar (non-vector) field in a collection schema.</p> <p>A <code>FieldSchema</code> defines the name, data type, nullability, and optional inverted index configuration for a regular field (e.g., ID, timestamp, category).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the field. Must be unique within the collection.</p> required <code>DataType</code> <p>Data type of the field (e.g., INT64, STRING).</p> required <code>bool</code> <p>Whether the field can contain null values. Defaults to False.</p> <code>False</code> <code>Optional[InvertIndexParam]</code> <p>Inverted index parameters for this field. Only applicable to fields that support indexing (e.g., scalar fields used in filtering). Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import DataType\n&gt;&gt;&gt; from zvec.model.param import InvertIndexParam\n&gt;&gt;&gt; id_field = FieldSchema(\n...     name=\"id\",\n...     data_type=DataType.INT64,\n...     nullable=False,\n...     index_param=InvertIndexParam(enable_range_optimization=True)\n... )\n</code></pre> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>str: The name of the field.</p> <code>data_type</code> <code>DataType</code> <p>DataType: The data type of the field (e.g., INT64, STRING).</p> <code>nullable</code> <code>bool</code> <p>bool: Whether the field allows null values.</p> <code>index_param</code> <code>Optional[InvertIndexParam]</code> <p>Optional[InvertIndexParam]: Inverted index configuration, if any.</p>"},{"location":"schema/#zvec.model.schema.FieldSchema(name)","title":"<code>name</code>","text":""},{"location":"schema/#zvec.model.schema.FieldSchema(data_type)","title":"<code>data_type</code>","text":""},{"location":"schema/#zvec.model.schema.FieldSchema(nullable)","title":"<code>nullable</code>","text":""},{"location":"schema/#zvec.model.schema.FieldSchema(index_param)","title":"<code>index_param</code>","text":""},{"location":"schema/#zvec.model.schema.FieldSchema-attributes","title":"Attributes","text":""},{"location":"schema/#zvec.model.schema.FieldSchema.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>str: The name of the field.</p>"},{"location":"schema/#zvec.model.schema.FieldSchema.data_type","title":"data_type  <code>property</code>","text":"<pre><code>data_type: DataType\n</code></pre> <p>DataType: The data type of the field (e.g., INT64, STRING).</p>"},{"location":"schema/#zvec.model.schema.FieldSchema.nullable","title":"nullable  <code>property</code>","text":"<pre><code>nullable: bool\n</code></pre> <p>bool: Whether the field allows null values.</p>"},{"location":"schema/#zvec.model.schema.FieldSchema.index_param","title":"index_param  <code>property</code>","text":"<pre><code>index_param: Optional[InvertIndexParam]\n</code></pre> <p>Optional[InvertIndexParam]: Inverted index configuration, if any.</p>"},{"location":"schema/#zvec.model.schema.VectorSchema","title":"VectorSchema","text":"<pre><code>VectorSchema(\n    name: str,\n    data_type: DataType,\n    dimension: Optional[int] = 0,\n    index_param: Optional[Union[HnswIndexParam, FlatIndexParam, IVFIndexParam]] = None,\n)\n</code></pre> <p>Represents a vector field in a collection schema.</p> <p>A <code>VectorSchema</code> defines the name, data type, dimensionality, and index configuration for a vector field used in similarity search.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the vector field. Must be unique within the collection.</p> required <code>DataType</code> <p>Vector data type (e.g., VECTOR_FP32, VECTOR_INT8).</p> required <code>int</code> <p>Dimensionality of the vector. Must be &gt; 0 for dense vectors; may be <code>None</code> for sparse vectors.</p> <code>0</code> <code>Union[HnswIndexParam, IVFIndexParam, FlatIndexParam]</code> <p>Index configuration for this vector field. Defaults to <code>HnswIndexParam()</code>.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import DataType\n&gt;&gt;&gt; from zvec.model.param import HnswIndexParam\n&gt;&gt;&gt; emb_field = VectorSchema(\n...     name=\"embedding\",\n...     data_type=DataType.VECTOR_FP32,\n...     dimension=128,\n...     index_param=HnswIndexParam(ef_construction=200, m=16)\n... )\n</code></pre> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>str: The name of the vector field.</p> <code>data_type</code> <code>DataType</code> <p>DataType: The vector data type (e.g., VECTOR_FP32).</p> <code>dimension</code> <code>int</code> <p>int: The dimensionality of the vector.</p> <code>index_param</code> <code>Union[HnswIndexParam, IVFIndexParam, FlatIndexParam]</code> <p>Union[HnswIndexParam, IVFIndexParam, FlatIndexParam]: Index configuration for the vector.</p>"},{"location":"schema/#zvec.model.schema.VectorSchema(name)","title":"<code>name</code>","text":""},{"location":"schema/#zvec.model.schema.VectorSchema(data_type)","title":"<code>data_type</code>","text":""},{"location":"schema/#zvec.model.schema.VectorSchema(dimension)","title":"<code>dimension</code>","text":""},{"location":"schema/#zvec.model.schema.VectorSchema(index_param)","title":"<code>index_param</code>","text":""},{"location":"schema/#zvec.model.schema.VectorSchema-attributes","title":"Attributes","text":""},{"location":"schema/#zvec.model.schema.VectorSchema.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>str: The name of the vector field.</p>"},{"location":"schema/#zvec.model.schema.VectorSchema.data_type","title":"data_type  <code>property</code>","text":"<pre><code>data_type: DataType\n</code></pre> <p>DataType: The vector data type (e.g., VECTOR_FP32).</p>"},{"location":"schema/#zvec.model.schema.VectorSchema.dimension","title":"dimension  <code>property</code>","text":"<pre><code>dimension: int\n</code></pre> <p>int: The dimensionality of the vector.</p>"},{"location":"schema/#zvec.model.schema.VectorSchema.index_param","title":"index_param  <code>property</code>","text":"<pre><code>index_param: Union[HnswIndexParam, IVFIndexParam, FlatIndexParam]\n</code></pre> <p>Union[HnswIndexParam, IVFIndexParam, FlatIndexParam]: Index configuration for the vector.</p>"},{"location":"types/","title":"Types","text":""},{"location":"types/#zvec.typing","title":"zvec.typing","text":"<p>This module contains the basic data types of Zvec</p> <p>Modules:</p> Name Description <code>enum</code> <p>Classes:</p> Name Description <code>DataType</code> <p>Enumeration of supported data types in Zvec.</p> <code>IndexType</code> <p>Enumeration of supported index types in Zvec.</p> <code>MetricType</code> <p>Enumeration of supported distance/similarity metrics.</p> <code>QuantizeType</code> <p>Enumeration of supported quantization types for vector compression.</p> <code>Status</code> <p>Represents the outcome of a Zvec operation.</p> <code>StatusCode</code> <p>Enumeration of possible status codes for Zvec operations.</p>"},{"location":"types/#zvec.typing-classes","title":"Classes","text":""},{"location":"types/#zvec.typing.DataType","title":"DataType","text":"<pre><code>DataType(value: SupportsInt)\n</code></pre> <p>Enumeration of supported data types in Zvec.</p> <p>Includes scalar types, dense/sparse vector types, and array types.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; print(zvec.DataType.FLOAT)\nDataType.FLOAT\n&gt;&gt;&gt; print(zvec.DataType.VECTOR_FP32)\nDataType.VECTOR_FP32\n</code></pre> <p>Members:</p> <p>STRING</p> <p>BOOL</p> <p>INT32</p> <p>INT64</p> <p>FLOAT</p> <p>DOUBLE</p> <p>UINT32</p> <p>UINT64</p> <p>VECTOR_FP16</p> <p>VECTOR_FP32</p> <p>VECTOR_FP64</p> <p>VECTOR_INT8</p> <p>SPARSE_VECTOR_FP32</p> <p>SPARSE_VECTOR_FP16</p> <p>ARRAY_STRING</p> <p>ARRAY_INT32</p> <p>ARRAY_INT64</p> <p>ARRAY_FLOAT</p> <p>ARRAY_DOUBLE</p> <p>ARRAY_BOOL</p> <p>ARRAY_UINT32</p> <p>ARRAY_UINT64</p>"},{"location":"types/#zvec.typing.IndexType","title":"IndexType","text":"<pre><code>IndexType(value: SupportsInt)\n</code></pre> <p>Enumeration of supported index types in Zvec.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; print(zvec.IndexType.HNSW)\nIndexType.HNSW\n</code></pre> <p>Members:</p> <p>UNDEFINED</p> <p>HNSW</p> <p>IVF</p> <p>FLAT</p> <p>INVERT</p>"},{"location":"types/#zvec.typing.MetricType","title":"MetricType","text":"<pre><code>MetricType(value: SupportsInt)\n</code></pre> <p>Enumeration of supported distance/similarity metrics.</p> <ul> <li>COSINE: Cosine similarity.</li> <li>IP: Inner product (dot product).</li> <li>L2: Euclidean distance (L2 norm).</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; print(zvec.MetricType.COSINE)\nMetricType.COSINE\n</code></pre> <p>Members:</p> <p>COSINE</p> <p>IP</p> <p>L2</p>"},{"location":"types/#zvec.typing.QuantizeType","title":"QuantizeType","text":"<pre><code>QuantizeType(value: SupportsInt)\n</code></pre> <p>Enumeration of supported quantization types for vector compression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import zvec\n&gt;&gt;&gt; print(zvec.QuantizeType.INT8)\nQuantizeType.INT8\n</code></pre> <p>Members:</p> <p>UNDEFINED</p> <p>FP16</p> <p>INT8</p> <p>INT4</p>"},{"location":"types/#zvec.typing.Status","title":"Status","text":"<p>Represents the outcome of a Zvec operation.</p> <p>A <code>Status</code> object is either OK (success) or carries an error code and message.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from zvec.typing import Status, StatusCode\n&gt;&gt;&gt; s = Status()\n&gt;&gt;&gt; print(s.ok())\nTrue\n&gt;&gt;&gt; s = Status(StatusCode.INVALID_ARGUMENT, \"Field not found\")\n&gt;&gt;&gt; print(s.code() == StatusCode.INVALID_ARGUMENT)\nTrue\n&gt;&gt;&gt; print(s.message())\nField not found\n</code></pre> <p>Methods:</p> Name Description <code>OK</code> <p>Create an OK status.</p> <code>code</code> <p>StatusCode: Returns the status code.</p> <code>message</code> <p>str: Returns the error message (may be empty).</p> <code>ok</code> <p>bool: Returns True if the status is OK.</p>"},{"location":"types/#zvec.typing.Status-functions","title":"Functions","text":""},{"location":"types/#zvec.typing.Status.OK","title":"OK  <code>staticmethod</code>","text":"<pre><code>OK() -&gt; Status\n</code></pre> <p>Create an OK status.</p>"},{"location":"types/#zvec.typing.Status.code","title":"code","text":"<pre><code>code() -&gt; StatusCode\n</code></pre> <p>StatusCode: Returns the status code.</p>"},{"location":"types/#zvec.typing.Status.message","title":"message","text":"<pre><code>message() -&gt; str\n</code></pre> <p>str: Returns the error message (may be empty).</p>"},{"location":"types/#zvec.typing.Status.ok","title":"ok","text":"<pre><code>ok() -&gt; bool\n</code></pre> <p>bool: Returns True if the status is OK.</p>"},{"location":"types/#zvec.typing.StatusCode","title":"StatusCode","text":"<pre><code>StatusCode(value: SupportsInt)\n</code></pre> <p>Enumeration of possible status codes for Zvec operations.</p> <p>Used by the <code>Status</code> class to indicate success or failure reason.</p> <p>Members:</p> <p>OK</p> <p>NOT_FOUND</p> <p>ALREADY_EXISTS</p> <p>INVALID_ARGUMENT</p> <p>PERMISSION_DENIED</p> <p>FAILED_PRECONDITION</p> <p>RESOURCE_EXHAUSTED</p> <p>UNAVAILABLE</p> <p>INTERNAL_ERROR</p> <p>NOT_SUPPORTED</p> <p>UNKNOWN</p>"}]}