# Benchmarks















import { Step, Steps } from 'fumadocs-ui/components/steps';

**Zvec** is engineered for speed, scale, and efficiency ‚Äî and has been battle-tested across demanding production workloads within Alibaba Group.

Below, we present benchmark results that demonstrate how our system performs under various workloads and configurations.

All tests were conducted in controlled environments using standardized datasets and widely accepted methodologies to ensure fairness, transparency, and reproducibility.

## Performance Evaluation

We evaluate Zvec using [**VectorDBBench**](https://github.com/zilliztech/VectorDBBench), an open-source benchmarking framework widely adopted in the vector database community.

Our evaluation focus on two standard datasets:

* **Cohere 1M**: 1 million 768-dimensional vectors
* **Cohere 10M**: 10 million 768-dimensional vectors

For each dataset, we measure the following key performance indicators:

* **Queries Per Second (QPS)**: Throughput under sustained load.
* **Recall**: Accuracy of nearest neighbor retrieval, reflecting search quality.
* **Index Build Time (load duration)**: Time required to ingest and index the full dataset, indicating ingestion efficiency.

### Cohere 10M Benchmark Results

<img alt="QPS Cohere 10M" src={__img0} />

<img alt="Recall Cohere 10M" src={__img1} />

<img alt="Load Duration Cohere 10M" src={__img2} />

### Cohere 1M Benchmark Results

<img alt="QPS Cohere 1M" src={__img3} />

<img alt="Recall Cohere 1M" src={__img4} />

<img alt="Load Duration Cohere 1M" src={__img5} />

## Reproducing the Benchmarks

Follow these steps to reproduce our benchmark results in your own environment.

<Steps>
  <Step>
    ### Prepare environment
  </Step>

  1. **Launch an ECS Instance**

     <Callout className="text-base" type="info">
       We recommend using **Ubuntu 24.04** as the operating system. Other OS choices may require adjustments to the commands in this guide.
     </Callout>

     * Create a **g9i.4xlarge** instance (16 vCPU, 64 GiB RAM) following [this guide](https://help.aliyun.com/zh/ecs/user-guide/quickly-purchase-a-windows-instance-and-build-an-iis-service?spm=a2c4g.11186623.0.0.5ded5144WlIwMl)

  2. **Install System Dependencies**
     * Install git if not already installed

       ```bash
       apt-get update
       apt install git
       ```

     * Install Python3.11 or higher

       ```bash
       apt-get update
       apt install python3-full python3-venv python3-dev

       cd /opt
       python3 -m venv venv
       source venv/bin/activate
       ```

  3. **Install [VectorDBBench](https://github.com/zilliztech/VectorDBBench)**

     ```bash
     # Clone VectorDBBench
     git clone https://github.com/zilliztech/VectorDBBench.git
     cd VectorDBBench

     # Install deps
     pip install -U pip
     pip install -e .

     # If you experience slow downloads or connection issues, you can try Aliyun PyPI mirror
     # pip install -U pip -i https://mirrors.aliyun.com/pypi/simple
     # pip install -e . -i https://mirrors.aliyun.com/pypi/simple
     ```

  4. **Install zvec**

     ```bash
     pip install zvec==v0.1.1
     ```

  <Step>
    ### Run Benchmarks
  </Step>

  #### Cohere 10M

  1. **Build Index**

     ```bash
     vectordbbench zvec --path Performance768D10M --db-label 16c64g-v0.1 --case-type Performance768D10M --num-concurrency 12,14,16,18,20 --quantize-type int8 --m 50 --ef-search 118 --is-using-refiner
     ```

  2. **Run Benchmark**

     ```bash
     vectordbbench zvec --path Performance768D10M --db-label 16c64g-v0.1 --case-type Performance768D10M --num-concurrency 12,14,16,18,20 --quantize-type int8 --m 50 --ef-search 118 --is-using-refiner --skip-drop-old --skip-load
     ```

  #### Cohere 1M

  1. **Build Index**

     ```bash
     vectordbbench zvec --path Performance768D1M --db-label 16c64g-v0.1 --case-type Performance768D1M --num-concurrency 12,14,16,18,20 --quantize-type int8 --m 15 --ef-search 180
     ```

  2. **Run Benchmark**

     ```bash
     vectordbbench zvec --path Performance768D1M --db-label 16c64g-v0.1 --case-type Performance768D1M --num-concurrency 12,14,16,18,20 --quantize-type int8 --m 15 --ef-search 180 --skip-drop-old --skip-load
     ```
</Steps>


# Building from Source



If you'd like to build **Zvec** from source, you can clone the repository and install it locally.

## Install from Source

<Callout className="text-base" type="info">
  The repository uses **Git submodules**. Cloning may take a few minutes depending on your network speed.
</Callout>

```bash
# Clone the repository
git clone --recurse-submodules https://github.com/alibaba/zvec.git
cd zvec

# Install from source
pip install .
```

## Build Requirements

* Python 3.9 or higher
* **Supported platforms**: Linux (ARM64/x86\_64) or macOS (ARM64/x86\_64)
* C++17 compatible compiler
* **scikit-build** (installed automatically as a build dependency, but may require manual configuration in some environments)

  <Callout className="text-base" type="idea">
    **Troubleshooting Tips**:

    * If you encounter issues during the build process, try setting a custom build directory for **scikit-build**.\
      This can help avoid cache inconsistencies and makes it easier to inspect detailed build logs:

      ```bash
      export SKBUILD_BUILD_DIR=/tmp/build  # Or other directory
      pip install .
      ```

      After the build attempt, you can examine the contents of **/tmp/build** (or your chosen directory) to review compiler output and diagnose errors.

    * By default, **scikit-build** uses **Ninja** as the build system. To use **Unix Makefiles** instead, set:

      ```bash
      export CMAKE_GENERATOR="Unix Makefiles"
      pip install .
      ```
  </Callout>


# Configuration



Before performing any database operations, you can optionally configure global settings using the `init()` function.

* If omitted, Zvec automatically applies sensible defaults ‚Äî typically tuned to your system's available memory, CPU, and environment.
* Use `init()` when you need to customize settings, such as
  * Adjusting log verbosity or output format
  * Controlling concurrency (e.g., query thread count)

<Callout className="text-base" type="info">
  Call `init()` once, and only at application startup ‚Äî before any collections are created or opened. It is not intended for runtime reconfiguration.
</Callout>

## Configuration Example

```python title="Global configuration"
import zvec

# [!code word:init]
zvec.init(
    log_type=zvec.LogType.CONSOLE,
    log_level=zvec.LogLevel.WARN,
    query_threads=4,
)
```

* Logs messages to the **console** at `WARN` level or higher.
* Limits query execution to 4 threads.

For a complete list of configuration options and advanced tuning parameters, please refer to the <a href="/api-reference/">API Reference</a>.


# Embedding



This page introduces **Zvec's embedding function system** for converting text into vector representations. It provides multiple **out-of-the-box implementations** and supports **custom extensions** to integrate your own models.

<Callout type="info" className="text-base">
  **Current Support:** Zvec currently supports **text modality** embeddings only. Support for other modalities (images, audio, etc.) may be added in future releases.
</Callout>

<Callout type="warn" className="text-base">
  **Note for users in mainland China:** To download models from Hugging Face more reliably, configure the mirror endpoint before running Python:

  ```bash
  export HF_ENDPOINT=https://hf-mirror.com
  ```
</Callout>

<Callout type="info" className="text-base">
  **Dependencies:** To run the examples in this document, install the following packages first:

  ```bash
  pip install openai dashscope dashtext sentence-transformers
  ```
</Callout>

## Overview

Zvec's embedding system provides ready-to-use **embedding functions** to convert text into vector representations for similarity search.

### Embedding Function Types

| Type             | Implementation                | Description                                                                       |
| ---------------- | ----------------------------- | --------------------------------------------------------------------------------- |
| **Local Dense**  | `DefaultLocalDenseEmbedding`  | Uses Sentence Transformers with `all-MiniLM-L6-v2` model (384 dimensions, \~80MB) |
| **Local Sparse** | `DefaultLocalSparseEmbedding` | Uses SPLADE `naver/splade-cocondenser-ensembledistil` model (\~100MB)             |
| **BM25**         | `BM25EmbeddingFunction`       | BM25 algorithm using DashText SDK (local computation, no API key needed)          |
| **Qwen Dense**   | `QwenDenseEmbedding`          | Uses Qwen Dashscope API                                                           |
| **Qwen Sparse**  | `QwenSparseEmbedding`         | Uses Qwen Dashscope API                                                           |
| **OpenAI Dense** | `OpenAIDenseEmbedding`        | Uses OpenAI API                                                                   |

## Dense Embedding

Dense embeddings capture semantic meaning in fixed-length continuous vectors.

### 1. DefaultLocalDenseEmbedding - Local Dense Embedding

Uses the Sentence Transformers library with the `all-MiniLM-L6-v2` model to generate 384-dimensional dense vectors.

**Model Details:**

* Model: `all-MiniLM-L6-v2` (HuggingFace) or `iic/nlp_gte_sentence-embedding_chinese-small` (ModelScope for Chinese)
* Dimensions: 384
* Size: \~80MB

```python
from zvec.extension import DefaultLocalDenseEmbedding

# Basic usage (international users)
embedding_func = DefaultLocalDenseEmbedding()
vector = embedding_func.embed("Hello, world!")
print(f"Dimensions: {len(vector)}")  # 384

# Chinese users: recommended to use ModelScope
embedding_func = DefaultLocalDenseEmbedding(model_source="modelscope")
vector = embedding_func.embed("‰Ω†Â•ΩÔºå‰∏ñÁïåÔºÅ")

# Batch processing
texts = ["Text 1", "Text 2", "Text 3"]
vectors = [embedding_func.embed(text) for text in texts]

# Semantic similarity computation
import numpy as np
v1 = embedding_func.embed("The cat sits on the mat")
v2 = embedding_func.embed("A cat is resting on the mat")
similarity = np.dot(v1, v2)  # Normalized vectors, dot product = cosine similarity
print(f"Similarity: {similarity:.4f}")
```

### 2. QwenDenseEmbedding - Dashscope API Dense Embedding

Uses Qwen's Dashscope embedding API.

**Note:** Requires Dashscope API key, and **dimension must be specified explicitly**.

```python
from zvec.extension import QwenDenseEmbedding

# API key required
embedding_func = QwenDenseEmbedding(
    api_key="your-dashscope-api-key",
    model="text-embedding-v4",   # Optional, uses latest model by default
    dimension=256,               # Required: embedding dimension
)

vector = embedding_func.embed("Vector database")
print(f"Dimensions: {embedding_func.dimension}")  # 256
```

### 3. OpenAIDenseEmbedding - OpenAI API Dense Embedding

Uses OpenAI's embedding API.

```python
from zvec.extension import OpenAIDenseEmbedding

embedding_func = OpenAIDenseEmbedding(
    api_key="your-openai-api-key",
    model="text-embedding-4",  # Optional, uses latest model by default
    dimension=256,            # Required: embedding dimension
)

vector = embedding_func.embed("Vector database")
```

## Sparse Embedding

Sparse embeddings represent text with high-dimensional sparse vectors, ideal for lexical matching.

### 1. DefaultLocalSparseEmbedding - Local Sparse Embedding

Uses the SPLADE model to generate sparse vectors, suitable for lexical matching and hybrid retrieval.

**Model Details:**

* Model: `naver/splade-cocondenser-ensembledistil`
* Size: \~100MB
* Output: Sparse dictionary format

```python
from zvec.extension import DefaultLocalSparseEmbedding

# Query embedding (for search queries)
query_embedding = DefaultLocalSparseEmbedding(encoding_type="query")
query_vec = query_embedding.embed("machine learning algorithms")

# Document embedding (for document indexing)
doc_embedding = DefaultLocalSparseEmbedding(encoding_type="document")
doc_vec = doc_embedding.embed("Machine learning is a subfield of artificial intelligence")

# Sparse vector format: {dimension_index: weight}
print(f"Non-zero dimensions: {len(query_vec)}")
print(f"First 5 dimensions: {list(query_vec.items())[:5]}")

# Clear model cache
DefaultLocalSparseEmbedding.clear_cache()
```

### 2. BM25EmbeddingFunction - DashText SDK BM25 Sparse Embedding

Uses DashText's local BM25 encoder for lexical matching. **No API key or network connectivity required.**

**Two Options:**

* **Built-in encoder** (recommended for general use): Pre-trained models for Chinese (`language="zh"`) and English (`language="en"`)
* **Custom encoder**: Train on your own corpus for domain-specific terminology with BM25 parameters (`b`, `k1`)

```python
from zvec.extension import BM25EmbeddingFunction

# Option 1: Using built-in encoder (no corpus needed)
# For Chinese query encoding
bm25_query_zh = BM25EmbeddingFunction(language="zh", encoding_type="query")
query_vec = bm25_query_zh.embed("Ê∑±Â∫¶Â≠¶‰π†Á•ûÁªèÁΩëÁªú")

# For Chinese document encoding
bm25_doc_zh = BM25EmbeddingFunction(language="zh", encoding_type="document")
doc_vec = bm25_doc_zh.embed("Êú∫Âô®Â≠¶‰π†ÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈáçË¶ÅÂàÜÊîØ")

# For English query encoding
bm25_query_en = BM25EmbeddingFunction(language="en", encoding_type="query")
query_vec_en = bm25_query_en.embed("deep learning neural networks")

# Option 2: Using custom corpus for better domain accuracy
corpus = [
    "Machine learning is an important branch of artificial intelligence",
    "Deep learning uses neural networks",
    "Natural language processing handles text data"
]

bm25_custom = BM25EmbeddingFunction(
    corpus=corpus,
    encoding_type="query",
    b=0.75,   # Document length normalization
    k1=1.2    # Term frequency saturation
)

query_vec = bm25_custom.embed("deep learning neural networks")
```

### 3. QwenSparseEmbedding - Dashscope API Sparse Embedding

<Callout type="info" className="text-base">
  **Requires Dashscope API key.** Visit [Dashscope Console](https://dashscope.console.aliyun.com/) to get your API key.
</Callout>

```python
from zvec.extension import QwenSparseEmbedding

embedding_func = QwenSparseEmbedding(
    api_key="your-dashscope-api-key",
    dimension=256,  # dashscope api required input dimension
)
sparse_vec = embedding_func.embed("sparse vector")
```

## Custom Implementation Guide

Learn how to create your own embedding functions.

### Custom Embedding Functions

Zvec provides **protocol base classes** and **framework-specific base classes** for custom embeddings:

**Protocol Base Classes:**

* `DenseEmbeddingFunction[T]`: Protocol for dense embeddings
* `SparseEmbeddingFunction[T]`: Protocol for sparse embeddings

**Framework-Specific Base Classes:**

* `SentenceTransformerFunctionBase`: Base class for Sentence Transformers models (in `sentence_transformer_function.py`)
* `QwenFunctionBase`: Base class for Qwen Dashscope API (in `qwen_function.py`)

### Example 1: Custom Dense Embedding from Scratch

```python
from zvec.extension import DenseEmbeddingFunction
from zvec.common.constants import TEXT, DenseVectorType
from typing import Optional
import numpy as np


class MyCustomDenseEmbedding(DenseEmbeddingFunction[TEXT]):
    """Custom dense embedding function example"""
    
    def __init__(self, model_name: str = "custom-model", **kwargs):
        self._model_name = model_name
        self._dimension = 768  # Custom dimension
        self._extra_params = kwargs
        # Initialize your model
        self._model = self._load_model()
    
    @property
    def dimension(self) -> int:
        """Return embedding vector dimension"""
        return self._dimension
    
    @property
    def extra_params(self) -> dict:
        """Return extra parameters"""
        return self._extra_params
    
    def _load_model(self):
        """Load your custom model"""
        # Implement your model loading logic here
        # e.g., return YourModelClass.from_pretrained(self._model_name)
        pass
    
    def embed(self, input: str) -> DenseVectorType:
        """
        Generate dense embedding vector
        
        Args:
            input: Input text
            
        Returns:
            DenseVectorType: List of floats, length = self.dimension
        """
        # Input validation
        if not isinstance(input, str):
            raise TypeError(f"Expected str, got {type(input).__name__}")
        
        input = input.strip()
        if not input:
            raise ValueError("Input cannot be empty")
        
        # Generate embedding using your model
        # embedding = self._model.encode(input)
        # return embedding.tolist()
        
        # Example: return random vector
        return np.random.randn(self._dimension).tolist()
    
    def __call__(self, input: str) -> DenseVectorType:
        """Make the function callable"""
        return self.embed(input)


# Use custom embedding
custom_emb = MyCustomDenseEmbedding(model_name="my-model")
vector = custom_emb.embed("Test text")
print(f"Dimensions: {len(vector)}")
```

### Example 2: Custom Sparse Embedding from Scratch

```python
from zvec.extension import SparseEmbeddingFunction
from zvec.common.constants import TEXT, SparseVectorType
from typing import Dict


class MyCustomSparseEmbedding(SparseEmbeddingFunction[TEXT]):
    """Custom sparse embedding function example"""
    
    def __init__(self, vocab_size: int = 30000, **kwargs):
        self._vocab_size = vocab_size
        self._extra_params = kwargs
        self._tokenizer = self._load_tokenizer()
    
    @property
    def extra_params(self) -> dict:
        return self._extra_params
    
    def _load_tokenizer(self):
        """Load tokenizer"""
        # Implement your tokenizer loading logic
        pass
    
    def embed(self, input: str) -> SparseVectorType:
        """
        Generate sparse embedding vector
        
        Args:
            input: Input text
            
        Returns:
            SparseVectorType: Dictionary {dimension_index: weight}, contains only non-zero values
        """
        if not isinstance(input, str):
            raise TypeError(f"Expected str, got {type(input).__name__}")
        
        input = input.strip()
        if not input:
            raise ValueError("Input cannot be empty")
        
        # Implement your sparse embedding logic
        # tokens = self._tokenizer.tokenize(input)
        # sparse_vec = self._compute_sparse_representation(tokens)
        
        # Example: return simple term frequency vector
        sparse_vec = {
            100: 0.5,
            250: 1.2,
            500: 0.8
        }
        
        # Ensure sorted by index
        return dict(sorted(sparse_vec.items()))
    
    def __call__(self, input: str) -> SparseVectorType:
        return self.embed(input)


# Use custom sparse embedding
sparse_emb = MyCustomSparseEmbedding(vocab_size=50000)
sparse_vec = sparse_emb.embed("Test text")
print(f"Non-zero dimensions: {len(sparse_vec)}")
```

### Example 3: Using SentenceTransformerFunctionBase

If you want to use a different Sentence Transformers model, you can inherit from `SentenceTransformerFunctionBase`:

```python
from zvec.extension.sentence_transformer_function import SentenceTransformerFunctionBase
from zvec.extension import DenseEmbeddingFunction
from zvec.common.constants import TEXT, DenseVectorType
from typing import Literal, Optional


class CustomSentenceTransformerEmbedding(
    SentenceTransformerFunctionBase, 
    DenseEmbeddingFunction[TEXT]
):
    """Using custom Sentence Transformer model"""
    
    def __init__(
        self,
        model_name: str = "all-mpnet-base-v2",  # Use a different model
        model_source: Literal["huggingface", "modelscope"] = "huggingface",
        normalize_embeddings: bool = True,
        **kwargs
    ):
        # Initialize base class
        SentenceTransformerFunctionBase.__init__(
            self, 
            model_name=model_name,
            model_source=model_source,
        )
        
        self._normalize_embeddings = normalize_embeddings
        self._extra_params = kwargs
        
        # Load model and get dimension
        model = self._get_model()
        self._dimension = model.get_sentence_embedding_dimension()
    
    @property
    def dimension(self) -> int:
        return self._dimension
    
    @property
    def extra_params(self) -> dict:
        return self._extra_params
    
    def embed(self, input: str) -> DenseVectorType:
        if not isinstance(input, str):
            raise TypeError(f"Expected str, got {type(input).__name__}")
        
        input = input.strip()
        if not input:
            raise ValueError("Input cannot be empty")
        
        model = self._get_model()
        embedding = model.encode(
            input,
            convert_to_numpy=True,
            normalize_embeddings=self._normalize_embeddings
        )
        
        return embedding.tolist()
    
    def __call__(self, input: str) -> DenseVectorType:
        return self.embed(input)


# Use custom model
# Use larger MPNet model (768 dimensions)
custom_emb = CustomSentenceTransformerEmbedding(
    model_name="all-mpnet-base-v2"
)
vector = custom_emb.embed("High-quality text embedding")
print(f"Dimensions: {len(vector)}")  # 768

# Use multilingual model
multilingual_emb = CustomSentenceTransformerEmbedding(
    model_name="paraphrase-multilingual-MiniLM-L12-v2"
)
```

### Example 4: Using QwenFunctionBase

If you want to implement custom embeddings using Qwen Dashscope API:

```python
from zvec.extension.qwen_function import QwenFunctionBase
from zvec.extension import DenseEmbeddingFunction
from zvec.common.constants import TEXT, DenseVectorType
from typing import Optional


class CustomQwenEmbedding(QwenFunctionBase, DenseEmbeddingFunction[TEXT]):
    """Custom Qwen embedding implementation"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "text-embedding-v3",
        **kwargs
    ):
        # Initialize base class with API key
        QwenFunctionBase.__init__(self, api_key=api_key)
        
        self._model = model
        self._extra_params = kwargs
        self._dimension = None  # Will be set after first call
    
    @property
    def dimension(self) -> int:
        if self._dimension is None:
            # Get dimension from first embedding call
            test_result = self.embed("test")
            self._dimension = len(test_result)
        return self._dimension
    
    @property
    def extra_params(self) -> dict:
        return self._extra_params
    
    def embed(self, input: str) -> DenseVectorType:
        if not isinstance(input, str):
            raise TypeError(f"Expected str, got {type(input).__name__}")
        
        input = input.strip()
        if not input:
            raise ValueError("Input cannot be empty")
        
        # Use the base class's embed_text method
        result = self._embed_text(
            text=input,
            model=self._model
        )
        
        return result
    
    def __call__(self, input: str) -> DenseVectorType:
        return self.embed(input)


# Use custom Qwen embedding
custom_qwen_emb = CustomQwenEmbedding(
    api_key="your-dashscope-api-key",
    model="text-embedding-v3"
)
vector = custom_qwen_emb.embed("Custom Qwen embedding")
```

## Best Practices

Follow these patterns to build effective search pipelines.

### 1. Hybrid Search (Multi-Vector Retrieval)

Combine dense and sparse embeddings for best retrieval performance:

```python
from zvec.extension import (
    DefaultLocalDenseEmbedding,
    DefaultLocalSparseEmbedding,
    RrfReRanker
)

# Create embedding functions
dense_emb = DefaultLocalDenseEmbedding()
sparse_emb = DefaultLocalSparseEmbedding(encoding_type="query")

# Query text
query = "What is a vector database"

# Generate both embeddings
dense_vec = dense_emb.embed(query)
sparse_vec = sparse_emb.embed(query)

# Fuse results using RRF
rrf_ranker = RrfReRanker(topn=3)

# Retrieve using both vectors separately (pseudo-code)
final_results = zvec.collection.query(
    vectors=[
        VectorQuery("dense", vector=dense_vec),
        VectorQuery("sparse", vector=dense_vec),
    ],
    topk=10,
    reranker=rrf_ranker,
)
```

### 2. Network Configuration for Chinese Users

For users in mainland China, configure network settings to download models reliably:

```python
import os
from zvec.extension import DefaultLocalDenseEmbedding

# Option 1: Use ModelScope
embedding = DefaultLocalDenseEmbedding(model_source="modelscope")

# Option 2: Use Hugging Face mirror in Python
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
embedding = DefaultLocalDenseEmbedding(model_source="huggingface")
```

## Important Notes

<Callout type="warn" className="text-base">
  **Key Considerations:**

  1. **Model Download**: Models will be downloaded on first use. Ensure network connectivity.
  2. **Memory Management**: Local models consume memory. Call `clear_cache()` to release memory after use.
  3. **API Rate Limiting**: When using API-based functions (Qwen, OpenAI), be mindful of quotas and rate limits.
  4. **Thread Safety**: Embedding functions are thread-safe and can be used in multi-threaded environments.
  5. **Text Only**: Currently, Zvec only supports text modality embeddings. Support for other modalities may be added in future releases.
</Callout>

## Related Documentation

Explore the source code and implementation details:

* [Dense Embedding Function Protocol](https://zvec.org/api-reference/python/extension/#zvec.extension.DenseEmbeddingFunction)
* [Sparse Embedding Function Protocol](https://zvec.org/api-reference/python/extension/#zvec.extension.SparseEmbeddingFunction)
* [Sentence Transformers Base Class](https://zvec.org/api-reference/python/extension/#zvec.extension.SentenceTransformerFunctionBase)
* [Qwen Function Base Class](https://zvec.org/api-reference/python/extension/#zvec.extension.QwenFunctionBase)
* [Openai Function Base Class](https://zvec.org/api-reference/python/extension/#zvec.extension.OpenAIFunctionBase)


# Overview



import { LayoutTemplate, Rocket } from 'lucide-react';

**Zvec** is an open-source, fast, lightweight, and feature-rich vector database that runs entirely **in-process** ‚Äî no server, daemon, or external infrastructure required. Just [install](./quickstart/#installation) the package and start indexing and querying vectors right away üöÄ.

[Vector](./concepts/vector-embedding/) databases are commonly used to power AI applications like semantic search, retrieval-augmented generation (RAG), recommendation systems, and other similarity-based workflows.

Zvec can serve as a **standalone vector database** for end-to-end storage and search, or it can be **seamlessly integrated into existing search systems** (such as traditional SQL databases) as a dedicated vector search engine.

Built on **Proxima** ‚Äî Alibaba Group's high-performance, production-grade vector search engine ‚Äî Zvec delivers **low-latency**, **scalable**, and **battle-tested** similarity search. With its minimal-dependency, in-process design, Zvec is well-suited for virtually any scenario:

* üíª From **rapid prototyping** and **local development**
* üì± To **embedded applications** and **edge deployments**
* üåê All the way to **billion-scale, production-grade systems**

## Key Features

* ‚ö° **Blazing Fast**: Scale to billions of vectors with sub-millisecond search latency.
* üß© **Simple, Just Works**: A single package is all you need ‚Äî install it and start searching in seconds. No servers, no config, no fuss.
* ‚ú® **Dense + Sparse Vectors**: Work with both dense and sparse embeddings, with native support for multi-vector queries in a single call.
* üéØ **Hybrid Search**: Combine semantic similarity with structured filters for precise results.
* üì¶ **Runs Anywhere**: As an in-process library, Zvec runs wherever your code runs ‚Äî notebooks, servers, CLI tools, or even edge devices.

## What is Next?

<Cards>
  <Card title="Quickstart" href="./quickstart/" description="Get started with Zvec in minutes" icon={<Rocket />} />

  <Card title="Data Modeling" href="./concepts/data-modeling/" description="Learn how Zvec manages vector and scalar data" icon={<LayoutTemplate />} />
</Cards>


# Quickstart



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

<Callout className="text-base" type="success">
  Want to explore the code examples **interactively**? Check out our [Jupyter Notebook walkthrough](/downloads/walkthrough.zip) that demonstrates **Zvec** in action ‚Äî including a hands-on multi-modal image search example.
</Callout>

## Installation

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```bash
    pip install zvec
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```bash
    npm install @zvec/zvec
    ```
  </CodeBlockTab>
</CodeBlockTabs>

## Create a Collection

A [collection](../collections/) stores your documents. Each [document](../concepts/data-modeling/#documents) contains scalar fields and [vector embeddings](../concepts/vector-embedding/).

Define a schema and create a collection:

<Accordions type="single">
  <Accordion title="Code">
    A schema has two parts: `fields` for scalar data and `vectors` for vector embeddings.

    <CodeBlockTabs defaultValue="Python">
      <CodeBlockTabsList>
        <CodeBlockTabsTrigger value="Python">
          Python
        </CodeBlockTabsTrigger>

        <CodeBlockTabsTrigger value="Node.js">
          Node.js
        </CodeBlockTabsTrigger>
      </CodeBlockTabsList>

      <CodeBlockTab value="Python">
        ```python  title="Create a collection"
        import zvec

        # [!code word:embedding]
        # [!code word:publish_year]
        collection_schema = zvec.CollectionSchema(    # Define a collection schema [!code highlight]
            name="my_collection",
            fields=[
                zvec.FieldSchema(
                    name="publish_year",
                    data_type=zvec.DataType.INT32,
                    index_param=zvec.InvertIndexParam(enable_range_optimization=True),
                ),
            ],
            vectors=[
                zvec.VectorSchema(
                    name="embedding",
                    data_type=zvec.DataType.VECTOR_FP32,
                    dimension=768,
                    index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
                ),
            ],
        )

        collection = zvec.create_and_open(            # Create a collection [!code highlight]
            path="/path/to/my/collection",
            schema=collection_schema,
        )
        ```
      </CodeBlockTab>

      <CodeBlockTab value="Node.js">
        ```ts  title="Create a collection"
        import { ZVecCollectionSchema, ZVecCreateAndOpen, ZVecDataType, ZVecIndexType, ZVecMetricType } from "@zvec/zvec"

        // [!code word:embedding]
        // [!code word:publish_year]
        // Define a collection schema
        const collectionSchema = new ZVecCollectionSchema({     // [!code highlight]
            name: "my_collection",
            fields: [
                {
                    name: "publish_year",
                    dataType: ZVecDataType.INT32,
                    indexParams: { indexType: ZVecIndexType.INVERT, enableRangeOptimization: true }
                }
            ],
            vectors: [
                {
                    name: "embedding",
                    dataType: ZVecDataType.VECTOR_FP32,
                    dimension: 768,
                    indexParams: { indexType: ZVecIndexType.HNSW, metricType: ZVecMetricType.COSINE }
                }
            ]
        })

        // Create a collection
        const collection = ZVecCreateAndOpen("/path/to/my/collection", collectionSchema)    // [!code highlight]
        ```
      </CodeBlockTab>
    </CodeBlockTabs>

    <Callout className="text-base" type="info">
      **Important**: The field names you define here (`publish_year`, `embedding`) must be used exactly as written when inserting or querying data.
    </Callout>
  </Accordion>
</Accordions>

## Add Documents

[Insert](../data-operations/insert/) documents with scalar fields and vector embeddings:

<Accordions type="single">
  <Accordion title="Code">
    <CodeBlockTabs defaultValue="Python">
      <CodeBlockTabsList>
        <CodeBlockTabsTrigger value="Python">
          Python
        </CodeBlockTabsTrigger>

        <CodeBlockTabsTrigger value="Node.js">
          Node.js
        </CodeBlockTabsTrigger>
      </CodeBlockTabsList>

      <CodeBlockTab value="Python">
        ```python  title="Insert a document"
        # [!code word:embedding]
        # [!code word:publish_year]
        collection.insert(  # [!code highlight]
            zvec.Doc(
                id="book_1",  # Unique document ID
                vectors={"embedding": [0.1] * 768}, # Replace with your actual vector
                fields={"publish_year": 1936},
            )
        )
        ```
      </CodeBlockTab>

      <CodeBlockTab value="Node.js">
        ```ts  title="Insert a document"
        // [!code word:embedding]
        // [!code word:publish_year]
        collection.insertSync({     // [!code highlight]
            id: "book_1",   // Unique document ID
            vectors: { "embedding": Array(768).fill(0.1) },  // Replace with your actual vector
            fields: { "publish_year": 1936 }
        })
        ```
      </CodeBlockTab>
    </CodeBlockTabs>

    <Callout className="text-base" type="info">
      **Important**: Field names must match exactly. The `publish_year` field and `embedding` vector must use the same names you defined in your schema.
    </Callout>
  </Accordion>
</Accordions>

## Optimize a Collection

[Optimize](../collections/optimize/) a collection to improve performance:

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```python  title="Optimize a collection"
    # [!code word:optimize]
    collection.optimize()
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```ts  title="Optimize a collection"
    // [!code word:optimizeSync]
    collection.optimizeSync()
    ```
  </CodeBlockTab>
</CodeBlockTabs>

## Retrieve a Document by ID

[Fetch](../data-operations/fetch/) a document directly by its `id`:

<Accordions type="single">
  <Accordion title="Code">
    <CodeBlockTabs defaultValue="Python">
      <CodeBlockTabsList>
        <CodeBlockTabsTrigger value="Python">
          Python
        </CodeBlockTabsTrigger>

        <CodeBlockTabsTrigger value="Node.js">
          Node.js
        </CodeBlockTabsTrigger>
      </CodeBlockTabsList>

      <CodeBlockTab value="Python">
        ```python  title="Fetch a document"
        result = collection.fetch(ids="book_1")   # [!code highlight]
        print(result)

        # {
        #     "book_1": {
        #         "id": "book_1",
        #         "score": 0.0,
        #         "fields": {"publish_year": 1936},
        #         "vectors": {"embedding": [0.1, 0.1 , ...... ]},
        #     }
        # }
        ```
      </CodeBlockTab>

      <CodeBlockTab value="Node.js">
        ```ts  title="Fetch a document"
        let result = collection.fetchSync("book_1")   // [!code highlight]
        console.log(result)

        // {
        //     book_1: {
        //         id: 'book_1',
        //         score: 0,
        //         vectors: { embedding: [Array] },
        //         fields: { publish_year: 1936 }
        //     }
        // }
        ```
      </CodeBlockTab>
    </CodeBlockTabs>
  </Accordion>
</Accordions>

## Search with Vectors

### Basic Similarity Search

Use [`query()`](../data-operations/query/) to find documents most similar to a given vector embedding:

<Accordions type="single">
  <Accordion title="Code">
    <CodeBlockTabs defaultValue="Python">
      <CodeBlockTabsList>
        <CodeBlockTabsTrigger value="Python">
          Python
        </CodeBlockTabsTrigger>

        <CodeBlockTabsTrigger value="Node.js">
          Node.js
        </CodeBlockTabsTrigger>
      </CodeBlockTabsList>

      <CodeBlockTab value="Python">
        ```python  title="Basic similarity search"
        # [!code word:embedding]
        result = collection.query(  # [!code highlight]
            zvec.VectorQuery(
                field_name="embedding",
                vector=[0.3] * 768,  # Replace with your actual vector
            ),
            topk=10,
        )
        print(result)

        # [
        #     {
        #         "id": "book_1",
        #         "score": 0.12222,
        #         "fields": {"publish_year": 1936},
        #         "vectors": {},
        #     },
        #     {
        #         "id": "book_2",
        #         "score": 0.34444,
        #         "fields": {"publish_year": 1894},
        #         "vectors": {},
        #     },
        #     ......
        #     ......
        # ]
        ```
      </CodeBlockTab>

      <CodeBlockTab value="Node.js">
        ```ts  title="Basic similarity search"
        // [!code word:embedding]
        let result = collection.querySync({   // [!code highlight]
            fieldName: "embedding",
            vector: Array(768).fill(0.3),     // Replace with your actual vector
            topk: 10
        })
        console.log(result)

        // [
        //     {
        //         id: 'book_1',
        //         score: 0.12222,
        //         vectors: {},
        //         fields: { publish_year: 1936 }
        //     },
        //     {
        //         id: 'book_2',
        //         score: 0.34444,
        //         vectors: {},
        //         fields: { publish_year: 1894 }
        //     },
        //     ......
        //     ......
        // ]
        ```
      </CodeBlockTab>
    </CodeBlockTabs>
  </Accordion>
</Accordions>

Results are ranked by similarity score.

### Filtered Similarity Search

Combine vector search with conditional filters:

<Accordions type="single">
  <Accordion title="Code">
    <CodeBlockTabs defaultValue="Python">
      <CodeBlockTabsList>
        <CodeBlockTabsTrigger value="Python">
          Python
        </CodeBlockTabsTrigger>

        <CodeBlockTabsTrigger value="Node.js">
          Node.js
        </CodeBlockTabsTrigger>
      </CodeBlockTabsList>

      <CodeBlockTab value="Python">
        ```python  title="Filtered similarity search"
        # [!code word:embedding]
        result = collection.query(        # [!code highlight]
            zvec.VectorQuery(
                field_name="embedding",
                vector=[0.3] * 768, # Replace with your actual vector
            ),
            topk=10,
            filter="publish_year > 1936", # [!code highlight]
        )
        print(result)

        # [
        #     {
        #         "id": "book_5",
        #         "score": 0.56666,
        #         "fields": {"publish_year": 1998},
        #         "vectors": {},
        #     },
        #     {
        #         "id": "book_21",
        #         "score": 0.67777,
        #         "fields": {"publish_year": 1999},
        #         "vectors": {},
        #     },
        #     ......
        #     ......
        # ]
        ```
      </CodeBlockTab>

      <CodeBlockTab value="Node.js">
        ```ts  title="Filtered similarity search"
        // [!code word:embedding]
        let result = collection.querySync({     // [!code highlight]
            fieldName: "embedding",
            vector: Array(768).fill(0.3),   // Replace with your actual vector
            topk: 10,
            filter: "publish_year > 1936"       // [!code highlight]
        })
        console.log(result)

        // [
        //     {
        //         id: 'book_5',
        //         score: 0.5666,
        //         vectors: {},
        //         fields: { publish_year: 1998 }
        //     },
        //     {
        //         id: 'book_21',
        //         score: 0.67777,
        //         vectors: {},
        //         fields: { publish_year: 1999 }
        //     },
        //     ......
        //     ......
        // ]
        ```
      </CodeBlockTab>
    </CodeBlockTabs>
  </Accordion>
</Accordions>

Only matching documents are considered during search.

## Inspect a Collection

View the collection's schema:

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```python  title="View collection schema"
    # [!code word:schema]
    print(collection.schema)
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```ts  title="View collection schema"
    // [!code word:schema]
    console.log(collection.schema.toString())
    ```
  </CodeBlockTab>
</CodeBlockTabs>

View the collection's statistics:

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```python  title="View collection statistics"
    # [!code word:stats]
    print(collection.stats)
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```ts  title="View collection statistics"
    // [!code word:stats]
    console.log(collection.stats)
    ```
  </CodeBlockTab>
</CodeBlockTabs>

## Delete a Document

[Delete](../data-operations/delete/#delete-by-ids) a document by its ID:

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```python  title="Delete a document"
    # [!code word:delete]
    collection.delete(ids="book_1")
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```ts  title="Delete a document"
    // [!code word:deleteSync]
    collection.deleteSync("book_1")
    ```
  </CodeBlockTab>
</CodeBlockTabs>

[Delete](../data-operations/delete/#delete-by-filter-condition) documents by filter condition:

<CodeBlockTabs defaultValue="Python">
  <CodeBlockTabsList>
    <CodeBlockTabsTrigger value="Python">
      Python
    </CodeBlockTabsTrigger>

    <CodeBlockTabsTrigger value="Node.js">
      Node.js
    </CodeBlockTabsTrigger>
  </CodeBlockTabsList>

  <CodeBlockTab value="Python">
    ```python  title="Delete documents by filter condition"
    # [!code word:delete_by_filter]
    collection.delete_by_filter(filter="publish_year < 1900")
    ```
  </CodeBlockTab>

  <CodeBlockTab value="Node.js">
    ```ts  title="Delete documents by filter condition"
    // [!code word:deleteByFilterSync]
    collection.deleteByFilterSync("publish_year < 1900")
    ```
  </CodeBlockTab>
</CodeBlockTabs>

***

‚ú® You're all set to store, retrieve, and search vector data with **Zvec**!

üíô Thank you for your interest in **Zvec**! We hope you enjoy exploring what **Zvec** can do!


# Reranker



This page introduces **Zvec's reranking function system** for re-ordering retrieval results to improve relevance and accuracy. It provides multiple **out-of-the-box implementations** and supports **custom extensions** to integrate your own models.

<Callout type="info" className="text-base">
  **Dependencies:** To run the examples in this document, install the following packages first:

  ```bash
  pip install openai dashscope sentence-transformers
  ```
</Callout>

## Overview

Zvec's reranking system provides ready-to-use **reranking functions** to re-order retrieval results and improve search relevance.

### Reranking Function Types

| Type                   | Implementation         | Description                                                             |
| ---------------------- | ---------------------- | ----------------------------------------------------------------------- |
| **Local Reranking**    | `DefaultLocalReRanker` | Uses Cross-Encoder `cross-encoder/ms-marco-MiniLM-L6-v2` model (\~80MB) |
| **Qwen Reranking**     | `QwenReRanker`         | Uses Qwen Dashscope API                                                 |
| **RRF Reranking**      | `RrfReRanker`          | Reciprocal Rank Fusion for multi-vector retrieval results               |
| **Weighted Reranking** | `WeightedReRanker`     | Weighted fusion for multi-vector retrieval results                      |

## Local Reranking

### DefaultLocalReRanker - Local Cross-Encoder Reranking

Uses a Cross-Encoder model for reranking.

**Model Details:**

* Model: `cross-encoder/ms-marco-MiniLM-L6-v2`
* Size: \~80MB

```python
from zvec.extension import DefaultLocalReRanker
from zvec import Doc

# Initialize reranker
reranker = DefaultLocalReRanker(
    query="What are machine learning algorithms",
    topn=5,
    rerank_field="content"  # Specify the field to rerank
)

# Prepare document list
documents = {
    "vector1": [
        Doc(
            id="1",
            fields={
                "content": "Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from data."
            },
        ),
        Doc(
            id="2",
            fields={
                "content": "The weather is nice today with clear skies and sunshine."
            },
        ),
        Doc(
            id="3",
            fields={
                "content": "Deep learning is a specialized branch of machine learning using neural networks with multiple layers."
            },
        ),
    ],
}

# Perform reranking
reranked_docs = reranker.rerank(documents)

for doc in reranked_docs:
    print(doc)
```

## API-Based Reranking

### QwenReRanker - Dashscope API Reranking

<Callout type="info" className="text-base">
  **Requires Dashscope API key.** Visit [Dashscope Console](https://dashscope.console.aliyun.com/) to get your API key.
</Callout>

```python
from zvec.extension import QwenReRanker
from zvec import Doc

reranker = QwenReRanker(
    query="What is a vector database",
    model="gte-rerank-v2",
    api_key="your-dashscope-api-key",
    topn=3,
    rerank_field="content",
)

documents = {
    "vector1": [
        Doc(
            id="1",
            fields={
                "content": "Vector databases store and retrieve vectors"
            },
        ),
        Doc(
            id="2",
            fields={
                "content": "Relational databases store structured data"
            },
        ),
        Doc(
            id="3",
            fields={
                "content": "Vector retrieval is based on similarity computation"
            },
        ),
    ],
}

# Perform reranking
reranked_docs = reranker.rerank(documents)

for doc in reranked_docs:
    print(doc)
```

## Fusion Reranking

Fusion rerankers are specifically designed for **multi-vector retrieval scenarios** where you have results from multiple embedding methods (e.g., dense + sparse).

### RrfReRanker - Reciprocal Rank Fusion

Fuses multiple retrieval results using **Reciprocal Rank Fusion (RRF)**.

<Callout type="info" className="text-base">
  **Note:** This reranker works with ranking positions only, no scores required.
</Callout>

```python
from zvec.extension import RrfReRanker
from zvec import Doc

# Prepare multiple retrieval results
documents = {
    "vector1": [
        Doc(
            id="1",
            score=0.8,
        ),
        Doc(
            id="2",
            score=0.7,
        ),
        Doc(
            id="3",
            score=0.75,
        ),
    ],
}

reranker = RrfReRanker(topn=3)
# Fuse results
fused_results = reranker.rerank(documents)
```

### WeightedReRanker - Weighted Fusion

Fuses multiple scored retrieval results according to weights.

```python
from zvec.extension import WeightedReRanker
from zvec import Doc

# Prepare multiple retrieval results
documents = {
    "vector1": [
        Doc(
            id="1",
            score=0.8,
        ),
        Doc(
            id="2",
            score=0.7,
        ),
        Doc(
            id="3",
            score=0.75,
        ),
    ],
}

reranker = WeightedReRanker(
    weights=[1.0],  # Weights for each result set
    topn=3
)

# Fuse results
fused_results = reranker.rerank(documents)
print(fused_results)
```

## Custom Implementation Guide

Learn how to create your own reranking functions.

### Custom Reranking Functions

Reranking functions need to inherit from the `RerankFunction` base class (exported as `ReRanker`).

### Example 1: Custom Reranking Function from Scratch

```python
from zvec.extension import ReRanker
from typing import List, Dict, Any, Optional


class MyCustomReRanker(ReRanker):
    """Custom reranking function example"""
    
    def __init__(
        self,
        topn: int = 10,
        model_name: str = "custom-reranker",
        **kwargs
    ):
        self._topn = topn
        self._model_name = model_name
        self._extra_params = kwargs
        self._model = self._load_model()
    
    @property
    def topn(self) -> int:
        """Return top-N"""
        return self._topn
    
    @topn.setter
    def topn(self, value: int):
        """Set top-N"""
        if value <= 0:
            raise ValueError("topn must be positive")
        self._topn = value
    
    @property
    def extra_params(self) -> dict:
        return self._extra_params
    
    def _load_model(self):
        """Load reranking model"""
        # Implement your model loading logic
        pass
    
    def rerank(
        self,
        documents: List[Dict[str, Any]],
        query: Optional[str] = None,
        rerank_field: str = "content",
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Rerank documents
        
        Args:
            documents: Document list
            query: Query text (Note: base class doesn't accept query parameter, 
                   implement in subclass if needed)
            rerank_field: Field name to use for reranking
            **kwargs: Extra parameters
            
        Returns:
            Reranked document list, preserves original fields and adds rerank score
        """
        if not documents:
            return []
        
        # Extract content to rerank
        contents = [doc.get(rerank_field, "") for doc in documents]
        
        # Compute reranking scores using your model
        # scores = self._model.predict(query, contents)
        
        # Example: random scores
        import random
        scores = [random.random() for _ in contents]
        
        # Add scores to documents
        scored_docs = []
        for doc, score in zip(documents, scores):
            doc_copy = doc.copy()
            doc_copy["rerank_score"] = score
            scored_docs.append(doc_copy)
        
        # Sort by score descending
        scored_docs.sort(key=lambda x: x["rerank_score"], reverse=True)
        
        # Return top-N
        return scored_docs[:self._topn]
    
    def __call__(
        self,
        documents: List[Dict[str, Any]],
        **kwargs
    ) -> List[Dict[str, Any]]:
        """Make the function callable"""
        return self.rerank(documents, **kwargs)


# Use custom reranker
reranker = MyCustomReRanker(topn=5, model_name="my-reranker")

documents = [
    {"id": 1, "content": "Document content 1"},
    {"id": 2, "content": "Document content 2"},
    {"id": 3, "content": "Document content 3"},
]

reranked = reranker.rerank(
    documents,
    query="Query text",
    rerank_field="content"
)

for doc in reranked:
    print(f"ID: {doc['id']}, Score: {doc['rerank_score']:.4f}")
```

### Example 2: Query-Based Reranker

```python
from zvec.extension import ReRanker
from typing import List, Dict, Any


class QueryBasedReRanker(ReRanker):
    """Reranker that requires query at initialization"""
    
    def __init__(self, query: str, topn: int = 10):
        if not query:
            raise ValueError("Query is required")
        
        self._query = query
        self._topn = topn
    
    @property
    def query(self) -> str:
        return self._query
    
    @property
    def topn(self) -> int:
        return self._topn
    
    @topn.setter
    def topn(self, value: int):
        if value <= 0:
            raise ValueError("topn must be positive")
        self._topn = value
    
    @property
    def extra_params(self) -> dict:
        return {}
    
    def rerank(
        self,
        documents: List[Dict[str, Any]],
        rerank_field: str = "content",
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Rerank documents based on query
        
        Note: query is provided at initialization, not as a parameter
        """
        if not documents:
            return []
        
        # Compute relevance using self._query and document content
        scored_docs = []
        for doc in documents:
            content = doc.get(rerank_field, "")
            # Compute relevance score
            score = self._compute_relevance(self._query, content)
            
            doc_copy = doc.copy()
            doc_copy["rerank_score"] = score
            scored_docs.append(doc_copy)
        
        # Sort and return top-N
        scored_docs.sort(key=lambda x: x["rerank_score"], reverse=True)
        return scored_docs[:self._topn]
    
    def _compute_relevance(self, query: str, content: str) -> float:
        """Compute relevance score (example implementation)"""
        # Simple word overlap score
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        overlap = len(query_words & content_words)
        return overlap / (len(query_words) + 1e-6)
    
    def __call__(
        self,
        documents: List[Dict[str, Any]],
        **kwargs
    ) -> List[Dict[str, Any]]:
        return self.rerank(documents, **kwargs)


# Use
reranker = QueryBasedReRanker(
    query="machine learning algorithms",
    topn=3
)

documents = [
    {"id": 1, "content": "Machine learning is an important AI algorithm"},
    {"id": 2, "content": "Deep learning uses neural networks"},
    {"id": 3, "content": "Supervised learning is a common ML method"},
]

reranked = reranker.rerank(documents, rerank_field="content")
```

### Example 3: Using QwenFunctionBase for Custom Reranking

```python
from zvec.extension.qwen_function import QwenFunctionBase
from zvec.extension import ReRanker
from typing import List, Dict, Any


class CustomQwenReRanker(QwenFunctionBase, ReRanker):
    """Custom Qwen reranking implementation"""
    
    def __init__(
        self,
        query: str,
        api_key: str,
        topn: int = 10,
        model: str = "gte-rerank",
        **kwargs
    ):
        # Initialize base class
        QwenFunctionBase.__init__(self, api_key=api_key)
        
        if not query:
            raise ValueError("Query is required")
        
        self._query = query
        self._topn = topn
        self._model = model
        self._extra_params = kwargs
    
    @property
    def query(self) -> str:
        return self._query
    
    @property
    def topn(self) -> int:
        return self._topn
    
    @topn.setter
    def topn(self, value: int):
        if value <= 0:
            raise ValueError("topn must be positive")
        self._topn = value
    
    @property
    def extra_params(self) -> dict:
        return self._extra_params
    
    def rerank(
        self,
        documents: List[Dict[str, Any]],
        rerank_field: str = "content",
        **kwargs
    ) -> List[Dict[str, Any]]:
        if not documents:
            return []
        
        # Extract contents
        contents = [doc.get(rerank_field, "") for doc in documents]
        
        # Use base class's rerank_text method
        scores = self._rerank_text(
            query=self._query,
            documents=contents,
            model=self._model
        )
        
        # Add scores to documents
        scored_docs = []
        for doc, score in zip(documents, scores):
            doc_copy = doc.copy()
            doc_copy["rerank_score"] = score
            scored_docs.append(doc_copy)
        
        # Sort by score descending
        scored_docs.sort(key=lambda x: x["rerank_score"], reverse=True)
        
        return scored_docs[:self._topn]
    
    def __call__(
        self,
        documents: List[Dict[str, Any]],
        **kwargs
    ) -> List[Dict[str, Any]]:
        return self.rerank(documents, **kwargs)


# Use custom Qwen reranker
custom_qwen_reranker = CustomQwenReRanker(
    query="What is a vector database",
    api_key="your-dashscope-api-key",
    topn=5
)
reranked = custom_qwen_reranker.rerank(documents, rerank_field="text")
```

## Best Practices

Follow these patterns to build effective search pipelines.

### Two-Stage Retrieval

Use fast recall first, then apply precise reranking:

```python
from zvec.extension import (
    DefaultLocalDenseEmbedding,
    DefaultLocalReRanker
)

# Stage 1: Fast recall
dense_emb = DefaultLocalDenseEmbedding()
query_vec = dense_emb.embed("machine learning tutorial")

# Stage 2: Precise reranking
reranker = DefaultLocalReRanker(
    query="machine learning tutorial",
    rerank_field="content",
    topn=10
)

# Recall top-100 (pseudo-code)
final_results = zvec.collection.query(
    vectors=VectorQuery("dense", vector=query_vec),
    topk=100,
    reranker=reranker,
)
```

### Multi-Vector Fusion

Use RRF or Weighted rerankers for multi-vector retrieval:

```python
from zvec.extension import (
    DefaultLocalDenseEmbedding,
    DefaultLocalSparseEmbedding,
    RrfReRanker
)

# Create embedding functions
dense_emb = DefaultLocalDenseEmbedding()
sparse_emb = DefaultLocalSparseEmbedding(encoding_type="query")

# Query text
query = "What is a vector database"

# Generate both embeddings
dense_vec = dense_emb.embed(query)
sparse_vec = sparse_emb.embed(query)

# Fuse results using RRF
rrf_ranker = RrfReRanker(topn=3)

# Retrieve using both vectors separately (pseudo-code)
final_results = zvec.collection.query(
    vectors=[
        VectorQuery("dense", vector=dense_vec),
        VectorQuery("sparse", vector=sparse_vec),
    ],
    topk=10,
    reranker=rrf_ranker,
)
```

## Important Notes

<Callout type="warn" className="text-base">
  **Key Considerations:**

  1. **Model Download**: Local models will be downloaded on first use. Ensure network connectivity.
  2. **Memory Management**: Local models consume memory. Call `clear_cache()` to release memory after use.
  3. **API Rate Limiting**: When using API-based functions (Qwen), be mindful of quotas and rate limits.
  4. **Thread Safety**: Reranking functions are thread-safe and can be used in multi-threaded environments.
  5. **Multi-Vector Reranking**: `RrfReRanker` and `WeightedReRanker` are specifically designed for fusing results from multiple retrieval methods (e.g., dense + sparse). For single-vector results, use `DefaultLocalReRanker` or `QwenReRanker`.
</Callout>

## Related Documentation

Explore the source code and implementation details:

* [Reranking Function Protocol](https://zvec.org/api-reference/python/extension/#zvec.extension.ReRanker)
* [Sentence Transformers Base Class](https://zvec.org/api-reference/python/extension/#zvec.extension.SentenceTransformerFunctionBase)
* [Qwen Function Base Class](https://zvec.org/api-reference/python/extension/#zvec.extension.QwenFunctionBase)


# Create



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

To create a new, empty collection in Zvec, you need to define the following:

* **Schema** ‚Äî  the structural blueprint of your data, specifying scalar fields and vector embeddings.
* **Collection options** (optional) ‚Äî runtime settings that control how the collection behaves when opened (e.g., read-only mode).

Once defined, you call `create_and_open()` to create the collection on disk and get a ready-to-use `Collection` handle.

<Callout className="text-base" type="warn">
  If a collection already exists at the specified path, `create_and_open()` will raise an error to prevent accidental overwrites.
</Callout>

***

## Step 1: Define the Schema

A **collection schema** `CollectionSchema` defines the structure that every [document](../../concepts/data-modeling/#documents) inserted into the collection must conform to.

<Callout className="text-base" type="success">
  The schema in Zvec is **dynamic**: you can add or remove scalar fields and vectors at any time without rebuilding the collection.
</Callout>

`CollectionSchema` has three parts:

1. `name`: An identifier for the collection.
2. `fields`: A list of scalar fields.
3. `vectors`: A list of vector fields.

### 1. Collection Name

A human-readable identifier for your collection. This name is used internally for reference and logging.

### 2. Scalar Fields

Scalar fields store non-vector (i.e., structured) data ‚Äî such as strings, numbers, booleans, or arrays.

Each field is defined using `FieldSchema` with the following properties:

1. üî§ `name`: A unique string identifier for the field within the collection.
2. üß¨ [`data_type`](../../concepts/data-modeling/#scalar-types): The type of data stored ‚Äî e.g., `STRING`, `INT64`, or array types like `ARRAY_STRING`.
3. ‚≠ï `nullable` (optional): Whether the field is allowed to **have no value** (defaults to `False`).
4. üöÄ `index_param` (optional): Enables fast filtering by creating an [inverted index](../../concepts/inverted-index/) via `InvertIndexParam`.

<Callout className="text-base" type="idea">
  **Tip**:\
  Only add an index to fields you plan to filter on. Unindexed fields save storage and write overhead.

  If you do enable indexing, you can optionally activate performance-enhancing (but storage-costly) features:

  * `enable_range_optimization=True` ‚Üí faster range queries (e.g., `price > 100`)
  * `enable_extended_wildcard=True` ‚Üí complex string pattern matching (e.g., `name LIKE 'abc%def'`)
</Callout>

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Define a scalar field"
    import zvec

    field_schema = zvec.FieldSchema(  # [!code highlight]
        name="string_field_example",
        data_type=zvec.DataType.STRING,
        nullable=True,
        # Enables fast filtering; range queries are supported but not optimized
        index_param=zvec.InvertIndexParam(enable_range_optimization=False),
    )
    ```
  </Accordion>
</Accordions>

### 3. Vectors (Embeddings)

A vector is defined using `VectorSchema` with the following properties:

1. üî§ `name`: A unique string identifier for the vector within the collection.
2. üß¨ [`data_type`](../../concepts/data-modeling/#vector-types): The numeric format of the vector.
   * [Dense vectors](../../concepts/vector-embedding/#dense-vectors): `VECTOR_FP32`, `VECTOR_FP16`, etc.
   * [Sparse vectors](../../concepts/vector-embedding/#sparse-vectors): `SPARSE_VECTOR_FP32`, `SPARSE_VECTOR_FP16`.
3. üìê `dimension`: Required for [dense vectors](../../concepts/vector-embedding/#dense-vectors) ‚Äî the number of dimensions.
4. üöÄ `index_param`: Configures the vector index type and similarity metric.

Configure the vector index via the `index_param` field using one of the following:

* `FlatIndexParam(...)` for [Flat index](../../concepts/vector-index/flat-index/)
* [`HnswIndexParam(...)`](../../concepts/vector-index/hnsw-index/#index-time-parameters) for [HNSW index](../../concepts/vector-index/hnsw-index/)
* [`IVFIndexParam(...)`](../../concepts/vector-index/ivf-index/#index-time-parameters) for [IVF index](../../concepts/vector-index/ivf-index/)

In `index_param` you can also specify:

* `metric_type`:\
  `COSINE`, `L2`, or `IP` (inner product) ‚Äî *Ensure your metric matches how your embeddings were trained!*
* [`quantize_type`](../../concepts/vector-index/quantization/) (optional):\
  Compress vectors to reduce index size and speed up search (with slight [recall](../../concepts/vector-index/#recall-measuring-approximation-quality) trade-off)

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Define a vector"
    import zvec

    vector_schema = zvec.VectorSchema(  # [!code highlight]
        name="dense_vector",
        data_type=zvec.DataType.VECTOR_FP32,
        dimension=768,
        index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
    )
    ```
  </Accordion>
</Accordions>

### Full Schema Example

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Define a collection schema"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[  # [!code highlight]
            zvec.FieldSchema(  # [!code highlight]
                name="string_field_example",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
        ],
        vectors=[  # [!code highlight]
            zvec.VectorSchema(  # [!code highlight]
                name="dense_vector",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
    )
    ```
  </Accordion>
</Accordions>

***

## Step 2: Configure Collection Options

The `CollectionOption` lets you control runtime behavior when creating the collection:

* `read_only`: Opens the collection in read-only mode. Attempts to write will raise an error.
  <Callout className="text-base" type="warn">
    **Note**: `read_only` must be set to `False` when calling `create_and_open()`, since creation requires writing files to disk.
  </Callout>
* `enable_mmap`: Uses memory-mapped I/O for faster access (default to `True`). This trades slightly higher memory cache usage for improved performance.

```python title="Collection option"
import zvec

collection_option = zvec.CollectionOption(read_only=False, enable_mmap=True)  # [!code highlight]
```

***

## Step 3: Create and Open the Collection

With your schema and options ready, call `create_and_open()` to create the collection at the desired `path`:

```python title="Create and open a collection"
import zvec

collection = zvec.create_and_open(  # [!code highlight]
    path="/path/to/my/collection",
    schema=collection_schema,
    option=collection_option,
)
```

The returned `collection` object is immediately ready for inserting documents, running queries, or managing data.

***

## Real-World Example: üõí Product Search

This schema models a **multi-modal product search system**, combining visual, textual, and structured metadata for rich retrieval:

### üóÇÔ∏è Scalar Fields: For Filtering & Display

* `category` (array of strings, indexed):\
  Enables queries like `category CONTAIN_ANY ("electronics", "headphones")` to find products that belong to either "electronics" or "headphones" (or both).
* `price` (integer, indexed with range optimization):\
  Supports fast range queries such as `price > 100`.
* `in_stock` (boolean, indexed):\
  Enables instant filtering by availability (e.g., "only show items in stock").
* `image_url` and `description` are stored but **not indexed**, since they're only used for display.

### üìê Vector Embeddings: For Semantic Relevance

* Two dense vectors capture semantic meaning:
  * `image_vec`: 512-dimensional embeddings from product images (e.g., via a vision model).
  * `description_vec`: 768-dimensional embeddings from product descriptions (e.g., from a language model), stored with quantization.
* One sparse vector `keywords_sparse` for keyword matching, enabling hybrid sparse-dense search.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Create a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="product_search",
        fields=[  # [!code highlight]
            zvec.FieldSchema(
                name="image_url",
                data_type=zvec.DataType.STRING,  # Not used in filtering, no index created
                nullable=True,  # Could be null
            ),
            zvec.FieldSchema(
                name="description",
                data_type=zvec.DataType.STRING,  # Not used in filtering, no index created
            ),
            zvec.FieldSchema(
                name="category",
                data_type=zvec.DataType.ARRAY_STRING,
                # Inverted index for array membership queries
                index_param=zvec.InvertIndexParam(),
            ),
            zvec.FieldSchema(
                name="price",
                data_type=zvec.DataType.INT32,
                # Optimization for range queries, e.g., price > 100
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
            zvec.FieldSchema(
                name="in_stock",
                data_type=zvec.DataType.BOOL,
                # Inverted index for boolean queries
                index_param=zvec.InvertIndexParam(),
            ),
        ],
        vectors=[  # [!code highlight]
            # Dense embedding from product images
            zvec.VectorSchema(
                name="image_vec",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=512,
                # Use HNSW index for similarity search with cosine distance metric
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
            # Dense embedding from product descriptions
            zvec.VectorSchema(
                name="description_vec",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                # Enable quantization for faster similarity search
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE, quantize_type=zvec.QuantizeType.INT8),
            ),
            # Sparse vector from product keywords
            zvec.VectorSchema(
                name="keywords_sparse",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                # Use HNSW index for similarity search with inner product metric
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.create_and_open(  # [!code highlight]
        path="path/to/collection",
        schema=collection_schema,
        option=zvec.CollectionOption(read_only=False, enable_mmap=True),
    )
    ```
  </Accordion>
</Accordions>


# Destroy



Destroying a collection **permanently deletes it from disk**. This operation **cannot be undone**.

<Callout className="text-base" type="warn">
  **Warning**: All data in the collection will be lost. Ensure you no longer need the collection or have created a backup before calling `destroy()`.
</Callout>

```python title="Destroy a collection"
import zvec

collection = zvec.open(path="/path/to/my/collection")

# Permanently delete the collection
collection.destroy()  # [!code highlight]
```

After calling `destroy()`, the collection directory and its contents are removed from the filesystem.

Do not use the `collection` object afterward ‚Äî it is no longer valid.


# Collections



import { Eye, FolderOpen, FolderPlus, Trash, Wrench, Zap } from 'lucide-react';

A [**collection**](../concepts/data-modeling/#collections) is a named container for [documents](../concepts/data-modeling/#documents) in Zvec.

Think of a collection as a table in a relational database: it's where you *store, organize, and query your data*.

This section covers the operations for managing collections.

<Cards>
  <Card title="Create a New Collection" href="./create/" icon={<FolderPlus />} />

  <Card title="Open an Existing Collection" href="./open/" icon={<FolderOpen />} />

  <Card title="Inspect a Collection" href="./inspect/" icon={<Eye />} />

  <Card title="Destroy a Collection" href="./destroy/" icon={<Trash />} />

  <Card title="Optimize a Collection" href="./optimize/" icon={<Zap />} />

  <Card title="Schema Evolution" href="./schema-evolution/" icon={<Wrench />} />
</Cards>


# Inspect



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Once you've opened a collection, you can inspect its structure, configuration, and runtime state to better understand how it's organized and performing. This is especially helpful during development, debugging, or system monitoring.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    # [!code word:collection]
    collection = zvec.open(path="/your/specified/path/")

    print(collection.schema)  # View the schema [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## Quick Reference

| Property            | Description                                                                      |
| ------------------- | -------------------------------------------------------------------------------- |
| `Collection.schema` | Collection structure and field definitions (e.g., vector dimensions, data types) |
| `Collection.stats`  | Runtime metrics such as document count and index completeness                    |
| `Collection.option` | Runtime settings (e.g., read-only mode, memory mapping)                          |
| `Collection.path`   | Filesystem path to the collection directory                                      |

***

## Collection Schema

To view the [schema](../create/#step-1-define-the-schema):

```python
print(collection.schema)
```

<Accordions type="single">
  <Accordion title="Example">
    ```json
    // [!code word:fields]
    // [!code word:vectors]
    {
      "name": "my_collection",
      "fields": {
        "price": {
          "name": "price",
          "data_type": "INT32",
          "nullable": false,
          "index_param": {
            "enable_range_optimization": true
          }
        },
        "category": {
          "name": "category",
          "data_type": "ARRAY_STRING",
          "nullable": true,
          "index_param": {
            "enable_range_optimization": false
          }
        },
        "image_url": {
          "name": "image_url",
          "data_type": "STRING",
          "nullable": true,
          "index_param": null
        }
      },
      "vectors": {
        "image_vector": {
          "name": "image_vector",
          "data_type": "VECTOR_FP32",
          "dimension": 256,
          "index_param": {
            "type": "HNSW",
            "metric_type": "COSINE",
            "m": 100,
            "ef_construction": 500,
            "quantize_type": "UNDEFINED"
          }
        }
      }
    }
    ```

    1. `"name": "my_collection"`: The name of the collection.
    2. `"fields"`: A map of scalar field names to their definitions.
       <Callout className="text-base" type="info">
         If `index_param` is not null for a scalar field, that field has an [inverted index](../../concepts/inverted-index/).
       </Callout>
       * `"price"`: A required 32-bit integer, with inverted index and range query optimization enabled.
       * `"category"`: An optional array of strings with an inverted index enabled; range query optimization is disabled (not meaningful for array types).
       * `"image_url"`: An optional string, with no indexing applied.
    3. `"vectors"`: A map of vector names to their definitions.
       * `"image_vector"`: A 256-dimensional floating-point vector indexed with [HNSW](../../concepts/vector-index/hnsw-index/) using cosine similarity and no quantization.
  </Accordion>
</Accordions>

***

## Collection Statistics

The `stats` property provides real-time operational insights:

```python
print(collection.stats)
```

<Accordions type="single">
  <Accordion title="Example">
    ```json
    {"doc_count":100, "index_completeness":{"image_vector":1.000000}}
    ```

    1. `doc_count`: Total number of documents currently stored.
    2. `index_completeness`: Fraction (0.0\~1.0) indicating how much of the vector data has been indexed. A value of 1.0 means indexing is complete.
  </Accordion>
</Accordions>

***

## Collection Options

Runtime behavior is governed by the options used when opening the collection:

```python
print(collection.option)
```

<Accordions type="single">
  <Accordion title="Example">
    ```json
    {"enable_mmap":1, "read_only":0}
    ```

    1. `enable_mmap: 1` ‚Üí Memory-mapped I/O is enabled for faster access.
    2. `read_only: 0` ‚Üí The collection is open for both reads and writes.
  </Accordion>
</Accordions>

***

## Collection Path

The `path` property returns the on-disk location of the collection:

```python
print(collection.path)
```

<Accordions type="single">
  <Accordion title="Example">
    ```text
    ./my_collection/
    ```

    This is the same path passed to `db.open()`. It's useful for logging, backup scripts, or diagnostics.
  </Accordion>
</Accordions>


# Open



To open an existing collection, use the `open()` function to load it from disk.

<Callout className="text-base" type="warn">
  The specified path **must point to an existing Zvec collection**. If no valid collection is found, `open()` will raise an error.
</Callout>

## Usage

```python title="Open a collection"
import zvec

existing_collection = zvec.open(  # [!code highlight]
    path="/path/to/my/collection",
    option=zvec.CollectionOption(read_only=False, enable_mmap=True),
)
```

## Parameters

* `path`:\
  The filesystem path to the collection directory.
* `option`:\
  Runtime settings that control how the collection is accessed.
  * `read_only`:\
    Opens the collection in read-only mode. Attempts to write will raise an error.
    <Callout className="text-base" type="info">
      Use read-only mode when sharing a collection across multiple processes ‚Äî it ensures safe concurrent access without risking data corruption.
    </Callout>
  * `enable_mmap`:\
    Uses memory-mapped I/O for faster access (defaults to `True`). This trades slightly higher memory cache usage for improved performance.


# Optimize



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

The `optimize()` method **improves search performance** by building the configured vector index from vectors accumulated in a temporary flat buffer. It runs **in the background** and **does not block reads or writes**, ensuring your application remains fully responsive.

***

## Why Optimization is Needed

In Zvec, newly inserted vectors are **not added directly** to the configured vector index.

Instead, they are first appended to a lightweight [flat (brute-force) index](../../concepts/vector-index/flat-index/) buffer.

This design choice offers important benefits ‚Äî but also a trade-off:

* ‚úÖ **Strengths**
  * **Maximum write throughput**: Enables high-speed data ingestion.
  * **Streaming inserts**: Supports real-time insertion for index types like [IVF](../../concepts/vector-index/ivf-index/) that don't natively allow incremental updates.
* ‚ö†Ô∏è **Trade-off**
  * **Slower searches over time**: As the flat buffer grows, search performance degrades.

üîÅ **Solution**

Call `optimize()` periodically. This triggers a background process that merges the buffered vectors into the configured vector index ‚Äî **without interrupting ongoing reads or writes**. üöÄ

<Callout className="text-base" type="info">
  `optimize()` is a synchronous method (it returns only after the optimization has finished), but it **does not lock the collection**.\
  Other threads can continue reading, writing, and querying without delay ‚Äî your application stays fully responsive.
</Callout>

***

## Usage Example

```python title="Optimize a collection"
import zvec

collection = zvec.open(path="/path/to/my/collection")

# Insert some documents
for i in range(1000):
    doc = zvec.Doc(id=f"doc_{i}", vectors={"embedding": [i + 0.1, i + 0.2, i + 0.3]})
    collection.insert(doc)

# Optimize the collection
collection.optimize()  # [!code highlight]
```

***

## Check Indexing Status

Use the `stats` property to get real-time insights into your collection's indexing state:

```python
print(collection.stats)
```

<Accordions type="single">
  <Accordion title="Example">
    ```json
    {"doc_count":1000, "index_completeness":{"embedding":1.000000}}
    ```

    1. `doc_count`: Total number of documents currently stored.
    2. `index_completeness`: Fraction (0.0\~1.0) indicating how much of the vector data has been indexed.
       * `1.0` ‚Üí All vectors for that vector field are fully indexed using the configured index
       * `0.0` ‚Üí No indexing has occurred; all vectors remain in the flat buffer and are searched via brute force
       * **Values in between** ‚Üí Indexing is partial or in progress
  </Accordion>
</Accordions>

***

## When to Call `optimize()`

Optimize **regularly ‚Äî but not too often**:

* **Too infrequent** ‚Üí Flat buffers grow large, degrading search performance
* **Too frequent** ‚Üí Wastes resources optimizing small batches prematurely

Find a balance based on your **data ingestion rate** and **query latency requirements**.

<Callout className="text-base" type="idea">
  **Best practice:**\
  Check your collection's indexing status if searches feel slow.\
  As a general guideline, consider optimizing when you have **100,000+ unindexed documents** ‚Äî but adjust based on your specific use case.
</Callout>


# Schema Evolution



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Zvec supports **dynamic schema evolution**, allowing you to modify a collection's structure after it has been created ‚Äî without downtime, data re-ingestion, or reindexing.

You can:

* ‚úÖ **Add or drop scalar fields**
* ‚úÖ **Rename fields** or **change their data types** ((as long as the change is safe ‚Äî e.g., from `INT32` to `INT64`)
* ‚úÖ **Create or drop indexes on fields**
* ‚ùå  Add or drop vector fields (üîú coming soon)

***

## Data Definition Language (DDL)

In Zvec, schema changes are performed using **Data Definition Language (DDL)** methods, grouped into two categories:

* **Column DDL**: defines *what data you store*.\
  It manages the structure of your collection by [adding](#add-a-column), [removing](#drop-a-column), [renaming or altering](#alter-a-column) fields.
* **Index DDL**: defines *how you search that data*.\
  It controls the [creation](#create-an-index) and [removal](#drop-an-index) of indexes on fields.

<Callout className="text-base" type="info">
  üí° **Indexing Rules in Zvec**

  * **Every vector field must be indexed** using an appropriate [vector index](../../concepts/vector-index/) to enable similarity search.
  * **Scalar fields are optionally indexed** ‚Äî but you should build [inverted indexes](../../concepts/inverted-index/) on any scalar field you plan to use in filtering queries (e.g., `WHERE category = 'music'`).
</Callout>

***

## Prerequisites

This guide assumes you have opened a collection and have a `collection` object ready.

<Accordions type="single">
  <Accordion title="Example Collection Setup">
    This example collection includes a scalar field `publish_year`.

    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(name="publish_year", data_type=zvec.DataType.INT64),  # [!code highlight]
        ],
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## Column DDL

### Add a Column

To add a new scalar field to an existing collection, use `add_column()`:

```python title="Add a column"
import zvec

new_field = zvec.FieldSchema(name="rating", data_type=zvec.DataType.INT32)
collection.add_column(field_schema=new_field, expression="5")  # [!code highlight]
```

* `field_schema`:\
  Defines the name and data type of the new field. See [scalar field schema](../create/#2-scalar-fields) for details.
* `expression`:\
  Specifies the default value for existing documents. Since they don't already have a `rating` field, Zvec uses this `expression` to fill in the missing values ‚Äî in this case, setting `rating = 5` for all current documents.

<Callout className="text-base" type="info">
  Currently, only **numerical scalar fields** can be added via `add_column()`. Support for `string` and `boolean` types is coming soon.\
  Accordingly, the `expression` must evaluate to a number ‚Äî it can be a single numerical literal (like `"5"`) or a simple arithmetic expression involving existing numerical fields (e.g., `"publish_year + 1"`).
</Callout>

### Drop a Column

To permanently remove a scalar field, use `drop_column()`:

```python title="Drop a column"
# [!code word:drop_column]
collection.drop_column(field_name="publish_year")
```

<Callout className="text-base" type="warn">
  This **deletes the field and all its data from every document** in the collection. The operation is **irreversible**.
</Callout>

### Alter a Column

To rename a column or update its schema, use `alter_column()`:

```python title="Alter a column"
# Rename
collection.alter_column(old_name="publish_year", new_name="release_year")   # [!code highlight]

# Change type (if compatible)
updated = zvec.FieldSchema(name="rating", data_type=zvec.DataType.FLOAT)
collection.alter_column(field_schema=updated)                               # [!code highlight]
```

### View the Current Schema

After making changes, you can always check your collection's current structure by printing its schema:

```python title="View the current schema"
print(collection.schema)
```

See [schema example](../inspect/#collection-schema) for more details.

## Index DDL

### Create an Index

To accelerate search performance, you can create (or replace) indexes on both **vector** and **scalar** fields using `create_index()`:

```python title="Create an index"
import zvec

# Replace the existing HNSW index with a FLAT index
collection.create_index(  # [!code highlight]
    field_name="dense_embedding",
    index_param=zvec.FlatIndexParam(metric_type=zvec.MetricType.COSINE),
)

# Create an inverted index
collection.create_index(  # [!code highlight]
    field_name="publish_year",
    index_param=zvec.InvertIndexParam(),
)
```

* **Vector fields** must use one of the following index types:
  * [`HnswIndexParam`](../../concepts/vector-index/hnsw-index/#index-time-parameters)
  * [`IVFIndexParam`](../../concepts/vector-index/ivf-index/#index-time-parameters)
  * `FlatIndexParam`
* **Scalar fields** use `InvertIndexParam` to enable efficient filtering.

### Drop an Index

To remove an index from a scalar field, use `drop_index()`:

```python title="Drop an index"
collection.drop_index(field_name="publish_year")
```

<Callout className="text-base" type="info">
  **It is not allowed to drop the index of a vector field**.\
  In Zvec, every vector field must always have exactly one index to support similarity search.
</Callout>


# Data Modeling





import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

In Zvec, data is organized into **collections** and **documents**.

***

## Collections

A **collection** is a named container for [documents](#documents) ‚Äî similar to a **table** in a relational database system such as MySQL, where each **document** represents a **row** in a table. A collection is where you store, organize, and query your data.

Every collection is governed by a **schema** that defines the scalar fields and vectors it contains, along with their [types](#data-types) and [indexing settings](#indexes).

<img alt="Collection example" src={__img0} />

**All documents within a collection conform to the same schema**.

<Callout className="text-base" type="success">
  The schema in Zvec is **dynamic**: you can add or remove scalar fields and vectors at any time without recreating the collection.
</Callout>

<Callout className="text-base" type="error">
  **No cross-collection queries**: Joins, unions, or multi-collection searches are **not supported**. Design your data model accordingly.
</Callout>

### Why Use Collections?

Collections provide **isolation** by ensuring that each data workload operates within its own dedicated schema and indexing configuration. This separation prevents interference between unrelated use cases and allows each to evolve independently.

For example:

* A **Retrieval-Augmented Generation (RAG) collection** might store text embeddings together with metadata ‚Äî such as title, section, source URL, and last-updated timestamp.
* An **image search collection** could hold high-dimensional image embeddings along with associated fields like image ID, file path, or caption.

### Persistence

* **Each collection is persisted independently on disk in its own dedicated directory**, providing isolation between different data workloads.

* Each collection is **self-contained within its directory**. This means you can relocate a collection's directory and Zvec will still be able to open it when provided with the correct path.

***

## Documents

A document is the fundamental unit of data storage ‚Äî think of it as a single record or row in a relational database table. Each document lives inside a [collection](#collections) and must conform to that collection's schema.

### Structure of a Document

A document is a **structured** object composed of three core components.

* üîë `id`: A unique string identifier for the document, cannot be changed after insertion
* üìê `vectors`: A named set of vectors
* üóÇÔ∏è `fields`: A named set of scalar (non-vector) fields, which can include strings, numbers, booleans, or arrays of these types

### Example Document

<Accordions type="single">
  <Accordion title="Example">
    This document belongs to a collection with a schema that defines:

    1. Two dense vector: `vector_1` (4-dimensional) and `vector_2` (6-dimensional)
    2. One sparse vector: `vector_3`
    3. Scalar fields: `category` (string), `price` (integer), and `languages` (array of strings)

    ```json
    {
      // Unique identifier for this document
      // [!code word:id]
      "id": "my_doc_123",

      // A named set of vectors
      // [!code word:vectors]
      "vectors": {
        // A 4-dimensional dense vector, represented as a list
        "vector_1": [ 0.1, 0.2, 0.3, 0.4 ],

        // A 6-dimensional dense vector, represented as a list
        "vector_2": [ -0.6, -0.5, -0.4, -0.3, -0.2, -0.1 ],

        // A sparse vector, represented as a map
        "vector_3": { 11: 0.02, 37: 0.41, 1701: 0.13 }
      },

      // A named set of scalar fields
      // [!code word:fields]
      "fields": {
        "category": "music",  // A string field

        "price": 99,          // A numeric field

        "languages": [ "English", "Chinese", "Korean" ]   // An array field
      }
    }
    ```
  </Accordion>
</Accordions>

<Callout className="text-base" type="info">
  **All fields must conform to their declared types in the schema**. Vectors must exactly match the specified type (dense or sparse) and dimensionality (e.g., a 768-dimensional dense vector cannot accept a 512-dimensional vector).
</Callout>

<Callout className="text-base" type="idea">
  Once inserted, documents can be updated via [`upsert()`](../../data-operations/upsert/) or partial [`update()`](../../data-operations/update/) operations, but all modifications must still adhere to the collection's schema constraints.
</Callout>

***

## Data Types

Zvec uses a strongly typed schema system based on the `DataType` enumeration. The supported types fall into two categories:

1. **Scalar types** ‚Äî strings, integers, floats, booleans, and arrays of these types
2. **Vector types** ‚Äî dense or sparse numeric representations for vector embeddings

<Callout className="text-base" type="info">
  **Type safety is enforced at ingestion**: each document field must conform to its corresponding declared `DataType`.
</Callout>

### Scalar Types

* Elementary Types

  | `STRING` | `BOOL` | `INT32` | `INT64` | `UINT32` | `UINT64` | `FLOAT` | `DOUBLE` |
  | -------- | ------ | ------- | ------- | -------- | -------- | ------- | -------- |

* Array Types

  | `ARRAY_STRING` | `ARRAY_BOOL` | `ARRAY_INT32` | `ARRAY_INT64` | `ARRAY_UINT32` | `ARRAY_UINT64` | `ARRAY_FLOAT` | `ARRAY_DOUBLE` |
  | -------------- | ------------ | ------------- | ------------- | -------------- | -------------- | ------------- | -------------- |

  <Callout className="text-base" type="warn">
    Arrays cannot contain mixed types or nested structures. All elements must match the declared array element type.
  </Callout>

### Vector Types

* [Dense Vector](../vector-embedding/#dense-vectors) Types:\
  represented as fixed-length numeric arrays, e.g., `[0.1, -0.5, ..., 0.9]`

  | `VECTOR_FP16` | `VECTOR_FP32` | `VECTOR_INT8` |
  | ------------- | ------------- | ------------- |

* [Sparse Vector](../vector-embedding/#sparse-vectors) Types:\
  represented as maps from integer indices to float values, e.g., `{ 42: 0.85, 1024: 0.13 }`

  | `SPARSE_VECTOR_FP32` | `SPARSE_VECTOR_FP16` |
  | -------------------- | -------------------- |

***

## Indexes

Indexes accelerate data retrieval beyond basic storage of scalar fields and vectors. In Zvec:

* **Every vector field must be indexed** using an appropriate [vector index](../vector-index/) to enable similarity search.
* **Scalar fields are optionally indexed** ‚Äî but you should build [inverted indexes](../inverted-index/) on any scalar field you plan to use in filtering queries (e.g., `WHERE category = 'music'`).

You can define indexes at [collection creation](../../collections/create/) by specifying `index_param` in the schema for each field or vector.\
Alternatively, you can add indexes after collection creation by calling [`create_index()`](../../collections/schema-evolution/#create-an-index) dynamically ‚Äî no data re-ingestion required.

```python title="Create a collection"
import zvec

# Define the collection schema with one scalar field and one vector field, both
# configured with indexes via "index_param".
# [!code word:index_param]
schema = zvec.CollectionSchema(   # [!code highlight]
    name="my_collection",
    fields=[
        zvec.FieldSchema(
            name="price",
            data_type=zvec.DataType.INT32,
            index_param=zvec.InvertIndexParam(enable_range_optimization=True),
        ),
    ],
    vectors=[
        zvec.VectorSchema(
            name="vector",
            data_type=zvec.DataType.VECTOR_FP32,
            dimension=256,
            index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
        ),
    ],
)

collection = zvec.create_and_open(path="/path/to/my/collection", schema=schema)   # [!code highlight]
```


# Concepts



import { Database, Layers, Rocket } from 'lucide-react';

This section introduces key terms and foundational ideas that underpin the design and usage of Zvec.

<Cards>
  <Card title="Data Modeling" href="./data-modeling/" description="Learn more about how to structure and organize your data in Zvec" icon={<Database />} />

  <Card title="Vector Embedding" href="./vector-embedding/" description="Learn more about how unstructured data (e.g., images) are transformed into vectors for similarity search" icon={<Layers />} />

  <Card title="Vector Index" href="./vector-index/" description="Learn more about indexing techniques that enable fast and efficient similarity search across vector spaces" icon={<Rocket />} />

  <Card title="Inverted Index" href="./inverted-index/" description="Learn more about inverted indexing for fast filtering" icon={<Rocket />} />
</Cards>


# Inverted Index



An inverted index is a data structure used to store and organize information for ***efficient value-based search and retrieval***.

It is widely used in database systems, search engines, and analytics platforms to **accelerate filtering operations and keyword matching**.

## When to Use an Inverted Index

Use an inverted index when your workload involves **frequent lookups based on specific field values**. It excels in scenarios such as:

* ‚úÖ Exact-value filtering:
  * `status = "active"`
  * `category IN ("electronics", "books")`
* ‚úÖ Range queries:
  * `age > 25`
* ‚úÖ Text pattern matching:
  * Starts with: `product_name LIKE "Wireless%"`
  * Ends with: `email LIKE "%@engineering.company.com"`
* ‚úÖ Array or set membership queries:
  * Contains any: `tags CONTAIN_ANY ["sport", "music"]`
  * Contains all: `permissions CONTAIN_ALL ["read", "write"]`

## How Does It Work?

Imagine you're organizing a collection of recipes. Each recipe is a `document` with structured fields `cuisine`, `author`, and `url`.

| Doc ID | Cuisine | Author      | URL                                           |
| ------ | ------- | ----------- | --------------------------------------------- |
| 1      | Italian | Julia Chen  | `https://cooking.com/italian-pasta-carbonara` |
| 2      | Thai    | Liam Tran   | `https://cooking.com/thai-basil-42`           |
| 3      | Mexican | Elena Gomez | `https://cooking.com/mexican-pork-chicken-65` |
| 4      | Italian | Marco Rossi | `https://cooking.com/italian-pizza-37`        |
| 5      | Italian | Marco Rossi | `https://cooking.com/italian-pasta-20`        |
| 6      | Chinese | Julia Chen  | `https://cooking.com/chinese-spicy-hot-pot`   |

A regular (or "forward") view asks:

> What values does document #1 contain? ‚Üí Cuisine: Italian, Author: Julia Chen

But an **inverted index flips this around**. Instead, it answers:

> Which documents contain the value Italian? ‚Üí \[1, 4, 5]

To enable fast lookups, we build inverted indexes for **fields that are frequently searched** ‚Äî like `cuisine` and `author`.

**Inverted Index: `cuisine`**

| Cuisine | Doc IDs     |
| ------- | ----------- |
| Italian | `[1, 4, 5]` |
| Thai    | `[2]`       |
| Mexican | `[3]`       |
| Chinese | `[6]`       |

**Inverted Index: `author`**

| Author      | Doc IDs  |
| ----------- | -------- |
| Julia Chen  | `[1, 6]` |
| Liam Tran   | `[2]`    |
| Elena Gomez | `[3]`    |
| Marco Rossi | `[4, 5]` |

With these indexes in place, queries become extremely efficient ‚ú®:

* "Find all Italian recipes" ‚Üí look up "Italian" in the `cuisine` index ‚Üí `[1, 4, 5]`
* "Show recipes by Marco Rossi" ‚Üí look up "Marco Rossi" in the `author` index ‚Üí `[4, 5]`
* "Find Italian recipes by Julia Chen" ‚Üí intersect `[1, 4, 5]` and `[1, 6]` ‚Üí `[1]`

We **do not index** `url`, because it's rarely used in queries. Indexing it would waste storage and slow down writes, with little benefit. Once we have a document ID, we can always fetch its `url` directly from the original data.

## Why "inverted"?

Because it inverts the standard mapping:

| Direction | Mapping                     |
| --------- | --------------------------- |
| Forward   | Document ID ‚Üí List of Terms |
| Inverted  | Term ‚Üí List of Document IDs |

This inversion is what makes keyword-based search efficient. Instead of checking every document to see if it contains your query term, you jump straight to the term and get all matching documents immediately.

## Trade-offs

While powerful, inverted indexes come with costs:

* ‚ö†Ô∏è **Storage overhead**: The index requires additional storage space.
* ‚ö†Ô∏è **Write amplification**: Every write operation ‚Äî `INSERT`, `UPSERT`, and `UPDATE` ‚Äî require index maintenance, which adds latency to writes and increases I/O load.


# Vector Embedding







<a id="vector-embedding-diagram" />

<img alt="vector embedding" src={__img0} />

## What is a Vector?

In the context of AI and vector databases, ***a vector is a list of numbers generated by embedding models to capture the semantic essence of unstructured data*** ‚Äî  such as text, images, or audio.

These models transform raw input into a high-dimensional space where ***semantically similar items produce similar vectors***, enabling AI systems to compare meaning rather than relying on exact word matches.

***

## How Do You Use Vectors with a Database?

1. üóÇÔ∏è **Store**: Generate embeddings from your data ‚Äî documents, product images, or user profiles ‚Äî and save them in the vector database.
2. üîç **Search**: When a new query arrives (a question, photo, etc.), generate a **query vector** using the same embedding model, then ask the database to find the most similar stored vectors.

Using [efficient indexes](../vector-index/), the database quickly returns relevant results ‚Äî even at large scale. This is the foundation of semantic search: **finding what ***means*** the same, not just what ***says*** the same**.

***

## How Vectors Power Real-World Applications?

**Image search** is a great example:

* Each image is converted into a vector that captures its visual features ‚Äî such as shape, color, and object type.
* Images that are **visually or semantically similar end up with nearby vectors**.

By comparing these vectors, systems can:

* ‚úÖ **Recognize the same person across different photos**: Even with changes in lighting, pose, or expression, images of one individual generate similar vectors, allowing the system to match identities reliably.
* ‚úÖ **Find look-alike products in e-commerce**: When a user snaps a photo of a dress, lamp, or sofa, the system compares its vector to product vectors and retrieves items with similar appearance or style.

All of this happens through fast vector similarity comparisons, powered by the vector database.

<img alt="image search" src={__img1} />

***

## What is an Embedding Model?

An embedding model is an AI model that converts raw data into vector embeddings ‚Äî illustrated in the [diagram](#vector-embedding-diagram) at the top.

These models learn patterns from vast amounts of training data so that objects with similar meanings produce vectors that are close together in vector space ‚Äî typically measured using distance metrics such as **cosine similarity**, **dot product**, or **Euclidean distance**.

<Callout className="text-base" type="info">
  **The choice of distance metric matters.** If an embedding model was trained for a specific metric (e.g., cosine similarity), the vector database should use the same metric during search to preserve semantic relationships and achieve optimal accuracy.
</Callout>

To explore and compare state-of-the-art embedding models, you can check out the [Embedding Leaderboard on Hugging Face](https://huggingface.co/spaces/mteb/leaderboard), which evaluates hundreds of models across diverse tasks and languages.

***

## Types of Vectors

Vector representations are primarily categorized into two types: ***dense*** and ***sparse***, each capturing data in its own way.

### Dense Vectors

Dense vectors are fixed-length, real-valued embeddings where (nearly) every dimension carries semantic information. These vectors are often generated by deep learning models that transform raw inputs (e.g., text, images, audio) into a structured vector space reflecting their semantic similarities.

```python
# Example: 384-dimensional dense vector from a neural network model
dense_vector = [ 0.012, -0.034, 0.005, 0.041, -0.022, ..., 0.018 ]  # Length = 384
```

* **‚úÖ Semantic-Rich**: understands context and meaning (e.g., "king ‚Äì man + woman ‚âà queen")
* **‚ö†Ô∏è Opaque**: hard to interpret which features drive similarity

### Sparse Vectors

Sparse vectors are high-dimensional, often vocabulary-sized representations in which only a small subset of dimensions are non-zero. Each active dimension corresponds to a specific term (e.g., a word or n-gram), weighted by relevance scores such as **BM25**.

In this model, every document is converted into a vector ‚Äî called a document vector ‚Äî that records which terms appear in it and how important they are. Similarly, a search query is also turned into a sparse vector using the same weighting scheme.

Rather than relying on exact keyword matches, similarity between a query and a document is computed using the dot product of their vectors. This measures how well their weighted terms align: documents that contain the same important terms as the query receive higher scores ‚Äî rewarding both **term overlap** and **term importance**.

```python
# Example: Sparse vector over a vocabulary of 50,000 terms, stored as {term: weight}
sparse_vector = {
    "puppy": 2.31,
    "dog": 1.85,
    "pet": 1.12,
    "animal": 0.76
}
# The remaining ~49,996 dimensions are implicitly zero.
```

For computational efficiency, sparse vectors use integer indices to map terms to their positions within a vocabulary dictionary rather than storing the term strings directly.

```python
# Vocabulary mapping, containing around 50,000 unique terms, indexed by integer IDs
vocab = {
    "animal": 124,
    "dog": 309,
    "pet": 1822,
    "puppy": 4017,
    "cat": 5001,
    "kitten": 7890,
    # ... (many other terms fill the rest of the dictionary)
    # Total size ‚âà 50,000
}

# Sparse vector stored as {index: weight}
sparse_vector = {
    4017: 2.31,   # "puppy"
    309: 1.85,    # "dog"
    1822: 1.12,   # "pet"
    124: 0.76     # "animal"
}
# The remaining ~49,996 dimensions are implicitly zero.
```

* **‚úÖ Interpretable**: non-zero dimensions map directly to known terms (e.g., `4017` ‚Üí "puppy")
* **‚ö†Ô∏è Lacks Semantic Understanding**: treats "car" and "automobile" as unrelated unless explicitly linked


# Delete



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Zvec provides two ways to delete [documents](../../concepts/data-modeling/#documents). Choose the method that best fits your use case:

| Method               | Input                                             | When to Use                                                                                                |
| -------------------- | ------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `delete()`           | One or more document `id`s                        | Use when you know the exact ID(s) of the documents you want to delete                                      |
| `delete_by_filter()` | A filter expression (e.g., `publish_year < 1900`) | Use for bulk deletion based on field values ‚Äî ideal for cleaning up documents that match specific criteria |

<Callout className="text-base" type="warn">
  Delete operations are **immediate** and **irreversible**.\
  Always double-check your input before running a delete operation.
</Callout>

***

## Delete by IDs

Assume you've already opened a collection and have a `collection` object ready.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Use `delete()` to remove one or more documents when you know their exact IDs.

```python title="Delete documents by IDs"
# Delete a single document
result = collection.delete(ids="doc_id_1")              # [!code highlight]
print(result)  # {"code":0} means success

# Delete multiple documents at once
result = collection.delete(ids=["doc_id_2", "doc_id_3"])    # [!code highlight]
print(result)  # [{"code":0}, {"code":0}]
```

<Callout className="text-base" type="info">
  * When given a single `id`, `delete()` returns one `Status` object.
  * When given a list of `id`s, it returns a list of `Status` objects in the same order.
  * `{"code": 0}` indicates success.
  * Non-zero codes indicate failure ‚Äî for example, if the document `id` does not exist.
</Callout>

***

## Delete by Filter Condition

Use `delete_by_filter()` to remove all documents that match a boolean `filter` expression.

The `filter` can reference scalar fields (e.g., `publish_year`, `language`) using comparison and logical operators.

```python title="Delete documents by filter condition"
# Delete all books published before 1900
collection.delete_by_filter(filter="publish_year < 1900")   # [!code highlight]

# Combined filter
collection.delete_by_filter(                                # [!code highlight]
    filter='publish_year < 1900 AND (language = "English" OR language = "Chinese")'
)
```


# Fetch



Use `fetch()` to retrieve [documents](../../concepts/data-modeling/#documents) by their `id`s.\
This is a **direct lookup** ‚Äî no search, scoring, or filtering is involved.

```python title="Fetch documents"
# Fetch a single document
result = collection.fetch(ids="book_1")
print(result)   # { "book_1": Doc(...) }


# Fetch multiple documents
result = collection.fetch(ids=["book_1", "book_2", "book_3"])
print(result)   # { "book_1": Doc(...), "book_2": Doc(...), "book_3": Doc(...) }
```

* **Input**: A single document `id` or a list of document `id`s.
* **Output**: A dictionary mapping each found `id` to its document.
* Missing `id`s are **silently omitted** from the result (no error raised).
* The returned dictionary does not guarantee input order ‚Äî access documents by `id` instead.


# Data Operations



Zvec provides a complete set of **data manipulation operations** to manage [documents](../concepts/data-modeling/#documents) in your [collection](../collections/).

| Operation             | Purpose                                                                                    |
| --------------------- | ------------------------------------------------------------------------------------------ |
| [`Insert`](./insert/) | Add new documents (fails if the document `ID` already exists)                              |
| [`Upsert`](./upsert/) | Insert new documents or replace existing ones by `ID`                                      |
| [`Update`](./update/) | Modify specific fields of existing documents by `ID`                                       |
| [`Delete`](./delete/) | Delete documents by `ID` or using a scalar filter condition                                |
| [`Query`](./query/)   | Perform vector similarity search, optionally combined with scalar filtering and re-ranking |
| [`Fetch`](./fetch/)   | Retrieve full documents directly by `ID`                                                   |

<Callout className="text-base" type="success">
  All write operations (`insert`, `upsert`, `update`, `delete`) are immediately visible for querying ‚Äî enabling true real-time, streaming workloads.
</Callout>


# Insert



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Use the **`insert()`** method to add one or more new [documents](../../concepts/data-modeling/#documents) (`Doc`) to a [collection](../../collections/).

<Callout className="text-base" type="idea">
  **Performance Tip**:\
  New vectors are initially buffered for fast ingestion. For optimal search performance, call [`optimize()`](../../collections/optimize/) after inserting a large batch of documents.
</Callout>

***

## Document `Doc`

Each `Doc` passed to `insert()` must:

* Have a unique `id` (not already present in the collection)
* Provide data that matches the collection's [schema](../../collections/create/#step-1-define-the-schema):
  1. **Scalar fields** go in the `fields` dictionary (field names as keys)
  2. **Vector embeddings** go in the `vectors` dictionary (vector names as keys)
* You can omit `nullable` scalar fields if a document doesn't have a value for them

<Callout className="text-base" type="info">
  If a document with the same `id` already exists in the collection, the insertion will **fail** for that document.\
  To overwrite existing documents or insert without checking, use [`upsert()`](../upsert/) instead.
</Callout>

***

## Insert a Single Document

Assume you already have a collection with the following schema:

* A scalar field: `text` (string)
* A [dense vector embedding](../../concepts/vector-embedding/#dense-vectors): `text_embedding` (4-dimensional FP32 vector)
  <Callout className="text-base" type="idea">
    The 4-dimensional vector is for demonstration only ‚Äî real-world embeddings are usually much larger.
  </Callout>

You've also opened the collection and have a `collection` object ready.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="text",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="text_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=4,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Now, insert a document like this:

```python title="Insert a document"
import zvec

# Create a document
doc = zvec.Doc(  # [!code highlight]
    id="text_1",  # ‚Üê must be unique
    vectors={
        "text_embedding": [0.1, 0.2, 0.3, 0.4],  # ‚Üê must match the vector name
                          # ‚Üë list of floats; list length = dimension (4)
    },
    fields={
        "text": "This is a sample text.",  # ‚Üê must match the scalar field name
    },
)

# Insert the document
result = collection.insert(doc)  # [!code highlight]
print(result)  # {"code": 0} means success
```

<Callout className="text-base" type="info">
  The `insert()` method returns a `Status` object for single-document insertion.

  * `{"code": 0}` indicates success.
  * Non-zero codes indicate failure.

  Successfully inserted documents are immediately available for querying üöÄ.
</Callout>

***

## Insert a Batch of Documents

To insert multiple documents at once, pass a list of `Doc` objects to `insert()`.\
Each `Doc` is processed independently, and the method returns a list of `Status` objects ‚Äî one per document.

```python title="Insert a batch of documents"
import zvec

result = collection.insert(  # [!code highlight]
    [
        zvec.Doc(
            id="text_1",
            vectors={"text_embedding": [0.1, 0.2, 0.3, 0.4]},
            fields={"text": "This is a sample text."},
        ),
        zvec.Doc(
            id="text_2",
            vectors={"text_embedding": [0.4, 0.3, 0.2, 0.1]},
            fields={"text": "This is another sample text."},
        ),
        zvec.Doc(
            id="text_3",
            vectors={"text_embedding": [-0.1, -0.2, -0.3, -0.4]},
            fields={"text": "One more sample text."},
        ),
    ]
)

print(result)  # [{"code":0}, {"code":0}, {"code":0}]
```

<Callout className="text-base" type="info">
  A failure in one document (e.g., duplicate `id`) does not stop the others from being inserted.\
  üîç **Always check each `Status` in the result list.**
</Callout>

***

## Insert Documents with Sparse Vectors

Assume your collection includes a [sparse vector](../../concepts/vector-embedding/#sparse-vectors) named `sparse_embedding`.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        vectors=[
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Insert a document with a sparse vector like this:

```python title="Insert a document with a sparse vector"
import zvec

result = collection.insert(  # [!code highlight]
    zvec.Doc(
        id="text_1",
        vectors={
            "sparse_embedding": {
                42: 1.25,  # ‚Üê dimension 42 has weight 1.25
                1337: 0.8,  # ‚Üê dimension 1337 has weight 0.8
                2999: 0.63,  # ‚Üê dimension 1999 has weight 0.63
            }
        },
    )
)

print(result)  # {"code":0}
```

<Callout className="text-base" type="info">
  A sparse vector is represented as a dictionary `dict[int, float]`.\
  There is **no fixed dimension size** ‚Äî only non-zero dimensions need to be included.
</Callout>

***

## Insert Documents with Multiple Fields and Vectors

Real-world applications often require collections with multiple scalar fields and vector embeddings. In this example, assume your collection includes the following schema:

* **Scalar fields**:
  1. `book_title` (string)
  2. `category` (array of strings)
  3. `publish_year` (32-bit integer)
* **Vector embeddings**:
  1. `dense_embedding`: a 768-dimensional dense vector
  2. `sparse_embedding`: a sparse vector

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="book_title",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
            zvec.FieldSchema(
                name="category",
                data_type=zvec.DataType.ARRAY_STRING,
            ),
            zvec.FieldSchema(
                name="publish_year",
                data_type=zvec.DataType.INT32,
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Insert a document with multiple fields and vectors like this:

```python title="Insert a document with multiple fields and vectors"
import zvec

# Create a document
doc = zvec.Doc(  # [!code highlight]
    id="book_1",
    vectors={
        "dense_embedding": [0.1 for _ in range(768)],  # ‚Üê use real embedding in practice
        "sparse_embedding": {42: 1.25, 1337: 0.8, 1999: 0.64},  # ‚Üê use real embedding in practice
    },
    fields={
        "book_title": "Gone with the Wind",  # ‚Üê string
        "category": ["Romance", "Classic Literature"],  # ‚Üê array of strings
        "publish_year": 1936,  # ‚Üê integer
    },
)

# Insert the document
result = collection.insert(doc)   # [!code highlight]
print(result)  # {"code": 0} means success
```


# Update



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Use `update()` to modify **existing** [documents](../../concepts/data-modeling/#documents) (`Doc`).

Only the scalar fields and vector embeddings you include will be updated; all other content remains unchanged.

The method accepts either a single `Doc` object or a list of `Doc` objects.

***

## Document `Doc`

Each `Doc` passed to `update()` must:

* Specify an `id` that **already exists** in the collection (the operation will fail if the document is not found)
* Include only the fields and vectors you **intend to update**, formatted according to the collection's [schema](../../collections/create/#step-1-define-the-schema):
  1. **Scalar fields** go in the `fields` dictionary (field names as keys)
  2. **Vector embeddings** go in the `vectors` dictionary (vector names as keys)
* Omit any scalar fields or vectors you do not want to change ‚Äî they will be left untouched.

***

## Update a Single Document

Assume you already have a collection with the following schema:

* **Scalar fields**:
  1. `book_title` (string)
  2. `category` (array of strings)
  3. `publish_year` (32-bit integer)
* **Vector embeddings**:
  1. `dense_embedding`: a 768-dimensional dense vector
  2. `sparse_embedding`: a sparse vector

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="book_title",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
            zvec.FieldSchema(
                name="category",
                data_type=zvec.DataType.ARRAY_STRING,
            ),
            zvec.FieldSchema(
                name="publish_year",
                data_type=zvec.DataType.INT32,
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

To update an existing document, provide its `id` and only the fields or vectors you want to change:

```python title="Update a document"
import zvec

doc = zvec.Doc(  # [!code highlight]
    id="book_1",  # ‚Üê must already exist in the collection
    vectors={
        "sparse_embedding": {  # ‚Üê replaces entire sparse vector
            35: 0.25,
            237: 0.1,
            369: 0.44,
        },
    },
    fields={
        "category": [  # ‚Üê replaces current category list
            "Romance",
            "Classic Literature",
            "American Civil War",
        ],
    },
    # Note: `book_title`, `publish_year`, and `dense_embedding` are omitted ‚Üí they stay as-is
)

# Update the document
result = collection.update(doc)   # [!code highlight]
print(result)  # {"code": 0} means success
```

<Callout className="text-base" type="info">
  The `update()` method returns a single `Status` object for one document.

  * `{"code": 0}` indicates success.
  * Non-zero codes indicate failure.

  Successfully updated documents are immediately available for querying üöÄ.
</Callout>

***

## Update a Batch of Documents

To update multiple documents at once, pass a list of `Doc` objects to `update()`.\
Each `Doc` is processed independently, and the method returns a list of `Status` objects ‚Äî one per document.

```python title="Update a batch of documents"
import zvec

results = collection.update(  # [!code highlight]
    [
        zvec.Doc(
            id="book_1",
            vectors={
                "sparse_embedding": {35: 0.25, 237: 0.1, 369: 0.44},
            },
            fields={
                "category": ["Romance", "Classic Literature", "American Civil War"],
            },
        ),
        zvec.Doc(
            id="book_2",
            fields={
                "book_title": "The Great Gatsby",
            },
        ),
        zvec.Doc(
            id="book_3",
            fields={
                "book_title": "A Tale of Two Cities",
                "publish_year": 1859,
            },
        ),
    ]
)

print(results)  # [{"code":0}, {"code":0}, {"code":0}]
```

<Callout className="text-base" type="info">
  A failure in one document (e.g., the `id` doesn't exist ) does not stop the others from being updated.\
  üîç **Always check each `Status` in the result list.**
</Callout>


# Upsert



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

`upsert()` works just like `insert()` ‚Äî it adds one or more new [documents](../../concepts/data-modeling/#documents) (`Doc`) to a [collection](../../collections/).

The key difference is that if a document with the same `id` already exists, it will be **overwritten**.

<Callout className="text-base" type="info">
  * Use `upsert()` if you want to overwrite an existing document (or don't mind replacing it).
  * Use `insert()` if you want to avoid accidentally overwriting a document ‚Äî `insert()` will fail if a document with the same id already exists.
</Callout>

<Callout className="text-base" type="idea">
  **Performance Tip**:\
  New vectors are initially buffered for fast ingestion. For optimal search performance, call [`optimize()`](../../collections/optimize/) after upserting a large batch of documents.
</Callout>

***

## Document `Doc`

Each `Doc` passed to `upsert()` must:

* Have an `id` (if a document with the same `id` already exists, it will be replaced)
* Provide data that matches the collection's [schema](../../collections/create/#step-1-define-the-schema):
  1. **Scalar fields** go in the `fields` dictionary (field names as keys)
  2. **Vector embeddings** go in the `vectors` dictionary (vector names as keys)
* You can omit `nullable` scalar fields if a document doesn't have a value for them

***

## Upsert a Single Document

Assume you already have a collection with the following schema:

* A scalar field: `text` (string)
* A [dense vector embedding](../../concepts/vector-embedding/#dense-vectors): `text_embedding` (4-dimensional FP32 vector)
  <Callout className="text-base" type="idea">
    The 4-dimensional vector is for demonstration only ‚Äî real-world embeddings are usually much larger.
  </Callout>

You've also opened the collection and have a `collection` object ready.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="text",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="text_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=4,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Now, upsert a document like this:

```python title="Upsert a document"
import zvec

# Create a document
doc = zvec.Doc(  # [!code highlight]
    id="text_1",  # ‚Üê must be unique
    vectors={
        "text_embedding": [0.1, 0.2, 0.3, 0.4],  # ‚Üê must match the vector name
                          # ‚Üë list of floats; list length = dimension (4)
    },
    fields={
        "text": "This is a sample text.",  # ‚Üê must match the scalar field name
    },
)

# Upsert the document
result = collection.upsert(doc)  # [!code highlight]
print(result)  # {"code": 0} means success
```

<Callout className="text-base" type="info">
  The `upsert()` method returns a `Status` object for single-document upsertion.

  * `{"code": 0}` indicates success.
  * Non-zero codes indicate failure.

  Successfully upserted documents are immediately available for querying üöÄ.
</Callout>

***

## Upsert a Batch of Documents

To upsert multiple documents at once, pass a list of `Doc` objects to `upsert()`.\
Each `Doc` is processed independently, and the method returns a list of `Status` objects ‚Äî one per document.

```python title="Upsert a batch of documents"
import zvec

result = collection.upsert(  # [!code highlight]
    [
        zvec.Doc(
            id="text_1",
            vectors={"text_embedding": [0.1, 0.2, 0.3, 0.4]},
            fields={"text": "This is a sample text."},
        ),
        zvec.Doc(
            id="text_2",
            vectors={"text_embedding": [0.4, 0.3, 0.2, 0.1]},
            fields={"text": "This is another sample text."},
        ),
        zvec.Doc(
            id="text_3",
            vectors={"text_embedding": [-0.1, -0.2, -0.3, -0.4]},
            fields={"text": "One more sample text."},
        ),
    ]
)

print(result)  # [{"code":0}, {"code":0}, {"code":0}]
```

<Callout className="text-base" type="info">
  A failure in one document (e.g., missing a required field or invalid data type) does not stop the others from being upserted.\
  üîç **Always check each `Status` in the result list.**
</Callout>

***

## Upsert Documents with Sparse Vectors

Assume your collection includes a [sparse vector](../../concepts/vector-embedding/#sparse-vectors) named `sparse_embedding`.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        vectors=[
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Upsert a document with a sparse vector like this:

```python title="Upsert a document with a sparse vector"
import zvec

result = collection.upsert(  # [!code highlight]
    zvec.Doc(
        id="text_1",
        vectors={
            "sparse_embedding": {
                42: 1.25,  # ‚Üê dimension 42 has weight 1.25
                1337: 0.8,  # ‚Üê dimension 1337 has weight 0.8
                2999: 0.63,  # ‚Üê dimension 1999 has weight 0.63
            }
        },
    )
)

print(result)  # {"code":0}
```

<Callout className="text-base" type="info">
  A sparse vector is represented as a dictionary `dict[int, float]`.\
  There is **no fixed dimension size** ‚Äî only non-zero dimensions need to be included.
</Callout>

***

## Upsert Documents with Multiple Fields and Vectors

Real-world applications often require collections with multiple scalar fields and vector embeddings.\
In this example, assume your collection includes the following schema:

* **Scalar fields**:
  1. `book_title` (string)
  2. `category` (array of strings)
  3. `publish_year` (32-bit integer)
* **Vector embeddings**:
  1. `dense_embedding`: a 768-dimensional dense vector
  2. `sparse_embedding`: a sparse vector

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="book_title",
                data_type=zvec.DataType.STRING,
                index_param=zvec.InvertIndexParam(enable_range_optimization=False),
            ),
            zvec.FieldSchema(
                name="category",
                data_type=zvec.DataType.ARRAY_STRING,
            ),
            zvec.FieldSchema(
                name="publish_year",
                data_type=zvec.DataType.INT32,
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/example/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

Upsert a document with multiple fields and vectors like this:

```python title="Upsert a document with multiple fields and vectors"
import zvec

# Create a document
doc = zvec.Doc(  # [!code highlight]
    id="book_1",
    vectors={
        "dense_embedding": [0.1 for _ in range(768)],  # ‚Üê use real embedding in practice
        "sparse_embedding": {42: 1.25, 1337: 0.8, 1999: 0.64},  # ‚Üê use real embedding in practice
    },
    fields={
        "book_title": "Gone with the Wind",  # ‚Üê string
        "category": ["Romance", "Classic Literature"],  # ‚Üê array of strings
        "publish_year": 1936,  # ‚Üê integer
    },
)

# Upsert the document
result = collection.upsert(doc)  # [!code highlight]
print(result)  # {"code": 0} means success
```


# Flat Index



## How It Works

Performs an exact (brute-force) similarity search by comparing the query vector against every vector in the dataset.

## When to Use a Flat Index

* ‚úÖ Small datasets
* ‚úÖ Prototyping and experimentation
* ‚úÖ Evaluation baselines
* ‚úÖ Scenarios where 100% recall is non-negotiable

<Callout className="text-base" type="idea">
  **Best Practice**: Start with Flat Index during development and testing ‚Äî it‚Äôs your reliability anchor. Once you validate your approach, consider approximate indexes (like [HNSW](../hnsw-index/)) for production-scale performance. Use the Flat index when working with tiny datasets where correctness outweighs speed.
</Callout>

## Advantages

1. ‚ú® **Perfect Recall Guarantee** ‚Äî Finds true nearest neighbors
2. ‚ú® **Zero Configuration** ‚Äî Simple setup with no tuning required
3. ‚ú® **Instant Indexing** ‚Äî Build time is virtually immediate

## Limitations

‚ö†Ô∏è Search latency grows linearly with dataset size ‚Äî making it impractical for large-scale workloads.


# HNSW Index





A graph-based index and the go-to choice for low-latency approximate nearest neighbor search ‚Äî delivering state-of-the-art speed and recall at the cost of higher memory usage

## How It Works

[HNSW](https://arxiv.org/abs/1603.09320) builds a **multi-layer graph structure** where each node represents a vector and edges connect nodes based on similarity.

<img alt="HNSW Example" src={__img0} />

* Layers form a hierarchy ü™ú
  * **Upper layers** are sparse and act as "highways" for fast long-range navigation.
  * **Lower layers** are dense and provide fine-grained local neighborhood connectivity.
* How search works (coarse ‚Üí fine) üîç
  1. Start from an **entry point** at the top layer.
  2. At the current layer, you greedily walk to neighbors that are closer to the query vector, until you can't get any closer.
  3. Then you **drop down one layer** at that position and repeat the same greedy search.
  4. On the **lowest layer**, this process is done more carefully (with a small candidate list) to refine the result.
* **Why this is fast and accurate** ‚ö° üéØ
  * **Fast**: Upper layers let you jump quickly to the right region without visiting most points.
  * **Accurate**: The dense bottom layer lets you explore the local neighborhood thoroughly, so recall stays high.

## When to Use an HNSW Index?

* ‚úÖ Real-time, low-latency applications (e.g., conversational AI and live recommendations)
* ‚úÖ Production systems requiring consistent high recall with minimal latency

<Callout className="text-base" type="idea">
  **Best Practice**: HNSW is our **recommended default** for most production use cases. It strikes an excellent balance between speed, accuracy, and robustness.
</Callout>

## Advantages

1. ‚ú® **Near-logarithmic query time** ‚Äî Typically **O(log n)** for large datasets
2. ‚ú® **Consistently high recall** across diverse data distributions
3. ‚ú® **Faster indexing** than many alternatives (e.g., [IVF-based](../ivf-index/) methods)

## Trade-offs

1. ‚ö†Ô∏è **Higher memory footprint** ‚Äî Graph links require additional storage (scales with [`m`](#key-parameters))
2. ‚ö†Ô∏è **Indexing complexity of O(n log n)** ‚Äî Slower build time than [Flat index](../flat-index/) (but often faster than [IVF](../ivf-index/))

## Key Parameters

<Callout className="text-base" type="idea">
  **Tuning Tip**:\
  Start with defaults, then adjust `ef` first for recall/latency trade-offs.\
  Only if needed, increase `ef_construction` or `m` for better accuracy ‚Äî but expect slower indexing and higher memory use.
</Callout>

### Index-Time Parameters

| Parameter         | Description                                                                                                                                        | Tuning Guidance                                                                                                                                |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| `metric_type`     | **Similarity metric** used to compare vectors                                                                                                      | Choose based on how your embeddings were trained                                                                                               |
| `m`               | **Max neighbors per node** ‚Äî The maximum number of bidirectional links created for each node during graph construction                             | ‚Ä¢ Higher `m` ‚Üí <br /> ‚ú® better recall and graph connectivity <br /> ‚ö†Ô∏è more memory usage and higher latency for both indexing and search       |
| `ef_construction` | **Index-time candidate pool size** ‚Äî Determines how many neighboring candidates the algorithm considers when inserting a new vector into the graph | ‚Ä¢ Higher `ef_construction` ‚Üí <br /> ‚ú® better graph quality and higher recall <br /> ‚ö†Ô∏è longer index build time (*does not affect query speed*) |
| `quantize_type`   | **Vector quantization method** to apply <br /> Defaults to no quantization                                                                         | See [Quantization](../quantization/) for more details                                                                                          |

### Query-Time Parameters

| Parameter          | Description                                                                                                                                 | Tuning Guidance                                                                                                                                                                                                                                    |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ef`               | **Query-time candidate pool size** ‚Äî Determines how many potential neighbors are explored at each step during graph traversal at query time | ‚Ä¢ Higher `ef` ‚Üí <br /> ‚ú® higher recall <br /> ‚ö†Ô∏è higher query latency                                                                                                                                                                              |
| `radius`           | **Distance (similarity) threshold** for range-based filtering ‚Äî only documents satisfying the threshold are returned                        | Example: <br /> ‚Ä¢ With inner product `MetricType.IP`, set `radius=0.6` to  keep only results with score > 0.6 <br /> ‚úÖ Use when: You want to filter out low-quality matches <br /> üö´ Skip when: You want all top-k results, regardless of quality |
| `is_linear`        | Forces a **brute-force linear search** instead of using the index                                                                           | üêå Very slow for large datasets! <br /> ‚úÖ Only use for: Debugging, tiny collections, or verifying index accuracy                                                                                                                                   |
| `is_using_refiner` | **Enables exact score refinement** (recomputes exact similarity scores) for top candidates ‚Äî useful when vectors are **quantized**          | ‚úÖ Turn on: When you need higher accuracy <br /> ‚ö†Ô∏è Adds latency due to exact re-scoring                                                                                                                                                            |


# Vector Index



A vector index is a specialized data structure that accelerates similarity search over large collections of vector embeddings.

Without an index, finding the most similar items to a query requires comparing it against **every single vector** in the database ‚Äî a process known as **brute-force** or **flat search**.

Brute-force search is:

* ‚úÖ **Accurate**: Returns the exact most similar results ‚Äî no approximation.
* ‚ö†Ô∏è **Painfully slow at scale**: With millions or billions of vectors, queries can take seconds or minutes, making them impractical for real-time applications.

***

## Approximate vs. Exact Search

Most vector indexes use ***Approximate Nearest Neighbor (ANN)*** algorithms.

Instead of finding the exact closest matches, ANN finds *very close approximations* ‚Äî often indistinguishable in quality for practical purposes ‚Äî while delivering massive gains in speed and efficiency.

For real-world uses, such as semantic search or recommendations, this small accuracy trade-off delivers huge gains in speed and scalability. In short: ***good enough to be correct, but lightning fast*** ‚ú®.

### Recall: Measuring Approximation Quality

**Recall** is the standard metric for evaluating how well an ANN algorithm preserves result quality.

It quantifies the fraction of **true nearest neighbors** ‚Äî identified by an exact (brute-force) search ‚Äî that appear in the top‚Äëk results returned by the approximate method:

$$
\textcolor{#2563eb}{
  \text{Recall@}k = \frac{\text{Number of true nearest neighbors in top-}k}{k}
}
$$

Example:

* If you request the top 10 results and 9 of them match the true top 10 from a brute-force search, your `recall@10` is 90%.
* High recall (e.g., ‚â• 96%) typically means the approximation is practically indistinguishable from exact search for most applications.

Different index types (e.g., HNSW) and their parameters (e.g., `ef_search`) let you fine-tune the balance between ***recall, query speed, and resource usage*** ‚Äî so you can optimize for your specific accuracy and performance requirements.

***

## Vector Index Types

Zvec supports three vector index types, each suited to different use cases, dataset sizes, and performance requirements:

1. [Flat (Brute-Force) index](./flat-index/)
2. [HNSW (Hierarchical Navigable Small World)](./hnsw-index/)
3. [IVF (Inverted File Index)](./ivf-index/)

<Callout className="text-base" type="idea">
  Choose an index type based on your scale, latency requirements, and accuracy tolerance. Always use the same distance metric that your embedding model was trained for.
</Callout>


# IVF Index







A partition-based, scalable, memory-efficient indexing method best suited for large datasets ‚Äî especially those with natural cluster structure ‚Äî at the expense of slower indexing and more involved tuning

## How It Works

IVF operates by **partitioning the entire vector space into clusters**. The number of clusters is controlled by the parameter [`n_list`](#key-parameters) (short for "number of lists").

### Indexing Phase ‚öôÔ∏è

1. **Clustering**: The algorithm first applies a clustering algorithm, creating `n_list` clusters. Each cluster is represented by its centroid ‚Äî a central point that best represents all vectors assigned to that cluster.

2. **Assignment**: Each vector in the dataset is assigned to the **cluster whose centroid is closest** to it. The vector is then stored in an inverted list (also called a "bucket") associated with that centroid. The index essentially becomes a mapping from centroids to their associated vectors.

<img alt="IVF indexing" src={__img0} />

### Query Phase üîç

1. **Centroid Selection**: When a query vector arrives, the system first computes distances between the query and all `n_list` centroids to identify the `n_probe` nearest centroids (`n_probe` is a parameter that controls how many centroids to consider).

2. **Local Search**: Instead of scanning the entire dataset of `N` vectors, the search is **restricted to only the vectors stored in the `n_probe` selected buckets**. A brute-force (or refined) search is then performed within those buckets to find the final nearest neighbors.

<img alt="IVF Query" src={__img1} />

## When to Use an IVF Index

* ‚úÖ Your vector dataset exhibits natural clustering or locality structure
* ‚úÖ You‚Äôre working with very large datasets and memory efficiency is critical
* ‚úÖ You need to tune parameters to achieve optimal performance

<Callout className="text-base" type="idea">
  **Best Practice**:

  * IVF works best on datasets with inherent clustering structure.
  * For even greater memory efficiency and scalability, combine it with Product Quantization (PQ).
  * The performance of IVF is highly sensitive to parameters like `n_list`. As such, IVF is best suited for practitioners who can systematically experiment with, validate, and optimize these settings for their specific data distribution and latency-recall requirements.
</Callout>

## Advantages

1. ‚ú® **Compatibility** ‚Äî Often used as a base layer in composite indexes (e.g., IVF-PQ) for further optimization
2. ‚ú® **Scalability** ‚Äî Query time scales approximately as **O(N / `n_list` √ó `n_probe`)**, making it highly efficient for large `N` when `n_list` is large and `n_probe` is small
3. ‚ú® **Memory Efficiency** ‚Äî Stores vectors in compact inverted lists with minimal overhead from centroids and list pointers, typically uses significantly less memory than graph-based methods like [HNSW](../hnsw-index/)

## Trade-offs

1. ‚ö†Ô∏è **Indexing Overhead** ‚Äî Building the index requires clustering, which can be computationally intensive and slower to build than indexes like [HNSW](../hnsw-index/)
2. ‚ö†Ô∏è **Parameter Sensitivity** ‚Äî Accuracy and latency are highly dependent on the choice of `n_list` and `n_probe`

## Key Parameters

### Index-Time Parameters

| Parameter       | Description                                                                                                       | Tuning Guidance                                                                                                                                                                                                                                                                                                     |
| --------------- | ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `metric_type`   | **Similarity metric** used to compare vectors                                                                     | Choose based on how your embeddings were trained                                                                                                                                                                                                                                                                    |
| `n_list`        | **Number of clusters** (inverted lists) ‚Äî the vector space is partitioned into this many clusters during indexing | ‚Ä¢ Start with `n_list` ‚âà $\sqrt{N}$, where `N` is the number of vectors <br /> ‚Ä¢ Larger `n_list` ‚Üí ‚ú® finer partitioning, smaller buckets, faster search ‚Äî but ‚ö†Ô∏è higher indexing cost and more centroids to manage <br /> ‚Ä¢ Smaller `n_list` ‚Üí ‚ú® faster index construction ‚Äî but ‚ö†Ô∏è larger buckets and slower search |
| `n_iters`       | **Centroid refinement iterations** ‚Äî number of passes to optimize cluster centroids during indexing               | ‚Ä¢ Higher `n_iters` ‚Üí <br /> ‚ú® better clustering quality <br /> ‚ö†Ô∏è longer index build time                                                                                                                                                                                                                           |
| `quantize_type` | **Vector quantization method** to apply <br /> Defaults to no quantization                                        | See [Quantization](../quantization/) for more details                                                                                                                                                                                                                                                               |

### Query-Time Parameters

| Parameter   | Description                                                                                                          | Tuning Guidance                                                                                                                                                                                                                                  |
| ----------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `n_probe`   | **Number of clusters to search at query time** ‚Äî the system retrieves candidates only from these nearest clusters.   | ‚Ä¢ Higher `n_probe` ‚Üí <br /> ‚ú® higher recall <br /> ‚ö†Ô∏è slower queries                                                                                                                                                                             |
| `radius`    | **Distance (similarity) threshold** for range-based filtering ‚Äî only documents satisfying the threshold are returned | Example: With inner product metric `MetricType.IP`, set `radius=0.6` to  keep only results with score > 0.6 <br /> ‚úÖ Use when: You want to filter out low-quality matches <br /> üö´ Skip when: You want all top-k results, regardless of quality |
| `is_linear` | Forces a **brute-force linear search** instead of using the index                                                    | üêå Very slow for large datasets! <br /> ‚úÖ Only use for: Debugging, tiny collections, or verifying index accuracy                                                                                                                                 |


# Quantization





Quantization is a compression technique that ***transforms vectors from their original (specifically FP32) format into a more compact representation***, reducing the size of vector indexes used for search.

This transformation approximates vectors using fewer bits per dimension ‚Äî enabling:

* ‚ú® Lower **memory footprint** ‚Äî especially when the index is memory-resident,
* ‚ú® Faster I/O and lower query latency ‚Äî due to reduced data movement and efficient integer/fp16 arithmetic,
* ‚ú® Better scalability on resource-constrained hardware.

<img alt="Quantization" src={__img0} />

<Callout className="text-base" type="warn">
  **Important**:

  * Quantization is a ***lossy and irreversible*** compression method. It improves runtime efficiency **at the cost of potentially reduced recall accuracy**. Always validate its effect on your retrieval quality.
  * Quantization only provides benefits when applied to vectors in a **FP32** format.
</Callout>

## Storage Behavior

To ensure data integrity and flexibility, **Zvec stores both the original vectors and their quantized versions**. This means:

* The **overall on-disk storage usage may increase** (due to storing two copies).
* However, **only the quantized vectors are loaded into memory for indexing and search**, significantly reducing the active index size.
* Users can always **retrieve the original, unaltered vectors** when needed.

## Enabling Quantization

You can **activate quantization when creating a vector index** in Zvec by specifying the desired quantization type (`FP16`, `INT8`, or `INT4`) through the `quantize_type` parameter in your `VectorSchema`.

Zvec will then automatically generate and manage the quantized representation alongside your original vectors.

***

## Quantization Types

### FP16 (Half-Precision Floating Point)

Uses 16-bit floating-point numbers to reduce memory footprint and accelerate computation while maintaining high numerical precision. Ideal for applications requiring near-FP32 accuracy with improved efficiency. Requires conversion from FP32 source.

### INT8 (8-Bit Integer Quantization)

Represents vectors using 8-bit integers, significantly reducing storage and memory bandwidth requirements. Offers a good trade-off between speed, size, and retrieval accuracy for many similarity search tasks. Requires conversion from FP32 source.

### INT4 (4-Bit Integer Quantization)

Ultra-compact representation using only 4 bits per dimension. Maximizes storage density and inference speed, suitable for latency-sensitive or resource-constrained environments where noticeable accuracy loss is acceptable. Requires conversion from FP32 source.


# Conditional Filtering



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Conditional filtering lets you retrieve documents that match specific criteria based on their scalar fields ‚Äî similar to a `WHERE` clause in SQL.

***

## Performance Considerations

* **Indexed scalar fields**: Can be efficiently searched.
* **Unindexed scalar fields**: Can still be searched, but with significantly lower performance.

<Callout className="text-base" type="info">
  For optimal performance, ensure **frequently filtered fields are indexed**.\
  For more details, please see the [Inverted Index](../../../concepts/inverted-index/).
</Callout>

***

## Prerequisites

This guide assumes you have opened a collection containing scalar fields.

<Accordions type="single">
  <Accordion title="Example Collection Setup">
    This example collection contains the following scalar fields:

    1. `publish_year`: Integer field, indexed with range optimization enabled
    2. `category`: String array field, indexed ‚Äî supports fast membership checks
    3. `summary`: String field, stored but **not indexed** (`index_param` is `None`)
    4. `in_stock`: Boolean field, indexed for quick `true/false` queries

    ```python title="Open a collection"
    import zvec

    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        fields=[
            zvec.FieldSchema(
                name="publish_year",
                data_type=zvec.DataType.INT32,
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
            zvec.FieldSchema(
                name="category",
                data_type=zvec.DataType.ARRAY_STRING,
                index_param=zvec.InvertIndexParam(),
            ),
            zvec.FieldSchema(
                name="summary",
                data_type=zvec.DataType.STRING,
            ),
            zvec.FieldSchema(
                name="in_stock",
                data_type=zvec.DataType.BOOL,
                index_param=zvec.InvertIndexParam(),
            ),
        ],
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## Performing Conditional Filtering

Apply conditional filtering by passing a `filter` expression to the `query()` method.

The expression uses **SQL-like syntax** to define search conditions.

The `topk` parameter specifies the maximum number of matching documents to return.

<Callout className="text-base" type="idea">
  If more documents satisfy the filter than the specified `topk`, only the first `topk` results are returned.\
  Results are returned in no guaranteed order (typically in internal storage order).
</Callout>

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Conditional filtering"
    # [!code word:filter]
    import zvec

    # 1. Retrieve up to 10 documents published in the year 2000
    results = collection.query(filter="publish_year = 2000", topk=10)

    # 2. Retrieve up to 50 documents published before 1999
    results = collection.query(filter="publish_year < 1999", topk=50)

    # 3. Retrieve all in-stock items (assuming the collection has ‚â§100 documents)
    results = collection.query(filter="in_stock = true", topk=100)

    # 4. Romance or mystery books (up to 20 matches)
    results = collection.query(filter="category CONTAIN_ANY('romance', 'mystery')", topk=20)

    # 5. Books that belong to both science and philosophy categories
    results = collection.query(filter="category CONTAIN_ALL('science', 'philosophy')", topk=10)

    # 6. Recent (2015 or later), in-stock romance books
    results = collection.query(
        filter="publish_year >= 2015 AND in_stock = true AND category CONTAIN_ANY('romance')",
        topk=30,
        output_fields=["summary"],  # Return only the 'summary' field
    )
    ```
  </Accordion>
</Accordions>

<Callout className="text-base" type="info">
  The `query()` method with a `filter` returns a list of matching `Doc` objects.

  Each `Doc` object includes:

  1. `id`: The document identifier.
  2. `vectors`: A dictionary of vector embeddings.\
     This is **only populated** if `include_vector=True` is passed in the query.
  3. `fields`: A dictionary of scalar field values.\
     By default, **all scalar fields** are returned; this can be restricted using the `output_fields` parameter.
</Callout>

***

## Supported Filter Syntax

### Comparison Operators

| Operator      | Description                    | Supported Data Types                | Example Expression                               |
| ------------- | ------------------------------ | ----------------------------------- | ------------------------------------------------ |
| `<`           | Less than                      | Integers, Floats, Strings           | `publish_year < 2000`                            |
| `<=`          | Less than or equal to          | Integers, Floats, Strings           | ‚Ä¢ `price <= 29.99` <br /> ‚Ä¢ `author_name <= 'M'` |
| `=`           | Equal to                       | Integers, Floats, Strings, Booleans | ‚Ä¢ `in_stock = true` <br /> ‚Ä¢ `name = 'Michael'`  |
| `!=`          | Not equal to                   | Integers, Floats, Strings, Booleans | ‚Ä¢ `rating != 5` <br /> ‚Ä¢ `status != 'active'`    |
| `>=`          | Greater than or equal to       | Integers, Floats, Strings           | `score >= 85.5`                                  |
| `>`           | Greater than                   | Integers, Floats, Strings           | `age > 12`                                       |
| `is null`     | Checks if a field has no value | All data types                      | `email is null`                                  |
| `is not null` | Checks if a field has a value  | All data types                      | `email is not null`                              |

<Callout className="text-base" type="info">
  * **String comparisons** use lexicographic ordering: `'apple' < 'banana'` evaluates to `true`
  * **String literals** must be enclosed in single (`'`) or double (`"`) quotes: `'hello world'`
  * **Boolean comparisons** use the keywords `true` and `false` (case-insensitive)
  * **Range queries**: When `enable_range_optimization` is set to `true`, range queries run efficiently. If it's `false`, they still work ‚Äî but may be significantly slower.
</Callout>

### Membership Operators

| Operator       | Description                                         | Supported Data Types      | Example Expression                                                          | Explanation                                                                                                                                                                                                                            |
| -------------- | --------------------------------------------------- | ------------------------- | --------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `in`           | Is one of                                           | Integers, Floats, Strings | ‚Ä¢ `error_code in (400, 403, 404)` <br /> ‚Ä¢ `user_name in ('admin', 'root')` | Evaluates to `true` if the field value **matches any** of the listed values. <br /><br /> ‚Ä¢ `error_code` is `400`, `403`, or `404` ‚Üí `true` <br /> ‚Ä¢ `user_name` is `'admin'` or '`root'` ‚Üí `true`                                     |
| `not in`       | Is not one of                                       | Integers, Floats, Strings | `status not in ('deleted', 'archived')`                                     | Evaluates to `true` if the field value **does not match any** of the listed values. <br /><br /> ‚Ä¢ `status` is anything other than `'deleted'` or `'archived'` ‚Üí `true`                                                                |
| `contain_all`  | Array includes **all** listed values                | Array Types               | `tags contain_all ('urgent', 'bug')`                                        | Evaluates to `true` only if the array contains **every** value in the list. <br /><br /> ‚Ä¢ `tags = ['bug', 'urgent', 'ui']` ‚Üí `true` <br /> ‚Ä¢ `tags = ['bug', 'ui']` ‚Üí `false` (missing 'urgent')                                      |
| `contain_any`  | Array includes **at least one** of the listed value | Array Types               | `permissions contain_any ('execute', 'write')`                              | Evaluates to `true` if the array contains **at least one** of the listed values. <br /><br /> ‚Ä¢ `permissions = ['admin', 'execute']` ‚Üí `true` <br /> ‚Ä¢ `permissions = ['read', 'forbidden']` ‚Üí `false` (neither 'execute' nor 'write') |
| `array_length` | Array length                                        | Array Types               | `array_length(tags) > 2`                                                    | Evaluates to `true` if the array's length satisfies the condition. <br /><br /> ‚Ä¢ `tags = ['bug']` ‚Üí `false` (length is 1) <br /> ‚Ä¢ `tags = ['bug', 'urgent', 'fix']` ‚Üí `true` (length is 3)                                           |

<Callout className="text-base" type="info">
  * **Parentheses `()` are required** around the list of values.
  * **String literals** must be enclosed in single (`'`) or double (`"`) quotes: `'hello world'`
</Callout>

### String Operators

| Operator | Description                  | Supported Data Types | Example Expression                                               | Explanation                                                                                                                                                                      |
| -------- | ---------------------------- | -------------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `like`   | Pattern match with wildcards | Strings              | ‚Ä¢ `product_name like 'Smart%'` <br /> ‚Ä¢ `file_name like '%.log'` | ‚Ä¢ `'Smart%'`: matches values starting with 'Smart' (e.g., 'SmartPhone', 'SmartWatch') <br /> ‚Ä¢ `'%.log'`: matches values ending with '.log' (e.g., 'app.log', 'debug\_2025.log') |

<Callout className="text-base" type="info">
  **Performance Considerations**:\
  For optimal `LIKE` query performance, fields should be [indexed](../../../concepts/inverted-index/).

  * **Unindexed fields** still support filtering, but queries may be **significantly slower**.
  * For **efficient infix/suffix patterns** (`'abc%def'`, `'%abc'`), configure an inverted index with `enable_extended_wildcard = true` option.
  * Patterns with **multiple wildcards** (e.g., `'%abc%def%'`) are inherently expensive and should be used sparingly.
</Callout>

### Logical Operators

| Operator | Description | Example Expression                       | Explanation                                                  |
| -------- | ----------- | ---------------------------------------- | ------------------------------------------------------------ |
| `and`    | Logical AND | `status = 'active' and score > 90`       | Evaluates to `true` only if **all** conditions are `true`.   |
| `or`     | Logical OR  | `role = 'admin' or permission = 'write'` | Evaluates to `true` if **at least one** condition is `true`. |

<Callout className="text-base" type="info">
  **Tip**: Use parentheses `()` to group expressions and control evaluation order, e.g., `expr1 and (expr2 or expr3)`.
</Callout>


# Grouped Query



Grouped Query brings the power of SQL-like `GROUP BY` semantics to vector search. With this feature, you'll be able to group retrieval results by specified scalar fields ‚Äî such as `category` ‚Äî and perform vector similarity searches within each group.

<Callout className="text-base" type="info">
  Grouped Query support will be available in an upcoming release.
</Callout>


# Vector + Filter



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

You can combine **vector search** with **scalar filters** to restrict results to a subset of documents ‚Äî just like adding a `WHERE` clause to a similarity search.

***

## Prerequisites

This guide assumes you:

* Have already opened a `collection` instance.
* Are familiar with [vector querying](../single-vector/) and [conditional filtering](../filter/).

<Accordions type="single">
  <Accordion title="Example Collection Setup">
    This example collection contains one dense vector field `dense_embedding` and one scalar field `publish_year`.

    ```python title="Open a collection"
    import zvec

    # [!code word:dense_embedding]
    # [!code word:publish_year]
    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
        ],
        fields=[
            zvec.FieldSchema(
                name="publish_year",
                data_type=zvec.DataType.INT32,
                index_param=zvec.InvertIndexParam(enable_range_optimization=True),
            ),
        ],
    )

    collection = zvec.open(path="/path/to/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## Performing Filtered Vector Search

To combine vector similarity search with filters, pass both a `VectorQuery` and a `filter` expression to the `query()` method.

```python title="Filtered vector similarity search"
import zvec

result = collection.query(
    zvec.VectorQuery(  # [!code highlight]
        field_name="dense_embedding",
        vector=[0.1] * 768,  # Replace with real embedding
    ),
    filter="publish_year > 1936",  # Only consider books published after 1936   [!code highlight]
    topk=10,
)
print(result)
```

This returns the top-10 most similar documents that satisfy `publish_year > 1936`, sorted by similarity score.


# Query



import { Combine,  Filter, Layers, Search } from 'lucide-react';

The `query()` method supports **vector similarity search**, **conditional filtering** (like a SQL `WHERE` clause), or **both combined in a hybrid query**.

It returns a list of `Doc` objects, each containing the matched [document](../../concepts/data-modeling/#documents) and its relevance score.

<Callout className="text-base" type="info">
  * Use [`VectorQuery`](./single-vector/#vectorquery) objects for vector similarity search
  * Use a filter expression string (e.g., `status = 'published'`) for conditional filtering
</Callout>

***

## Query Types

<Cards>
  <Card title="Single-Vector Search" description="Find documents using a single vector embedding" href="./single-vector/" icon={<Search />} />

  <Card title="Multi-Vector Search" description="Combine multiple embeddings with re-ranking" href="./multi-vector/" icon={<Layers />} />

  <Card title="Conditional Filtering" description="Filter documents using scalar field conditions" href="./filter/" icon={<Filter />} />

  <Card title="Filtered Vector Search" description="Combine vector search with conditional filters" href="./hybrid/" icon={<Combine />} />
</Cards>

***

## Quick Start Examples

### Single-Vector Search

```python
import zvec

result = collection.query(  # [!code highlight]
    vectors=zvec.VectorQuery(
        field_name="dense_embedding",
        vector=[0.1] * 768,  # Replace with a real 768-dim embedding in practice
    ),
    topk=10,
)
```

### Multi-Vector Search

```python
import zvec

result = collection.query(  # [!code highlight]
    topk=10,
    vectors=[
        zvec.VectorQuery(field_name="dense_embedding", vector=[0.1] * 768),         # [!code highlight]
        zvec.VectorQuery(field_name="sparse_embedding", vector={1: 0.1, 37: 0.43}), # [!code highlight]
    ],
    reranker=zvec.WeightedReRanker(  # [!code highlight]
        topn=3,
        metric=zvec.MetricType.IP,
        weights={
            "dense_embedding": 1.2,
            "sparse_embedding": 1.0,
        },
    ),
)
print(result)
```

### Conditional Filtering

```python
# [!code word:filter]
results = collection.query(filter="publish_year < 1999", topk=50)
```

### Hybrid Search

```python
import zvec

result = collection.query(          # [!code highlight]
    vectors=zvec.VectorQuery(
        field_name="dense_embedding",
        vector=[0.1] * 768,  # Replace with a real 768-dim embedding in practice
    ),
    filter="publish_year < 1999",   # [!code highlight]
    topk=10,
)
```


# Multiple Vectors



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Zvec supports **multi-vector queries**, allowing you to combine different embeddings in a single search.

When querying multiple vector embeddings, Zvec retrieves top candidates from each vector space independently.\
Since similarity scores from different vector spaces might not be directly comparable, a **re-ranker** is required to fuse and and re-rank the results into a unified, relevance-ordered list.

***

## Prerequisites

This guide assumes:

* You have opened a `collection` with multiple vector fields
* You're familiar with the basic vector querying concepts. If not, please review the [single-vector search](../single-vector/) guide

<Accordions type="single">
  <Accordion title="Example Collection Setup">
    This example collection contains two vector fields:

    1. **`dense_embedding`** ‚Äî A 768-dimensional dense vector using inner product metric
    2. **`sparse_embedding`** ‚Äî A sparse vector using inner product metric

    It also includes two scalar fields (`publish_year` and `category`).

    ```python title="Open a collection"
    import zvec

    # [!code word:dense_embedding]
    # [!code word:sparse_embedding]
    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
        fields=[
            zvec.FieldSchema(name="publish_year", data_type=zvec.DataType.INT64),
            zvec.FieldSchema(name="category", data_type=zvec.DataType.ARRAY_STRING),
        ],
    )

    collection = zvec.open(path="/path/to/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## Performing Multi-Vector Search

To run a multi-vector search, pass a list of [`VectorQuery`](../single-vector/#vectorquery) objects to the `query()` method and specify a fusion strategy via the `reranker` parameter.

<Accordions type="single">
  <Accordion title="Code Example">
    This example queries both `dense_embedding` and `sparse_embedding` and uses a `WeightedReranker` to combine their results:

    ```python title="Query with multiple vectors"
    import zvec

    result = collection.query(  # [!code highlight]
        topk=5,  # Retrieve top 5 candidates from each individual vector embedding
        vectors=[  # List of vector queries ‚Äî one for each embedding space to search
            zvec.VectorQuery(field_name="dense_embedding", vector=[0.1] * 768),           # [!code highlight]
            zvec.VectorQuery(field_name="sparse_embedding", vector={1: 0.1, 37: 0.43}),   # [!code highlight]
        ],
        reranker=zvec.WeightedReRanker(  # [!code highlight]
            topn=3,  # Return top 3 documents after re-ranking
            metric=zvec.MetricType.IP,  # Metric used to interpret raw scores
            weights={  # Assign higher importance (weight) to 'dense_embedding'
                "dense_embedding": 1.2,
                "sparse_embedding": 1.0,
            },
        ),
    )
    print(result)
    ```
  </Accordion>
</Accordions>

<Callout className="text-base" type="info">
  In multi-vector search, `topk` takes on a different meaning compared to single-vector queries:

  * `topk` (in `query()`): Controls how many candidate documents are retrieved **from each vector field** before re-ranking. A larger `topk` gives the re-ranker more candidates to work with, potentially improving final quality but increasing computational cost.
  * `topn` (in `ReRanker`): Controls how many final documents are returned **after** score fusion and re-ranking. This is your final result set size.
</Callout>

### Re-ranking Strategies

Zvec provides different re-ranking strategies to combine scores from multiple vector fields.

| Re-ranker  | `WeightedReRanker`                                                                                                                              | `RrfReRanker` (Reciprocal Rank Fusion)                                                                                                          |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Approach   | Combines normalized similarity scores using **custom weights**                                                                                  | Fuses results based only on **ranking positions** ‚Äî no scores needed <br /> The RRF score at rank‚ÄØ*r* is: $\text{RRF}(r) = \frac{1}{k + r + 1}$ |
| Best for   | ‚Ä¢ Scores are reasonably comparable across vector fields <br /> ‚Ä¢ You know the relative importance of each embedding type                        | ‚Ä¢ Scores come from different metrics or scales <br /> ‚Ä¢ You prefer a simple, robust, tuning-free method                                         |
| Parameters | ‚Ä¢ `weights`: Dictionary mapping vector names to their relative importance <br /> ‚Ä¢ `metric`: The similarity metric used for score normalization | `rank_constant` (*k*): Controls how quickly rank influence decreases. Higher values reduce the dominance of top-ranked results.                 |


# Single Vector



import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { Settings2 } from 'lucide-react';

Single-vector search finds documents most similar to a single query embedding. This is the most common search pattern in vector databases.

***

## Prerequisites

This guide assumes you have opened a collection and have a `collection` object ready.

<Accordions type="single">
  <Accordion title="Example Collection Setup">
    This example collection contains two vector fields:

    1. **`dense_embedding`** ‚Äî A 768-dimensional dense vector using cosine metric
    2. **`sparse_embedding`** ‚Äî A sparse vector using inner product metric

    It also includes two scalar fields (`publish_year` and `category`).

    ```python title="Open a collection"
    import zvec

    # [!code word:dense_embedding]
    # [!code word:sparse_embedding]
    collection_schema = zvec.CollectionSchema(  # [!code highlight]
        name="example_collection",
        vectors=[
            zvec.VectorSchema(
                name="dense_embedding",
                data_type=zvec.DataType.VECTOR_FP32,
                dimension=768,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.COSINE),
            ),
            zvec.VectorSchema(
                name="sparse_embedding",
                data_type=zvec.DataType.SPARSE_VECTOR_FP32,
                index_param=zvec.HnswIndexParam(metric_type=zvec.MetricType.IP),
            ),
        ],
        fields=[
            zvec.FieldSchema(name="publish_year", data_type=zvec.DataType.INT64),
            zvec.FieldSchema(name="category", data_type=zvec.DataType.ARRAY_STRING),
        ],
    )

    collection = zvec.open(path="/path/to/collection")  # [!code highlight]
    ```
  </Accordion>
</Accordions>

***

## `VectorQuery`

In Zvec, all vector similarity searches are performed by passing one or more `VectorQuery` objects to the `query()` method.

Each `VectorQuery` specifies:

1. `field_name`: The name of the vector field to search
2. **Query source** (exactly one required):
   * An explicit `vector`, **or**
   * a document `id` (to reuse the stored embedding of an existing document)
   <Callout className="text-base" type="info">
     You must provide **exactly one** of `vector` or `id`. Specifying both will raise an error.
   </Callout>
3. `param` (optional): Index-specific query parameters (e.g., `ef` for [HNSW](../../../concepts/vector-index/hnsw-index/)).

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="VectorQuery"
    import zvec

    vector_query = zvec.VectorQuery(  # [!code highlight]
        field_name="dense_embedding",
        vector=[0.1] * 768,  # Replace with a real 768-dim embedding in practice
    )

    by_id_query = zvec.VectorQuery(  # [!code highlight]
        field_name="dense_embedding",
        id="doc123",  # Use the 'dense_embedding' from the document with ID "doc123"
    )
    ```
  </Accordion>
</Accordions>

***

## Performing Single-Vector Search

To perform a single-vector similarity search, call the `query()` method with a single `VectorQuery` object.

<Accordions type="single">
  <Accordion title="Code Example">
    ```python title="Query with a single vector"
    import zvec

    # Dense vector search
    result = collection.query(  # [!code highlight]
        vectors=zvec.VectorQuery(
            field_name="dense_embedding",
            # Dense embeddings are lists of floats
            vector=[0.1] * 768,  # Replace with a real 768-dim embedding in practice
        ),
        topk=3,
    )
    print(result)

    # Sparse vector search
    result = collection.query(  # [!code highlight]
        vectors=zvec.VectorQuery(
            field_name="sparse_embedding",
            # Sparse embeddings are dicts: {dimension_index: weight}
            vector={  # Replace with a real sparse embedding in practice
                42: 1.25,
                1337: 0.8,
                1999: 0.64,
            },
        ),
        topk=3,
    )
    print(result)

    # Query by document ID (reuses stored embedding)
    result = collection.query(  # [!code highlight]
        vectors=zvec.VectorQuery(
            field_name="dense_embedding",
            id="book_1",  # Uses the 'dense_embedding' of the document with this ID
        ),
        topk=100,
        include_vector=True,  # Returns the vector embedding
        output_fields=["publish_year"],  # Returns the 'publish_year' field
    )
    print(result)
    ```
  </Accordion>
</Accordions>

<Callout className="text-base" type="info">
  All queries return a `list[Doc]` containing the **top-k** most similar documents, sorted by relevance score.

  Each `Doc` object includes:

  1. `id`: The document identifier.
  2. `score`: The similarity score.
  3. `vectors`: A dictionary of vector embeddings.\
     This is **only populated** if `include_vector=True` is passed in the query.
  4. `fields`: A dictionary of scalar field values.\
     By default, **all scalar fields** are returned; this can be restricted using the `output_fields` parameter.
</Callout>

<Accordions type="single">
  <Accordion title="Example Output">
    This example shows results from a query on the `dense_embedding` field with the following settings:

    1. `topk=3:` returns the 3 most similar documents
    2. `include_vector=False` (default): vector embeddings are not returned, so `"vectors": null`
    3. All scalar fields are returned
    4. Cosine distance is used to compute similarity scores ‚Äî lower scores indicate greater similarity

    $$
    \textcolor{#2563eb}{
      d_{\text{cosine}} = 1 - \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \|\mathbf{b}\|}
    }
    $$

    ```json
    [{
      "id": "book_16",    // [!code highlight]
      "score": 0.12152397632598877,
      "fields": {
        "publish_year": 1866,
        "category": [
          "technology",
          "romance"
        ]
      },
      "vectors": null
    }, {
      "id": "book_69",    // [!code highlight]
      "score": 0.12367439270019531,
      "fields": {
        "publish_year": 1919,
        "category": [
          "art",
          "fiction"
        ]
      },
      "vectors": null
    }, {
      "id": "book_24",    // [!code highlight]
      "score": 0.12455785274505615,
      "fields": {
        "publish_year": 1874,
        "category": [
          "romance",
          "politics"
        ]
      },
      "vectors": null
    }]
    ```
  </Accordion>
</Accordions>

### Common Parameters

| Parameter        | Description                                                                                                     |
| ---------------- | --------------------------------------------------------------------------------------------------------------- |
| `vectors`        | The `VectorQuery` object specifying the query vector and target field.                                          |
| `topk`           | The number of most similar documents to return.                                                                 |
| `include_vector` | If `True`, the returned `Doc` objects include the full vector embeddings (disabled by default for performance). |
| `output_fields`  | An optional list of scalar field names to include in results. If omitted, all scalar fields are returned.       |
| `filter`         | An optional SQL-like boolean expression to restrict results. See [filtered search](../filter/) for details.     |

<Callout className="text-base" type="warn">
  The `reranker` parameter is part of the `query()` interface but **only applies to [multi-vector search](../multi-vector/)**.\
  Do not provide it in single-vector queries.
</Callout>

### Index-Specific Parameters

You can fine-tune search behavior by passing index-specific query parameters through the `param` in `VectorQuery`.

The `param` option accepts different parameter classes depending on the index type of your vectors ‚Äî for example,

* `VectorQuery(..., param=HnswQueryParam())` for HNSW indexes,
* `VectorQuery(..., param=IVFQueryParam())` for IVF-based indexes.

The available query options are determined by this index type. If omitted, default values are used.

<Callout className="text-base" type="info">
  Each index type exposes its own set of tunable options at query time. For full details:

  <Cards>
    <Card title="HNSW Query Parameters" href="../../../concepts/vector-index/hnsw-index/#query-time-parameters" icon={<Settings2 />} />

    <Card title="IVF Query Parameters" href="../../../concepts/vector-index/ivf-index/#query-time-parameters" icon={<Settings2 />} />
  </Cards>
</Callout>

<Callout className="text-base" type="warn">
  Mismatched parameter classes will cause an error. For instance, using `IVFQueryParam` with an HNSW-indexed vector (or vice versa) is not allowed.
</Callout>

<Accordions type="single">
  <Accordion title="Code Example">
    If `dense_embedding` uses an [HNSW](../../../concepts/vector-index/hnsw-index/) index, you can adjust the `ef` parameter like this:

    ```python title="Query with index-specific parameters"
    import zvec

    result = collection.query(    # [!code highlight]
        vectors=zvec.VectorQuery(
            field_name="dense_embedding",
            vector=[0.1] * 768,
            param=zvec.HnswQueryParam(ef=500),  # Set ef to a larger value for better recall [!code highlight]
        ),
        topk=10,
    )
    print(result)
    ```
  </Accordion>
</Accordions>
